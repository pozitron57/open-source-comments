{
  "sha": "c852ea4834dbed5e739fcdfecce51fe7638236a2",
  "node_id": "C_kwDOBtgov9oAKGM4NTJlYTQ4MzRkYmVkNWU3MzlmY2RmZWNjZTUxZmU3NjM4MjM2YTI",
  "commit": {
    "author": {
      "name": "Dmitry Verkhoturov",
      "email": "paskal.07@gmail.com",
      "date": "2021-10-29T16:33:25Z"
    },
    "committer": {
      "name": "Umputun",
      "email": "umputun@gmail.com",
      "date": "2021-10-29T16:48:46Z"
    },
    "message": "bump go modules",
    "tree": {
      "sha": "ebb37916a1a243cdd5de9bb0347d21b596df1391",
      "url": "https://api.github.com/repos/umputun/remark42/git/trees/ebb37916a1a243cdd5de9bb0347d21b596df1391"
    },
    "url": "https://api.github.com/repos/umputun/remark42/git/commits/c852ea4834dbed5e739fcdfecce51fe7638236a2",
    "comment_count": 0,
    "verification": {
      "verified": false,
      "reason": "unsigned",
      "signature": null,
      "payload": null
    }
  },
  "url": "https://api.github.com/repos/umputun/remark42/commits/c852ea4834dbed5e739fcdfecce51fe7638236a2",
  "html_url": "https://github.com/umputun/remark42/commit/c852ea4834dbed5e739fcdfecce51fe7638236a2",
  "comments_url": "https://api.github.com/repos/umputun/remark42/commits/c852ea4834dbed5e739fcdfecce51fe7638236a2/comments",
  "author": {
    "login": "paskal",
    "id": 712534,
    "node_id": "MDQ6VXNlcjcxMjUzNA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/712534?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/paskal",
    "html_url": "https://github.com/paskal",
    "followers_url": "https://api.github.com/users/paskal/followers",
    "following_url": "https://api.github.com/users/paskal/following{/other_user}",
    "gists_url": "https://api.github.com/users/paskal/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/paskal/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/paskal/subscriptions",
    "organizations_url": "https://api.github.com/users/paskal/orgs",
    "repos_url": "https://api.github.com/users/paskal/repos",
    "events_url": "https://api.github.com/users/paskal/events{/privacy}",
    "received_events_url": "https://api.github.com/users/paskal/received_events",
    "type": "User",
    "site_admin": false
  },
  "committer": {
    "login": "umputun",
    "id": 535880,
    "node_id": "MDQ6VXNlcjUzNTg4MA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/535880?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/umputun",
    "html_url": "https://github.com/umputun",
    "followers_url": "https://api.github.com/users/umputun/followers",
    "following_url": "https://api.github.com/users/umputun/following{/other_user}",
    "gists_url": "https://api.github.com/users/umputun/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/umputun/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/umputun/subscriptions",
    "organizations_url": "https://api.github.com/users/umputun/orgs",
    "repos_url": "https://api.github.com/users/umputun/repos",
    "events_url": "https://api.github.com/users/umputun/events{/privacy}",
    "received_events_url": "https://api.github.com/users/umputun/received_events",
    "type": "User",
    "site_admin": false
  },
  "parents": [
    {
      "sha": "8818faf1892407023fc00647e483132aa282424d",
      "url": "https://api.github.com/repos/umputun/remark42/commits/8818faf1892407023fc00647e483132aa282424d",
      "html_url": "https://github.com/umputun/remark42/commit/8818faf1892407023fc00647e483132aa282424d"
    }
  ],
  "stats": {
    "total": 11612,
    "additions": 1797,
    "deletions": 9815
  },
  "files": [
    {
      "sha": "ecf43cea0723e10ae892daaac9fa29f45977394c",
      "filename": "backend/_example/memory_store/go.sum",
      "status": "modified",
      "additions": 21,
      "deletions": 21,
      "changes": 42,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/_example/memory_store/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/_example/memory_store/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/_example/memory_store/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -35,24 +35,21 @@ github.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03\n github.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\n github.com/Depado/bfchroma v1.3.0 h1:zz14vpvySU6S0CL6yGPr1vkFevQecIt8dJdCsMS2JpM=\n github.com/Depado/bfchroma v1.3.0/go.mod h1:c0bFk0tFmT+clD3TIGurjWCfD/QV8/EebfM3JGr+98M=\n-github.com/PuerkitoBio/goquery v1.7.1 h1:oE+T06D+1T7LNrn91B4aERsRIeCLJ/oPSa6xB9FPnz4=\n-github.com/PuerkitoBio/goquery v1.7.1/go.mod h1:XY0pP4kfraEmmV1O7Uf6XyjoslwsneBbgeDjLYuN8xY=\n+github.com/PuerkitoBio/goquery v1.8.0 h1:PJTF7AmFCFKk1N6V6jmKfrNH9tV5pNE6lZMkG0gta/U=\n+github.com/PuerkitoBio/goquery v1.8.0/go.mod h1:ypIiRMtY7COPGk+I/YbZLbxsxn9g5ejnI2HSMtkjZvI=\n github.com/ajg/form v1.5.1/go.mod h1:uL1WgH+h2mgNtvBq0339dVnzXdBETtL2LeUXaIv25UY=\n-github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38 h1:smF2tmSOzy2Mm+0dGI2AIUHY+w0BUc+4tn40djz7+6U=\n github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38/go.mod h1:r7bzyVFMNntcxPZXK3/+KdruV1H5KSlyVY0gc+NgInI=\n github.com/alecthomas/chroma v0.7.3/go.mod h1:sko8vR34/90zvl5QdcUdvzL3J8NKjAUx9va9jPuFNoM=\n-github.com/alecthomas/chroma v0.9.2 h1:yU1sE2+TZbLIQPMk30SolL2Hn53SR/Pv750f7qZ/XMs=\n-github.com/alecthomas/chroma v0.9.2/go.mod h1:eMuEnpA18XbG/WhOWtCzJHS7WqEtDAI+HxdwoW0nVSk=\n-github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721 h1:JHZL0hZKJ1VENNfmXvHbgYlbUOvpzYzvy2aZU5gXVeo=\n+github.com/alecthomas/chroma v0.9.4 h1:YL7sOAE3p8HS96T9km7RgvmsZIctqbK1qJ0b7hzed44=\n+github.com/alecthomas/chroma v0.9.4/go.mod h1:jtJATyUxlIORhUOFNA9NZDWGAQ8wpxQQqNSB4rjA/1s=\n github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721/go.mod h1:QO9JBoKquHd+jz9nshCh40fOfO+JzsoXy8qTHF68zU0=\n github.com/alecthomas/kong v0.2.4/go.mod h1:kQOmtJgV+Lb4aj+I2LEn40cbtawdWJ9Y8QLq+lElKxE=\n github.com/alecthomas/repr v0.0.0-20180818092828-117648cd9897/go.mod h1:xTS7Pm1pD1mvyM075QCDSRqH6qRLXylzS24ZTpRiSzQ=\n-github.com/alecthomas/repr v0.0.0-20200325044227-4184120f674c h1:MVVbswUlqicyj8P/JljoocA7AyCo62gzD0O7jfvrhtE=\n github.com/alecthomas/repr v0.0.0-20200325044227-4184120f674c/go.mod h1:xTS7Pm1pD1mvyM075QCDSRqH6qRLXylzS24ZTpRiSzQ=\n github.com/alicebob/gopher-json v0.0.0-20180125190556-5a6b3ba71ee6/go.mod h1:SGnFV6hVsYE877CKEZ6tDNTjaSXYUk6QqoIK6PrAtcc=\n github.com/alicebob/miniredis/v2 v2.11.4/go.mod h1:VL3UDEfAH59bSa7MuHMuFToxkqyHh69s/WUbYlOAuyg=\n-github.com/andybalholm/cascadia v1.2.0 h1:vuRCkM5Ozh/BfmsaTm26kbjm0mIOM3yS5Ek/F5h18aE=\n-github.com/andybalholm/cascadia v1.2.0/go.mod h1:YCyR8vOZT9aZ1CHEd8ap0gMVm2aFgxBp0T0eFw1RUQY=\n+github.com/andybalholm/cascadia v1.3.1 h1:nhxRkql1kdYCc8Snf7D5/D3spOX+dBgjA6u8x004T2c=\n+github.com/andybalholm/cascadia v1.3.1/go.mod h1:R4bJ1UQfqADjvDa4P6HZHLh/3OxWWEqc0Sk8XGwHqvA=\n github.com/asaskevich/govalidator v0.0.0-20210307081110-f21760c49a8d/go.mod h1:WaHUgvxTVq04UNunO+XhnAqY/wQc+bxr74GqbsZ/Jqw=\n github.com/aymerick/douceur v0.2.0 h1:Mv+mAeH1Q+n9Fr+oyamOlAkUNPWPlA8PPGR0QAaYuPk=\n github.com/aymerick/douceur v0.2.0/go.mod h1:wlT5vV2O3h55X9m7iVYN0TBM0NH/MmbLnd30/FjWUq4=\n@@ -62,7 +59,6 @@ github.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5P\n github.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\n github.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\n github.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\n-github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964 h1:y5HC9v93H5EPKqaS1UYVg1uYah5Xf51mBfIoWehClUQ=\n github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964/go.mod h1:Xd9hchkHSWYkEqJwUGisez3G1QY8Ryz0sdWrLPMGjLk=\n github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\n github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\n@@ -88,7 +84,7 @@ github.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMo\n github.com/gavv/httpexpect v2.0.0+incompatible/go.mod h1:x+9tiU1YnrOvnB725RkpoLv1M62hOWzwo5OXotisrKc=\n github.com/go-chi/chi v4.1.1+incompatible h1:MmTgB0R8Bt/jccxp+t6S/1VGIKdJw5J74CK/c9tTfA4=\n github.com/go-chi/chi v4.1.1+incompatible/go.mod h1:eB3wogJHnLi3x/kFX2A+IbTBlXxmMeXJVKy9tTv1XzQ=\n-github.com/go-chi/chi/v5 v5.0.4/go.mod h1:DslCQbL2OYiznFReuXYUmQ2hGd1aDpCnlMNITLSKoi8=\n+github.com/go-chi/chi/v5 v5.0.5/go.mod h1:DslCQbL2OYiznFReuXYUmQ2hGd1aDpCnlMNITLSKoi8=\n github.com/go-chi/cors v1.2.0/go.mod h1:sSbTewc+6wYHBBCW7ytsFSn836hqM7JxpglAy2Vzc58=\n github.com/go-chi/render v1.0.1 h1:4/5tis2cKaNdnv9zFLfXzcquC9HbeZgCnxGnKrltBS8=\n github.com/go-chi/render v1.0.1/go.mod h1:pq4Rr7HbnsdaeHagklXub+p6Wd16Af5l9koip1OvJns=\n@@ -231,7 +227,6 @@ github.com/markbates/safe v1.0.1/go.mod h1:nAqgmRi7cY2nqMc92/bSEeQA+R4OheNU2T1kN\n github.com/mattn/go-colorable v0.1.4/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=\n github.com/mattn/go-colorable v0.1.6/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\n github.com/mattn/go-isatty v0.0.8/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\n-github.com/mattn/go-isatty v0.0.12 h1:wuysRhFDzyxgEmMf5xjvJ2M9dZoWAXNNr5LSBS7uHXY=\n github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\n github.com/microcosm-cc/bluemonday v1.0.15/go.mod h1:ZLvAzeakRwrGnzQEvstVzVt3ZpqOF2+sdFr0Om+ce30=\n github.com/microcosm-cc/bluemonday v1.0.16 h1:kHmAq2t7WPWLjiGvzKa5o3HzSfahUKiOq7fAPUiMNIc=\n@@ -260,13 +255,12 @@ github.com/rs/xid v1.3.0/go.mod h1:trrq9SKmegXys3aeAKXMUTdJsYXVwGY3RLcfgqegfbg=\n github.com/russross/blackfriday/v2 v2.0.1/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\n github.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=\n github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\n-github.com/sergi/go-diff v1.0.0 h1:Kpca3qRNrduNnOQeazBd0ysaKrUJiIuISHxogkT9RPQ=\n github.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=\n github.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=\n github.com/sirupsen/logrus v1.4.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\n github.com/sirupsen/logrus v1.4.1/go.mod h1:ni0Sbl8bgC9z8RoU9G6nDWqqs/fq4eDPysMBDgk/93Q=\n github.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\n-github.com/slack-go/slack v0.9.4/go.mod h1:wWL//kk0ho+FcQXcBTmEafUI5dz4qz5f4mMk8oIkioQ=\n+github.com/slack-go/slack v0.9.5/go.mod h1:wWL//kk0ho+FcQXcBTmEafUI5dz4qz5f4mMk8oIkioQ=\n github.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\n github.com/smartystreets/goconvey v1.6.4/go.mod h1:syvi0/a8iFYH4r/RixwvyeAJjdLS9QV7WQ/tjFTllLA=\n github.com/spf13/cobra v0.0.3/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=\n@@ -308,6 +302,7 @@ github.com/yudai/pp v2.0.1+incompatible/go.mod h1:PuxR/8QJ7cyCkFp/aUDS+JY727OFEZ\n github.com/yuin/goldmark v1.1.25/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n github.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n github.com/yuin/goldmark v1.1.32/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n+github.com/yuin/goldmark v1.3.5/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\n github.com/yuin/gopher-lua v0.0.0-20191220021717-ab39c6098bdb/go.mod h1:gqRgreBUhTSL0GeU64rtZ3Uq3wtjOa/TB2YfrtkCbVQ=\n go.etcd.io/bbolt v1.3.5/go.mod h1:G5EMThwa9y8QZGBClrRx5EY+Yw9kAhnjy3bSjsnlVTQ=\n go.etcd.io/bbolt v1.3.6 h1:/ecaJf0sk1l4l6V4awd65v2C3ILy7MSj+s/x1ADCIMU=\n@@ -318,7 +313,7 @@ go.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\n go.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n go.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n go.opencensus.io v0.22.4/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n-go.uber.org/goleak v1.1.10/go.mod h1:8a7PlsEVH3e/a/GLqe5IIrQx6GzcnRmZEufDUTk4A7A=\n+go.uber.org/goleak v1.1.12/go.mod h1:cwTWslyiVhfpKIDGSZEM2HlOvcqm+tG4zioyIeLoqMQ=\n golang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\n golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\n golang.org/x/crypto v0.0.0-20190422162423-af44ce270edf/go.mod h1:WFFai1msRO1wXaEeE5yQxYXgSfI8pQAWXbQop6sCtWE=\n@@ -327,7 +322,7 @@ golang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8U\n golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\n golang.org/x/crypto v0.0.0-20200302210943-78000ba7a073/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\n golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\n-golang.org/x/crypto v0.0.0-20210817164053-32db794688a5/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\n+golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\n golang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\n@@ -341,8 +336,8 @@ golang.org/x/exp v0.0.0-20200224162631-6cc2880d07d6/go.mod h1:3jZMyOhIsHpP37uCMk\n golang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\n golang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\n golang.org/x/image v0.0.0-20210504121937-7319ad40d33e/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\n-golang.org/x/image v0.0.0-20210628002857-a66eb6448b8d h1:RNPAfi2nHY7C2srAV8A49jpsYr0ADedCk1wq6fTMTvs=\n-golang.org/x/image v0.0.0-20210628002857-a66eb6448b8d/go.mod h1:023OzeP/+EPmXeapQh35lcL3II3LrY8Ic+EFFKVhULM=\n+golang.org/x/image v0.0.0-20211028202545-6944b10bf410 h1:hTftEOvwiOq2+O8k2D5/Q7COC7k5Qcrgc2TFURJYnvQ=\n+golang.org/x/image v0.0.0-20211028202545-6944b10bf410/go.mod h1:023OzeP/+EPmXeapQh35lcL3II3LrY8Ic+EFFKVhULM=\n golang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\n golang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\n golang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\n@@ -361,7 +356,7 @@ golang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzB\n golang.org/x/mod v0.1.1-0.20191107180719-034126e5016b/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\n golang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n golang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n-golang.org/x/net v0.0.0-20180218175443-cbe0f9307d01/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n+golang.org/x/mod v0.4.2/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n golang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n golang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n golang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n@@ -392,8 +387,10 @@ golang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81R\n golang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\n golang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\n golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\n-golang.org/x/net v0.0.0-20210614182718-04defd469f4e h1:XpT3nA5TvE525Ne3hInMh6+GETgn27Zfm9dxsThnX2Q=\n+golang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\n golang.org/x/net v0.0.0-20210614182718-04defd469f4e/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8 h1:/6y1LfuqNuQdHAm0jjtPtgRcxIxjVZgm5OTu8/QhZvk=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\n golang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\n golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\n@@ -409,6 +406,7 @@ golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJ\n golang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n+golang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n golang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n@@ -447,7 +445,9 @@ golang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7w\n golang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20200923182605-d9f96fdee20d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1 h1:SrN+KX8Art/Sf4HNj6Zcz06G7VEz+7w9tdXTPOZ7+l4=\n golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\n@@ -484,7 +484,6 @@ golang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgw\n golang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n-golang.org/x/tools v0.0.0-20191108193012-7d206e10da11/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n@@ -510,6 +509,7 @@ golang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roY\n golang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n golang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n golang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n+golang.org/x/tools v0.1.5/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\n golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0="
    },
    {
      "sha": "a39f6e5f8b286367ffc85dfc3be1bcb82a7232a5",
      "filename": "backend/go.mod",
      "status": "modified",
      "additions": 8,
      "deletions": 8,
      "changes": 16,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/go.mod?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -4,11 +4,11 @@ go 1.16\n \n require (\n \tgithub.com/Depado/bfchroma v1.3.0\n-\tgithub.com/PuerkitoBio/goquery v1.7.1\n-\tgithub.com/alecthomas/chroma v0.9.2\n+\tgithub.com/PuerkitoBio/goquery v1.8.0\n+\tgithub.com/alecthomas/chroma v0.9.4\n \tgithub.com/didip/tollbooth/v6 v6.1.1\n \tgithub.com/didip/tollbooth_chi v0.0.0-20200828173446-a7173453ea21\n-\tgithub.com/go-chi/chi/v5 v5.0.4\n+\tgithub.com/go-chi/chi/v5 v5.0.5\n \tgithub.com/go-chi/cors v1.2.0\n \tgithub.com/go-chi/render v1.0.1\n \tgithub.com/go-pkgz/auth v1.18.0\n@@ -28,12 +28,12 @@ require (\n \tgithub.com/rakyll/statik v0.1.7\n \tgithub.com/rs/xid v1.3.0\n \tgithub.com/russross/blackfriday/v2 v2.1.0\n-\tgithub.com/slack-go/slack v0.9.4\n+\tgithub.com/slack-go/slack v0.9.5\n \tgithub.com/stretchr/testify v1.7.0\n \tgithub.com/umputun/go-flags v1.5.1\n \tgo.etcd.io/bbolt v1.3.6\n-\tgo.uber.org/goleak v1.1.10\n-\tgolang.org/x/crypto v0.0.0-20210817164053-32db794688a5\n-\tgolang.org/x/image v0.0.0-20210628002857-a66eb6448b8d\n-\tgolang.org/x/net v0.0.0-20210614182718-04defd469f4e\n+\tgo.uber.org/goleak v1.1.12\n+\tgolang.org/x/crypto v0.0.0-20210921155107-089bfa567519\n+\tgolang.org/x/image v0.0.0-20211028202545-6944b10bf410\n+\tgolang.org/x/net v0.0.0-20210916014120-12bc252f5db8\n )"
    },
    {
      "sha": "80d0b2f23605eb606a693504479f774b277f32e0",
      "filename": "backend/go.sum",
      "status": "modified",
      "additions": 27,
      "deletions": 26,
      "changes": 53,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -36,27 +36,24 @@ github.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03\n github.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\n github.com/Depado/bfchroma v1.3.0 h1:zz14vpvySU6S0CL6yGPr1vkFevQecIt8dJdCsMS2JpM=\n github.com/Depado/bfchroma v1.3.0/go.mod h1:c0bFk0tFmT+clD3TIGurjWCfD/QV8/EebfM3JGr+98M=\n-github.com/PuerkitoBio/goquery v1.7.1 h1:oE+T06D+1T7LNrn91B4aERsRIeCLJ/oPSa6xB9FPnz4=\n-github.com/PuerkitoBio/goquery v1.7.1/go.mod h1:XY0pP4kfraEmmV1O7Uf6XyjoslwsneBbgeDjLYuN8xY=\n+github.com/PuerkitoBio/goquery v1.8.0 h1:PJTF7AmFCFKk1N6V6jmKfrNH9tV5pNE6lZMkG0gta/U=\n+github.com/PuerkitoBio/goquery v1.8.0/go.mod h1:ypIiRMtY7COPGk+I/YbZLbxsxn9g5ejnI2HSMtkjZvI=\n github.com/ajg/form v1.5.1 h1:t9c7v8JUKu/XxOGBU0yjNpaMloxGEJhUkqFRq0ibGeU=\n github.com/ajg/form v1.5.1/go.mod h1:uL1WgH+h2mgNtvBq0339dVnzXdBETtL2LeUXaIv25UY=\n-github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38 h1:smF2tmSOzy2Mm+0dGI2AIUHY+w0BUc+4tn40djz7+6U=\n github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38/go.mod h1:r7bzyVFMNntcxPZXK3/+KdruV1H5KSlyVY0gc+NgInI=\n github.com/alecthomas/chroma v0.7.3/go.mod h1:sko8vR34/90zvl5QdcUdvzL3J8NKjAUx9va9jPuFNoM=\n-github.com/alecthomas/chroma v0.9.2 h1:yU1sE2+TZbLIQPMk30SolL2Hn53SR/Pv750f7qZ/XMs=\n-github.com/alecthomas/chroma v0.9.2/go.mod h1:eMuEnpA18XbG/WhOWtCzJHS7WqEtDAI+HxdwoW0nVSk=\n-github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721 h1:JHZL0hZKJ1VENNfmXvHbgYlbUOvpzYzvy2aZU5gXVeo=\n+github.com/alecthomas/chroma v0.9.4 h1:YL7sOAE3p8HS96T9km7RgvmsZIctqbK1qJ0b7hzed44=\n+github.com/alecthomas/chroma v0.9.4/go.mod h1:jtJATyUxlIORhUOFNA9NZDWGAQ8wpxQQqNSB4rjA/1s=\n github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721/go.mod h1:QO9JBoKquHd+jz9nshCh40fOfO+JzsoXy8qTHF68zU0=\n github.com/alecthomas/kong v0.2.4/go.mod h1:kQOmtJgV+Lb4aj+I2LEn40cbtawdWJ9Y8QLq+lElKxE=\n github.com/alecthomas/repr v0.0.0-20180818092828-117648cd9897/go.mod h1:xTS7Pm1pD1mvyM075QCDSRqH6qRLXylzS24ZTpRiSzQ=\n-github.com/alecthomas/repr v0.0.0-20200325044227-4184120f674c h1:MVVbswUlqicyj8P/JljoocA7AyCo62gzD0O7jfvrhtE=\n github.com/alecthomas/repr v0.0.0-20200325044227-4184120f674c/go.mod h1:xTS7Pm1pD1mvyM075QCDSRqH6qRLXylzS24ZTpRiSzQ=\n github.com/alicebob/gopher-json v0.0.0-20180125190556-5a6b3ba71ee6 h1:45bxf7AZMwWcqkLzDAQugVEwedisr5nRJ1r+7LYnv0U=\n github.com/alicebob/gopher-json v0.0.0-20180125190556-5a6b3ba71ee6/go.mod h1:SGnFV6hVsYE877CKEZ6tDNTjaSXYUk6QqoIK6PrAtcc=\n github.com/alicebob/miniredis/v2 v2.11.4 h1:GsuyeunTx7EllZBU3/6Ji3dhMQZDpC9rLf1luJ+6M5M=\n github.com/alicebob/miniredis/v2 v2.11.4/go.mod h1:VL3UDEfAH59bSa7MuHMuFToxkqyHh69s/WUbYlOAuyg=\n-github.com/andybalholm/cascadia v1.2.0 h1:vuRCkM5Ozh/BfmsaTm26kbjm0mIOM3yS5Ek/F5h18aE=\n-github.com/andybalholm/cascadia v1.2.0/go.mod h1:YCyR8vOZT9aZ1CHEd8ap0gMVm2aFgxBp0T0eFw1RUQY=\n+github.com/andybalholm/cascadia v1.3.1 h1:nhxRkql1kdYCc8Snf7D5/D3spOX+dBgjA6u8x004T2c=\n+github.com/andybalholm/cascadia v1.3.1/go.mod h1:R4bJ1UQfqADjvDa4P6HZHLh/3OxWWEqc0Sk8XGwHqvA=\n github.com/asaskevich/govalidator v0.0.0-20210307081110-f21760c49a8d/go.mod h1:WaHUgvxTVq04UNunO+XhnAqY/wQc+bxr74GqbsZ/Jqw=\n github.com/aymerick/douceur v0.2.0 h1:Mv+mAeH1Q+n9Fr+oyamOlAkUNPWPlA8PPGR0QAaYuPk=\n github.com/aymerick/douceur v0.2.0/go.mod h1:wlT5vV2O3h55X9m7iVYN0TBM0NH/MmbLnd30/FjWUq4=\n@@ -66,7 +63,6 @@ github.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5P\n github.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\n github.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\n github.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\n-github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964 h1:y5HC9v93H5EPKqaS1UYVg1uYah5Xf51mBfIoWehClUQ=\n github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964/go.mod h1:Xd9hchkHSWYkEqJwUGisez3G1QY8Ryz0sdWrLPMGjLk=\n github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\n github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\n@@ -96,8 +92,8 @@ github.com/gavv/httpexpect v2.0.0+incompatible h1:1X9kcRshkSKEjNJJxX9Y9mQ5BRfbxU\n github.com/gavv/httpexpect v2.0.0+incompatible/go.mod h1:x+9tiU1YnrOvnB725RkpoLv1M62hOWzwo5OXotisrKc=\n github.com/go-chi/chi v4.1.1+incompatible h1:MmTgB0R8Bt/jccxp+t6S/1VGIKdJw5J74CK/c9tTfA4=\n github.com/go-chi/chi v4.1.1+incompatible/go.mod h1:eB3wogJHnLi3x/kFX2A+IbTBlXxmMeXJVKy9tTv1XzQ=\n-github.com/go-chi/chi/v5 v5.0.4 h1:5e494iHzsYBiyXQAHHuI4tyJS9M3V84OuX3ufIIGHFo=\n-github.com/go-chi/chi/v5 v5.0.4/go.mod h1:DslCQbL2OYiznFReuXYUmQ2hGd1aDpCnlMNITLSKoi8=\n+github.com/go-chi/chi/v5 v5.0.5 h1:l3RJ8T8TAqLsXFfah+RA6N4pydMbPwSdvNM+AFWvLUM=\n+github.com/go-chi/chi/v5 v5.0.5/go.mod h1:DslCQbL2OYiznFReuXYUmQ2hGd1aDpCnlMNITLSKoi8=\n github.com/go-chi/cors v1.2.0 h1:tV1g1XENQ8ku4Bq3K9ub2AtgG+p16SmzeMSGTwrOKdE=\n github.com/go-chi/cors v1.2.0/go.mod h1:sSbTewc+6wYHBBCW7ytsFSn836hqM7JxpglAy2Vzc58=\n github.com/go-chi/render v1.0.1 h1:4/5tis2cKaNdnv9zFLfXzcquC9HbeZgCnxGnKrltBS8=\n@@ -261,7 +257,6 @@ github.com/markbates/safe v1.0.1/go.mod h1:nAqgmRi7cY2nqMc92/bSEeQA+R4OheNU2T1kN\n github.com/mattn/go-colorable v0.1.4/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=\n github.com/mattn/go-colorable v0.1.6/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\n github.com/mattn/go-isatty v0.0.8/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\n-github.com/mattn/go-isatty v0.0.12 h1:wuysRhFDzyxgEmMf5xjvJ2M9dZoWAXNNr5LSBS7uHXY=\n github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\n github.com/microcosm-cc/bluemonday v1.0.15/go.mod h1:ZLvAzeakRwrGnzQEvstVzVt3ZpqOF2+sdFr0Om+ce30=\n github.com/microcosm-cc/bluemonday v1.0.16 h1:kHmAq2t7WPWLjiGvzKa5o3HzSfahUKiOq7fAPUiMNIc=\n@@ -301,8 +296,8 @@ github.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeV\n github.com/sirupsen/logrus v1.4.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\n github.com/sirupsen/logrus v1.4.1/go.mod h1:ni0Sbl8bgC9z8RoU9G6nDWqqs/fq4eDPysMBDgk/93Q=\n github.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\n-github.com/slack-go/slack v0.9.4 h1:C+FC3zLxLxUTQjDy2RZeMHYon005zsCROiZNWVo+opQ=\n-github.com/slack-go/slack v0.9.4/go.mod h1:wWL//kk0ho+FcQXcBTmEafUI5dz4qz5f4mMk8oIkioQ=\n+github.com/slack-go/slack v0.9.5 h1:j7uOUDowybWf9eSgZg/AbGx6J1OPJB6SE8Z5dNl6Mtw=\n+github.com/slack-go/slack v0.9.5/go.mod h1:wWL//kk0ho+FcQXcBTmEafUI5dz4qz5f4mMk8oIkioQ=\n github.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\n github.com/smartystreets/goconvey v1.6.4/go.mod h1:syvi0/a8iFYH4r/RixwvyeAJjdLS9QV7WQ/tjFTllLA=\n github.com/spf13/cobra v0.0.3/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=\n@@ -364,6 +359,7 @@ github.com/yudai/pp v2.0.1+incompatible/go.mod h1:PuxR/8QJ7cyCkFp/aUDS+JY727OFEZ\n github.com/yuin/goldmark v1.1.25/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n github.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n github.com/yuin/goldmark v1.1.32/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\n+github.com/yuin/goldmark v1.3.5/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\n github.com/yuin/gopher-lua v0.0.0-20191220021717-ab39c6098bdb h1:ZkM6LRnq40pR1Ox0hTHlnpkcOTuFIDQpZ1IN8rKKhX0=\n github.com/yuin/gopher-lua v0.0.0-20191220021717-ab39c6098bdb/go.mod h1:gqRgreBUhTSL0GeU64rtZ3Uq3wtjOa/TB2YfrtkCbVQ=\n go.etcd.io/bbolt v1.3.5/go.mod h1:G5EMThwa9y8QZGBClrRx5EY+Yw9kAhnjy3bSjsnlVTQ=\n@@ -376,8 +372,8 @@ go.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\n go.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n go.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n go.opencensus.io v0.22.4/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\n-go.uber.org/goleak v1.1.10 h1:z+mqJhf6ss6BSfSM671tgKyZBFPTTJM+HLxnhPC3wu0=\n-go.uber.org/goleak v1.1.10/go.mod h1:8a7PlsEVH3e/a/GLqe5IIrQx6GzcnRmZEufDUTk4A7A=\n+go.uber.org/goleak v1.1.12 h1:gZAh5/EyT/HQwlpkCy6wTpqfH9H8Lz8zbm3dZh+OyzA=\n+go.uber.org/goleak v1.1.12/go.mod h1:cwTWslyiVhfpKIDGSZEM2HlOvcqm+tG4zioyIeLoqMQ=\n golang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\n golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\n golang.org/x/crypto v0.0.0-20190422162423-af44ce270edf/go.mod h1:WFFai1msRO1wXaEeE5yQxYXgSfI8pQAWXbQop6sCtWE=\n@@ -386,8 +382,8 @@ golang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8U\n golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\n golang.org/x/crypto v0.0.0-20200302210943-78000ba7a073/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\n golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\n-golang.org/x/crypto v0.0.0-20210817164053-32db794688a5 h1:HWj/xjIHfjYU5nVXpTM0s39J9CbLn7Cc5a7IC5rwsMQ=\n-golang.org/x/crypto v0.0.0-20210817164053-32db794688a5/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\n+golang.org/x/crypto v0.0.0-20210921155107-089bfa567519 h1:7I4JAnoQBe7ZtJcBaYHi5UtiO8tQHbUSXxL+pnGRANg=\n+golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\n golang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\n@@ -401,8 +397,8 @@ golang.org/x/exp v0.0.0-20200224162631-6cc2880d07d6/go.mod h1:3jZMyOhIsHpP37uCMk\n golang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\n golang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\n golang.org/x/image v0.0.0-20210504121937-7319ad40d33e/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\n-golang.org/x/image v0.0.0-20210628002857-a66eb6448b8d h1:RNPAfi2nHY7C2srAV8A49jpsYr0ADedCk1wq6fTMTvs=\n-golang.org/x/image v0.0.0-20210628002857-a66eb6448b8d/go.mod h1:023OzeP/+EPmXeapQh35lcL3II3LrY8Ic+EFFKVhULM=\n+golang.org/x/image v0.0.0-20211028202545-6944b10bf410 h1:hTftEOvwiOq2+O8k2D5/Q7COC7k5Qcrgc2TFURJYnvQ=\n+golang.org/x/image v0.0.0-20211028202545-6944b10bf410/go.mod h1:023OzeP/+EPmXeapQh35lcL3II3LrY8Ic+EFFKVhULM=\n golang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\n golang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\n golang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\n@@ -422,7 +418,7 @@ golang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzB\n golang.org/x/mod v0.1.1-0.20191107180719-034126e5016b/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\n golang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n golang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n-golang.org/x/net v0.0.0-20180218175443-cbe0f9307d01/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n+golang.org/x/mod v0.4.2/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n golang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n golang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n golang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n@@ -453,8 +449,10 @@ golang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81R\n golang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\n golang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\n golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\n-golang.org/x/net v0.0.0-20210614182718-04defd469f4e h1:XpT3nA5TvE525Ne3hInMh6+GETgn27Zfm9dxsThnX2Q=\n+golang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\n golang.org/x/net v0.0.0-20210614182718-04defd469f4e/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8 h1:/6y1LfuqNuQdHAm0jjtPtgRcxIxjVZgm5OTu8/QhZvk=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\n golang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\n golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\n@@ -470,8 +468,9 @@ golang.org/x/sync v0.0.0-20190412183630-56d357773e84/go.mod h1:RxMgew5VJxzue5/jJ\n golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n-golang.org/x/sync v0.0.0-20200625203802-6e8e738ad208 h1:qwRHBd0NqMbJxfbotnDhm2ByMI1Shq4Y6oRJo21SGJA=\n golang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n+golang.org/x/sync v0.0.0-20210220032951-036812b2e83c h1:5KslGYwFpkhGh+Q16bwMP3cOontH8FOep7tGV86Y7SQ=\n+golang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n golang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n@@ -510,7 +509,9 @@ golang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7w\n golang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20200923182605-d9f96fdee20d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1 h1:SrN+KX8Art/Sf4HNj6Zcz06G7VEz+7w9tdXTPOZ7+l4=\n golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\n@@ -547,7 +548,6 @@ golang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgw\n golang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n-golang.org/x/tools v0.0.0-20191108193012-7d206e10da11/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n@@ -572,8 +572,9 @@ golang.org/x/tools v0.0.0-20200515010526-7d3b6ebf133d/go.mod h1:EkVYQZoAsY45+roY\n golang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\n golang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n golang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n-golang.org/x/tools v0.0.0-20200825202427-b303f430e36d h1:W07d4xkoAUSNOkOzdzXCdFGxT7o2rW4q8M34tB2i//k=\n golang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\n+golang.org/x/tools v0.1.5 h1:ouewzE6p+/VEB31YYnTbEJdi8pFqKp4P4n85vwo3DHA=\n+golang.org/x/tools v0.1.5/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\n golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0="
    },
    {
      "sha": "8430c86a2a505815865340e25f933dd4d709318f",
      "filename": "backend/vendor/github.com/PuerkitoBio/goquery/.travis.yml",
      "status": "removed",
      "additions": 0,
      "deletions": 31,
      "changes": 31,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/PuerkitoBio/goquery/.travis.yml",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/PuerkitoBio/goquery/.travis.yml",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/PuerkitoBio/goquery/.travis.yml?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,31 +0,0 @@\n-arch:\n-    - amd64\n-    - ppc64le\n-language: go\n-\n-go:\n-    - 1.7.x\n-    - 1.8.x\n-    - 1.9.x\n-    - 1.10.x\n-    - 1.11.x\n-    - 1.12.x\n-    - 1.13.x\n-    - 1.14.x\n-    - 1.15.x\n-    - tip\n-\n-jobs:\n- exclude:\n-    - arch: ppc64le\n-      go: 1.7.x\n-    - arch: ppc64le\n-      go: 1.8.x\n-    - arch: ppc64le\n-      go: 1.9.x\n-    - arch: ppc64le\n-      go: 1.10.x\n-    - arch: ppc64le\n-      go: 1.11.x\n-    - arch: ppc64le\n-      go: 1.12.x"
    },
    {
      "sha": "775223401dd38af858ef7184ed4b0994cce0dab4",
      "filename": "backend/vendor/github.com/PuerkitoBio/goquery/README.md",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/PuerkitoBio/goquery/README.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,7 +1,6 @@\n # goquery - a little like that j-thing, only in Go\n \n-[![builds.sr.ht status](https://builds.sr.ht/~mna/goquery/commits/fedora.yml.svg)](https://builds.sr.ht/~mna/goquery/commits/fedora.yml?)\n-[![build status](https://secure.travis-ci.org/PuerkitoBio/goquery.svg?branch=master)](http://travis-ci.org/PuerkitoBio/goquery)\n+[![Build Status](https://github.com/PuerkitoBio/goquery/actions/workflows/test.yml/badge.svg?branch=master)](https://github.com/PuerkitoBio/goquery/actions)\n [![Go Reference](https://pkg.go.dev/badge/github.com/PuerkitoBio/goquery.svg)](https://pkg.go.dev/github.com/PuerkitoBio/goquery)\n [![Sourcegraph Badge](https://sourcegraph.com/github.com/PuerkitoBio/goquery/-/badge.svg)](https://sourcegraph.com/github.com/PuerkitoBio/goquery?badge)\n \n@@ -41,6 +40,7 @@ Please note that because of the net/html dependency, goquery requires Go1.1+ and\n \n **Note that goquery's API is now stable, and will not break.**\n \n+*    **2021-10-25 (v1.8.0)** : Add `Render` function to render a `Selection` to an `io.Writer` (thanks [@anthonygedeon](https://github.com/anthonygedeon)).\n *    **2021-07-11 (v1.7.1)** : Update go.mod dependencies and add dependabot config (thanks [@jauderho](https://github.com/jauderho)).\n *    **2021-06-14 (v1.7.0)** : Add `Single` and `SingleMatcher` functions to optimize first-match selection (thanks [@gdollardollar](https://github.com/gdollardollar)).\n *    **2021-01-11 (v1.6.1)** : Fix panic when calling `{Prepend,Append,Set}Html` on a `Selection` that contains non-Element nodes."
    },
    {
      "sha": "4b5a30963a39fdcf6e9afd73fbf298801340fa81",
      "filename": "backend/vendor/github.com/PuerkitoBio/goquery/go.mod",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/PuerkitoBio/goquery/go.mod?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,8 +1,8 @@\n module github.com/PuerkitoBio/goquery\n \n require (\n-\tgithub.com/andybalholm/cascadia v1.2.0\n-\tgolang.org/x/net v0.0.0-20210614182718-04defd469f4e\n+\tgithub.com/andybalholm/cascadia v1.3.1\n+\tgolang.org/x/net v0.0.0-20210916014120-12bc252f5db8\n )\n \n go 1.13"
    },
    {
      "sha": "167f12d2db63d97a0dbb16fead68d9478eea6378",
      "filename": "backend/vendor/github.com/PuerkitoBio/goquery/go.sum",
      "status": "modified",
      "additions": 4,
      "deletions": 5,
      "changes": 9,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/PuerkitoBio/goquery/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,8 +1,7 @@\n-github.com/andybalholm/cascadia v1.2.0 h1:vuRCkM5Ozh/BfmsaTm26kbjm0mIOM3yS5Ek/F5h18aE=\n-github.com/andybalholm/cascadia v1.2.0/go.mod h1:YCyR8vOZT9aZ1CHEd8ap0gMVm2aFgxBp0T0eFw1RUQY=\n-golang.org/x/net v0.0.0-20180218175443-cbe0f9307d01/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\n-golang.org/x/net v0.0.0-20210614182718-04defd469f4e h1:XpT3nA5TvE525Ne3hInMh6+GETgn27Zfm9dxsThnX2Q=\n-golang.org/x/net v0.0.0-20210614182718-04defd469f4e/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n+github.com/andybalholm/cascadia v1.3.1 h1:nhxRkql1kdYCc8Snf7D5/D3spOX+dBgjA6u8x004T2c=\n+github.com/andybalholm/cascadia v1.3.1/go.mod h1:R4bJ1UQfqADjvDa4P6HZHLh/3OxWWEqc0Sk8XGwHqvA=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8 h1:/6y1LfuqNuQdHAm0jjtPtgRcxIxjVZgm5OTu8/QhZvk=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo="
    },
    {
      "sha": "6d243cdd63ad55f3fbb728d864fe9e6a5eaf8a02",
      "filename": "backend/vendor/github.com/PuerkitoBio/goquery/utilities.go",
      "status": "modified",
      "additions": 14,
      "deletions": 7,
      "changes": 21,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/utilities.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/PuerkitoBio/goquery/utilities.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/PuerkitoBio/goquery/utilities.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -2,6 +2,7 @@ package goquery\n \n import (\n \t\"bytes\"\n+\t\"io\"\n \n \t\"golang.org/x/net/html\"\n )\n@@ -50,13 +51,24 @@ func nodeName(node *html.Node) string {\n \tcase html.ElementNode, html.DoctypeNode:\n \t\treturn node.Data\n \tdefault:\n-\t\tif node.Type >= 0 && int(node.Type) < len(nodeNames) {\n+\t\tif int(node.Type) < len(nodeNames) {\n \t\t\treturn nodeNames[node.Type]\n \t\t}\n \t\treturn \"\"\n \t}\n }\n \n+// Render renders the html of the first element from selector and writes it to\n+// the writer.  It behaves the same as OuterHtml but writes to w instead of\n+// returning the string.\n+func Render(w io.Writer, s *Selection) error {\n+\tif s.Length() == 0 {\n+\t\treturn nil\n+\t}\n+\tn := s.Get(0)\n+\treturn html.Render(w, n)\n+}\n+\n // OuterHtml returns the outer HTML rendering of the first item in\n // the selection - that is, the HTML including the first element's\n // tag and attributes.\n@@ -66,12 +78,7 @@ func nodeName(node *html.Node) string {\n // a property provided by the DOM).\n func OuterHtml(s *Selection) (string, error) {\n \tvar buf bytes.Buffer\n-\n-\tif s.Length() == 0 {\n-\t\treturn \"\", nil\n-\t}\n-\tn := s.Get(0)\n-\tif err := html.Render(&buf, n); err != nil {\n+\tif err := Render(&buf, s); err != nil {\n \t\treturn \"\", err\n \t}\n \treturn buf.String(), nil"
    },
    {
      "sha": "8cd7592d3fb73c2c30c6267c809cde66480b7717",
      "filename": "backend/vendor/github.com/alecthomas/chroma/.goreleaser.yml",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/.goreleaser.yml",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/.goreleaser.yml",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/.goreleaser.yml?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -14,11 +14,13 @@ builds:\n     - darwin\n     - windows\n   goarch:\n+    - arm64\n     - amd64\n     - \"386\"\n   goarm:\n     - \"6\"\n-  main: ./cmd/chroma/main.go\n+  dir: ./cmd/chroma\n+  main: .\n   ldflags: -s -w -X main.version={{.Version}} -X main.commit={{.Commit}} -X main.date={{.Date}}\n   binary: chroma\n archives:"
    },
    {
      "sha": "7786fe1f7004f51e87909c62095cb954908f02db",
      "filename": "backend/vendor/github.com/alecthomas/chroma/README.md",
      "status": "modified",
      "additions": 5,
      "deletions": 6,
      "changes": 11,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/README.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,4 +1,5 @@\n-# Chroma  A general purpose syntax highlighter in pure Go [![Golang Documentation](https://godoc.org/github.com/alecthomas/chroma?status.svg)](https://godoc.org/github.com/alecthomas/chroma) [![CircleCI](https://img.shields.io/circleci/project/github/alecthomas/chroma.svg)](https://circleci.com/gh/alecthomas/chroma) [![Go Report Card](https://goreportcard.com/badge/github.com/alecthomas/chroma)](https://goreportcard.com/report/github.com/alecthomas/chroma) [![Slack chat](https://img.shields.io/static/v1?logo=slack&style=flat&label=slack&color=green&message=gophers)](https://invite.slack.golangbridge.org/)\n+# Chroma  A general purpose syntax highlighter in pure Go\n+[![Golang Documentation](https://godoc.org/github.com/alecthomas/chroma?status.svg)](https://godoc.org/github.com/alecthomas/chroma) [![CI](https://github.com/alecthomas/chroma/actions/workflows/ci.yml/badge.svg)](https://github.com/alecthomas/chroma/actions/workflows/ci.yml) [![Slack chat](https://img.shields.io/static/v1?logo=slack&style=flat&label=slack&color=green&message=gophers)](https://invite.slack.golangbridge.org/)\n \n > **NOTE:** As Chroma has just been released, its API is still in flux. That said, the high-level interface should not change significantly.\n \n@@ -49,7 +50,7 @@ K | Kotlin\n L | Lighttpd configuration file, LLVM, Lua\n M | Mako, markdown, Mason, Mathematica, Matlab, MiniZinc, MLIR, Modula-2, MonkeyC, MorrowindScript, Myghty, MySQL\n N | NASM, Newspeak, Nginx configuration file, Nim, Nix\n-O | Objective-C, OCaml, Octave, OpenSCAD, Org Mode\n+O | Objective-C, OCaml, Octave, OnesEnterprise, OpenSCAD, Org Mode\n P | PacmanConf, Perl, PHP, PHTML, Pig, PkgConfig, PL/pgSQL, plaintext, Pony, PostgreSQL SQL dialect, PostScript, POVRay, PowerShell, Prolog, PromQL, Protocol Buffer, Puppet, Python 2, Python\n Q | QBasic\n R | R, Racket, Ragel, Raku, react, ReasonML, reg, reStructuredText, Rexx, Ruby, Rust\n@@ -249,11 +250,9 @@ For a quick overview of the available styles and how they look, check out the [C\n <a id=\"markdown-command-line-interface\" name=\"command-line-interface\"></a>\n ## Command-line interface\n \n-A command-line interface to Chroma is included. It can be installed with:\n+A command-line interface to Chroma is included.\n \n-```sh\n-go get -u github.com/alecthomas/chroma/cmd/chroma\n-```\n+Binaries are available to install from [the releases page](https://github.com/alecthomas/chroma/releases).\n \n The CLI can be used as a preprocessor to colorise output of `less(1)`,\n see documentation for the `LESSOPEN` environment variable."
    },
    {
      "sha": "c406562f2d03bd52fd6cd0b5660abe63521356e3",
      "filename": "backend/vendor/github.com/alecthomas/chroma/go.mod",
      "status": "modified",
      "additions": 2,
      "deletions": 11,
      "changes": 13,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/go.mod?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -3,16 +3,7 @@ module github.com/alecthomas/chroma\n go 1.13\n \n require (\n-\tgithub.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38\n-\tgithub.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721 // indirect\n-\tgithub.com/alecthomas/kong v0.2.4\n-\tgithub.com/alecthomas/repr v0.0.0-20180818092828-117648cd9897 // indirect\n-\tgithub.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964\n+\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n \tgithub.com/dlclark/regexp2 v1.4.0\n-\tgithub.com/mattn/go-colorable v0.1.6\n-\tgithub.com/mattn/go-isatty v0.0.12\n-\tgithub.com/pkg/errors v0.9.1 // indirect\n-\tgithub.com/sergi/go-diff v1.0.0 // indirect\n-\tgithub.com/stretchr/testify v1.3.0 // indirect\n-\tgolang.org/x/sys v0.0.0-20200413165638-669c56c373c4 // indirect\n+\tgithub.com/stretchr/testify v1.7.0\n )"
    },
    {
      "sha": "734f796c89d22a1c94af0b040a862d2f092f89d3",
      "filename": "backend/vendor/github.com/alecthomas/chroma/go.sum",
      "status": "modified",
      "additions": 6,
      "deletions": 26,
      "changes": 32,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,34 +1,14 @@\n-github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38 h1:smF2tmSOzy2Mm+0dGI2AIUHY+w0BUc+4tn40djz7+6U=\n-github.com/alecthomas/assert v0.0.0-20170929043011-405dbfeb8e38/go.mod h1:r7bzyVFMNntcxPZXK3/+KdruV1H5KSlyVY0gc+NgInI=\n-github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721 h1:JHZL0hZKJ1VENNfmXvHbgYlbUOvpzYzvy2aZU5gXVeo=\n-github.com/alecthomas/colour v0.0.0-20160524082231-60882d9e2721/go.mod h1:QO9JBoKquHd+jz9nshCh40fOfO+JzsoXy8qTHF68zU0=\n-github.com/alecthomas/kong v0.2.4 h1:Y0ZBCHAvHhTHw7FFJ2FzCAAG4pkbTgA45nc7BpMhDNk=\n-github.com/alecthomas/kong v0.2.4/go.mod h1:kQOmtJgV+Lb4aj+I2LEn40cbtawdWJ9Y8QLq+lElKxE=\n-github.com/alecthomas/repr v0.0.0-20180818092828-117648cd9897 h1:p9Sln00KOTlrYkxI1zYWl1QLnEqAqEARBEYa8FQnQcY=\n-github.com/alecthomas/repr v0.0.0-20180818092828-117648cd9897/go.mod h1:xTS7Pm1pD1mvyM075QCDSRqH6qRLXylzS24ZTpRiSzQ=\n-github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964 h1:y5HC9v93H5EPKqaS1UYVg1uYah5Xf51mBfIoWehClUQ=\n-github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964/go.mod h1:Xd9hchkHSWYkEqJwUGisez3G1QY8Ryz0sdWrLPMGjLk=\n github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\n github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\n github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\n github.com/dlclark/regexp2 v1.4.0 h1:F1rxgk7p4uKjwIQxBs9oAXe5CqrXlCduYEJvrF4u93E=\n github.com/dlclark/regexp2 v1.4.0/go.mod h1:2pZnwuY/m+8K6iRw6wQdMtk+rH5tNGR1i55kozfMjCc=\n-github.com/mattn/go-colorable v0.1.6 h1:6Su7aK7lXmJ/U79bYtBjLNaha4Fs1Rg9plHpcH+vvnE=\n-github.com/mattn/go-colorable v0.1.6/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\n-github.com/mattn/go-isatty v0.0.12 h1:wuysRhFDzyxgEmMf5xjvJ2M9dZoWAXNNr5LSBS7uHXY=\n-github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\n-github.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\n-github.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\n-github.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\n github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\n github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\n-github.com/sergi/go-diff v1.0.0 h1:Kpca3qRNrduNnOQeazBd0ysaKrUJiIuISHxogkT9RPQ=\n-github.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=\n github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\n-github.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\n-github.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=\n-github.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\n-golang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n-golang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n-golang.org/x/sys v0.0.0-20200413165638-669c56c373c4 h1:opSr2sbRXk5X5/givKrrKj9HXxFpW2sdCiP8MJSKLQY=\n-golang.org/x/sys v0.0.0-20200413165638-669c56c373c4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+github.com/stretchr/testify v1.7.0 h1:nwc3DEeHmmLAfoZucVR881uASk0Mfjw8xYJ99tb5CcY=\n+github.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\n+gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\n+gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\n+gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c h1:dUUwHk2QECo/6vqA44rthZ8ie2QXMNeKRTHCNY2nXvo=\n+gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM="
    },
    {
      "sha": "4055f3651eba2792528cc6accf67418bc74fff73",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/a/al.go",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/al.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/al.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/a/al.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -30,13 +30,12 @@ func alRules() Rules {\n \t\t\t{`\\b(?i:(ARRAY|ASSERTERROR|BEGIN|BREAK|CASE|DO|DOWNTO|ELSE|END|EVENT|EXIT|FOR|FOREACH|FUNCTION|IF|IMPLEMENTS|IN|INDATASET|INTERFACE|INTERNAL|LOCAL|OF|PROCEDURE|PROGRAM|PROTECTED|REPEAT|RUNONCLIENT|SECURITYFILTERING|SUPPRESSDISPOSE|TEMPORARY|THEN|TO|TRIGGER|UNTIL|VAR|WHILE|WITH|WITHEVENTS))\\b`, Keyword, nil},\n \t\t\t{`\\b(?i:(AND|DIV|MOD|NOT|OR|XOR))\\b`, OperatorWord, nil},\n \t\t\t{`\\b(?i:(AVERAGE|CONST|COUNT|EXIST|FIELD|FILTER|LOOKUP|MAX|MIN|ORDER|SORTING|SUM|TABLEDATA|UPPERLIMIT|WHERE|ASCENDING|DESCENDING))\\b`, Keyword, nil},\n-\t\t\t// Added new objects types of BC 2021 wave 1 (REPORTEXTENSION|Entitlement|PermissionSet|PermissionSetExtension)\n-\t\t\t{`\\b(?i:(CODEUNIT|PAGE|PAGEEXTENSION|PAGECUSTOMIZATION|DOTNET|ENUM|ENUMEXTENSION|VALUE|QUERY|REPORT|TABLE|TABLEEXTENSION|XMLPORT|PROFILE|CONTROLADDIN|REPORTEXTENSION|Entitlement|PermissionSet|PermissionSetExtension))\\b`, Keyword, nil},\n+\t\t\t{`\\b(?i:(CODEUNIT|PAGE|PAGEEXTENSION|PAGECUSTOMIZATION|DOTNET|ENUM|ENUMEXTENSION|VALUE|QUERY|REPORT|TABLE|TABLEEXTENSION|XMLPORT|PROFILE|CONTROLADDIN|REPORTEXTENSION|INTERFACE|PERMISSIONSET|PERMISSIONSETEXTENSION|ENTITLEMENT))\\b`, Keyword, nil},\n \t\t\t{`\\b(?i:(Action|Array|Automation|BigInteger|BigText|Blob|Boolean|Byte|Char|ClientType|Code|Codeunit|CompletionTriggerErrorLevel|ConnectionType|Database|DataClassification|DataScope|Date|DateFormula|DateTime|Decimal|DefaultLayout|Dialog|Dictionary|DotNet|DotNetAssembly|DotNetTypeDeclaration|Duration|Enum|ErrorInfo|ErrorType|ExecutionContext|ExecutionMode|FieldClass|FieldRef|FieldType|File|FilterPageBuilder|Guid|InStream|Integer|Joker|KeyRef|List|ModuleDependencyInfo|ModuleInfo|None|Notification|NotificationScope|ObjectType|Option|OutStream|Page|PageResult|Query|Record|RecordId|RecordRef|Report|ReportFormat|SecurityFilter|SecurityFiltering|Table|TableConnectionType|TableFilter|TestAction|TestField|TestFilterField|TestPage|TestPermissions|TestRequestPage|Text|TextBuilder|TextConst|TextEncoding|Time|TransactionModel|TransactionType|Variant|Verbosity|Version|XmlPort|HttpContent|HttpHeaders|HttpClient|HttpRequestMessage|HttpResponseMessage|JsonToken|JsonValue|JsonArray|JsonObject|View|Views|XmlAttribute|XmlAttributeCollection|XmlComment|XmlCData|XmlDeclaration|XmlDocument|XmlDocumentType|XmlElement|XmlNamespaceManager|XmlNameTable|XmlNode|XmlNodeList|XmlProcessingInstruction|XmlReadOptions|XmlText|XmlWriteOptions|WebServiceActionContext|WebServiceActionResultCode|SessionSettings))\\b`, Keyword, nil},\n \t\t\t{`\\b([<>]=|<>|<|>)\\b?`, Operator, nil},\n \t\t\t{`\\b(\\-|\\+|\\/|\\*)\\b`, Operator, nil},\n \t\t\t{`\\s*(\\:=|\\+=|-=|\\/=|\\*=)\\s*?`, Operator, nil},\n-\t\t\t{`\\b(?i:(ADDFIRST|ADDLAST|ADDAFTER|ADDBEFORE|ACTION|ACTIONS|AREA|ASSEMBLY|CHARTPART|CUEGROUP|CUSTOMIZES|COLUMN|DATAITEM|DATASET|ELEMENTS|EXTENDS|FIELD|FIELDGROUP|FIELDATTRIBUTE|FIELDELEMENT|FIELDGROUPS|FIELDS|FILTER|FIXED|GRID|GROUP|MOVEAFTER|MOVEBEFORE|KEY|KEYS|LABEL|LABELS|LAYOUT|MODIFY|MOVEFIRST|MOVELAST|MOVEBEFORE|MOVEAFTER|PART|REPEATER|USERCONTROL|REQUESTPAGE|SCHEMA|SEPARATOR|SYSTEMPART|TABLEELEMENT|TEXTATTRIBUTE|TEXTELEMENT|TYPE))\\b`, Keyword, nil},\n+\t\t\t{`\\b(?i:(ADD|ADDFIRST|ADDLAST|ADDAFTER|ADDBEFORE|ACTION|ACTIONS|AREA|ASSEMBLY|CHARTPART|CUEGROUP|CUSTOMIZES|COLUMN|DATAITEM|DATASET|ELEMENTS|EXTENDS|FIELD|FIELDGROUP|FIELDATTRIBUTE|FIELDELEMENT|FIELDGROUPS|FIELDS|FILTER|FIXED|GRID|GROUP|MOVEAFTER|MOVEBEFORE|KEY|KEYS|LABEL|LABELS|LAYOUT|MODIFY|MOVEFIRST|MOVELAST|MOVEBEFORE|MOVEAFTER|PART|REPEATER|USERCONTROL|REQUESTPAGE|SCHEMA|SEPARATOR|SYSTEMPART|TABLEELEMENT|TEXTATTRIBUTE|TEXTELEMENT|TYPE))\\b`, Keyword, nil},\n \t\t\t{`\\s*[(\\.\\.)&\\|]\\s*`, Operator, nil},\n \t\t\t{`\\b((0(x|X)[0-9a-fA-F]*)|(([0-9]+\\.?[0-9]*)|(\\.[0-9]+))((e|E)(\\+|-)?[0-9]+)?)(L|l|UL|ul|u|U|F|f|ll|LL|ull|ULL)?\\b`, LiteralNumber, nil},\n \t\t\t{`[;:,]`, Punctuation, nil},"
    },
    {
      "sha": "f929d2e2b17aaf494ba572e20c743f2744228aaf",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/a/apl.go",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/apl.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/apl.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/a/apl.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -26,10 +26,10 @@ func aplRules() Rules {\n \t\t\t{`[()]`, Punctuation, nil},\n \t\t\t{`[\\[\\];]`, LiteralStringRegex, nil},\n \t\t\t{`[A-Za-z][A-Za-z_0-9]*`, NameFunction, nil},\n-\t\t\t{`[A-Za-z][A-Za-z_0-9]*`, NameVariable, nil},\n+\t\t\t{`[A-Za-z_][A-Za-z_0-9]*`, NameVariable, nil},\n \t\t\t{`?(0[Xx][0-9A-Fa-f]+|[0-9]*\\.?[0-9]+([Ee][+]?[0-9]+)?||)([Jj]?(0[Xx][0-9A-Fa-f]+|[0-9]*\\.?[0-9]+([Ee][+]?[0-9]+)?||))?`, LiteralNumber, nil},\n-\t\t\t{`[\\.\\\\/]`, NameAttribute, nil},\n-\t\t\t{`[+\\-|?*!<=>~,]`, Operator, nil},\n+\t\t\t{`[\\.\\\\/@]`, NameAttribute, nil},\n+\t\t\t{`[+\\-|?*!<=>~,]`, Operator, nil},\n \t\t\t{``, NameConstant, nil},\n \t\t\t{`[]`, NameVariableGlobal, nil},\n \t\t\t{`[]`, KeywordDeclaration, nil},"
    },
    {
      "sha": "a2bdceebb4063f048c896b68b954d9c98eba32b0",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/a/armasm.go",
      "status": "added",
      "additions": 72,
      "deletions": 0,
      "changes": 72,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/armasm.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/a/armasm.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/a/armasm.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,72 @@\n+package a\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+var ArmAsm = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:      \"ArmAsm\",\n+\t\tAliases:   []string{\"armasm\"},\n+\t\tEnsureNL:  true,\n+\t\tFilenames: []string{\"*.s\", \"*.S\"},\n+\t\tMimeTypes: []string{\"text/x-armasm\", \"text/x-asm\"},\n+\t},\n+\tarmasmRules,\n+))\n+\n+func armasmRules() Rules {\n+\treturn Rules{\n+\t\t\"commentsandwhitespace\": {\n+\t\t\t{`\\s+`, Text, nil},\n+\t\t\t{`[@;].*?\\n`, CommentSingle, nil},\n+\t\t\t{`/\\*.*?\\*/`, CommentMultiline, nil},\n+\t\t},\n+\t\t\"literal\": {\n+\t\t\t// Binary\n+\t\t\t{`0b[01]+`, NumberBin, Pop(1)},\n+\t\t\t// Hex\n+\t\t\t{`0x\\w{1,8}`, NumberHex, Pop(1)},\n+\t\t\t// Octal\n+\t\t\t{`0\\d+`, NumberOct, Pop(1)},\n+\t\t\t// Float\n+\t\t\t{`\\d+?\\.\\d+?`, NumberFloat, Pop(1)},\n+\t\t\t// Integer\n+\t\t\t{`\\d+`, NumberInteger, Pop(1)},\n+\t\t\t// String\n+\t\t\t{`(\")(.+)(\")`, ByGroups(Punctuation, StringDouble, Punctuation), Pop(1)},\n+\t\t\t// Char\n+\t\t\t{`(')(.{1}|\\\\.{1})(')`, ByGroups(Punctuation, StringChar, Punctuation), Pop(1)},\n+\t\t},\n+\t\t\"opcode\": {\n+\t\t\t// Escape at line end\n+\t\t\t{`\\n`, Text, Pop(1)},\n+\t\t\t// Comment\n+\t\t\t{`(@|;).*\\n`, CommentSingle, Pop(1)},\n+\t\t\t// Whitespace\n+\t\t\t{`(\\s+|,)`, Text, nil},\n+\t\t\t// Register by number\n+\t\t\t{`[rapcfxwbhsdqv]\\d{1,2}`, NameClass, nil},\n+\t\t\t// Address by hex\n+\t\t\t{`=0x\\w+`, ByGroups(Text, NameLabel), nil},\n+\t\t\t// Pseudo address by label\n+\t\t\t{`(=)(\\w+)`, ByGroups(Text, NameLabel), nil},\n+\t\t\t// Immediate\n+\t\t\t{`#`, Text, Push(\"literal\")},\n+\t\t},\n+\t\t\"root\": {\n+\t\t\tInclude(\"commentsandwhitespace\"),\n+\t\t\t// Directive with optional param\n+\t\t\t{`(\\.\\w+)([ \\t]+\\w+\\s+?)?`, ByGroups(KeywordNamespace, NameLabel), nil},\n+\t\t\t// Label with data\n+\t\t\t{`(\\w+)(:)(\\s+\\.\\w+\\s+)`, ByGroups(NameLabel, Punctuation, KeywordNamespace), Push(\"literal\")},\n+\t\t\t// Label\n+\t\t\t{`(\\w+)(:)`, ByGroups(NameLabel, Punctuation), nil},\n+\t\t\t// Syscall Op\n+\t\t\t{`svc\\s+\\w+`, NameNamespace, nil},\n+\t\t\t// Opcode\n+\t\t\t{`[a-zA-Z]+`, Text, Push(\"opcode\")},\n+\t\t},\n+\t}\n+}"
    },
    {
      "sha": "9043fa1cc774e55a3dc240e93df40c4069343f82",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/b/bashsession.go",
      "status": "added",
      "additions": 27,
      "deletions": 0,
      "changes": 27,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/b/bashsession.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/b/bashsession.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/b/bashsession.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,27 @@\n+package b\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+// BashSession lexer.\n+var BashSession = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:      \"BashSession\",\n+\t\tAliases:   []string{\"bash-session\", \"console\", \"shell-session\"},\n+\t\tFilenames: []string{\".sh-session\"},\n+\t\tMimeTypes: []string{\"text/x-sh\"},\n+\t\tEnsureNL:  true,\n+\t},\n+\tbashsessionRules,\n+))\n+\n+func bashsessionRules() Rules {\n+\treturn Rules{\n+\t\t\"root\": {\n+\t\t\t{`(^[#$%>]\\s*)(.*\\n?)`, ByGroups(GenericPrompt, Using(Bash)), nil},\n+\t\t\t{`^.+\\n?`, GenericOutput, nil},\n+\t\t},\n+\t}\n+}"
    },
    {
      "sha": "e4bbc67d94e7816c5fc9f1100c1a009d0b8f4a1c",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/circular/php.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/circular/php.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/circular/php.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/circular/php.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -52,7 +52,7 @@ func phpCommonRules() Rules {\n \t\t\t{`\\d+e[+-]?[0-9]+`, LiteralNumberFloat, nil},\n \t\t\t{`0[0-7]+`, LiteralNumberOct, nil},\n \t\t\t{`0x[a-f0-9_]+`, LiteralNumberHex, nil},\n-\t\t\t{`[\\d_]+`, LiteralNumberInteger, nil},\n+\t\t\t{`\\d[\\d_]*`, LiteralNumberInteger, nil},\n \t\t\t{`0b[01]+`, LiteralNumberBin, nil},\n \t\t\t{`'([^'\\\\]*(?:\\\\.[^'\\\\]*)*)'`, LiteralStringSingle, nil},\n \t\t\t{\"`([^`\\\\\\\\]*(?:\\\\\\\\.[^`\\\\\\\\]*)*)`\", LiteralStringBacktick, nil},"
    },
    {
      "sha": "23134d4ebb2fb32439649dcf36c4dcc2fc8f6eed",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/f/fennel.go",
      "status": "added",
      "additions": 66,
      "deletions": 0,
      "changes": 66,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/f/fennel.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/f/fennel.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/f/fennel.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,66 @@\n+package f\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+// Fennel lexer.\n+var Fennel = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:      \"Fennel\",\n+\t\tAliases:   []string{\"fennel\", \"fnl\"},\n+\t\tFilenames: []string{\"*.fennel\"},\n+\t\tMimeTypes: []string{\"text/x-fennel\", \"application/x-fennel\"},\n+\t},\n+\tfennelRules,\n+))\n+\n+// Here's some Fennel code used to generate the lists of keywords:\n+// (local fennel (require :fennel))\n+//\n+// (fn member? [t x] (each [_ y (ipairs t)] (when (= y x) (lua \"return true\"))))\n+//\n+// (local declarations [:fn :lambda : :local :var :global :macro :macros])\n+// (local keywords [])\n+// (local globals [])\n+//\n+// (each [name data (pairs (fennel.syntax))]\n+//   (if (member? declarations name) nil ; already populated\n+//       data.special? (table.insert keywords name)\n+//       data.macro? (table.insert keywords name)\n+//       data.global? (table.insert globals name)))\n+//\n+// (fn quoted [tbl]\n+//   (table.sort tbl)\n+//   (table.concat (icollect [_ k (ipairs tbl)]\n+//                   (string.format \"`%s`\" k)) \", \"))\n+//\n+// (print :Keyword (quoted keywords))\n+// (print :KeywordDeclaration (quoted declarations))\n+// (print :NameBuiltin (quoted globals))\n+\n+func fennelRules() Rules {\n+\treturn Rules{\n+\t\t\"root\": {\n+\t\t\t{`;.*$`, CommentSingle, nil},\n+\t\t\t{`\\s+`, Whitespace, nil},\n+\t\t\t{`-?\\d+\\.\\d+`, LiteralNumberFloat, nil},\n+\t\t\t{`-?\\d+`, LiteralNumberInteger, nil},\n+\t\t\t{`0x-?[abcdef\\d]+`, LiteralNumberHex, nil},\n+\t\t\t{`\"(\\\\\\\\|\\\\\"|[^\"])*\"`, LiteralString, nil},\n+\t\t\t{`'(?!#)[\\w!$%*+<=>?/.#-]+`, LiteralStringSymbol, nil},\n+\t\t\t{`\\\\(.|[a-z]+)`, LiteralStringChar, nil},\n+\t\t\t{`::?#?(?!#)[\\w!$%*+<=>?/.#-]+`, LiteralStringSymbol, nil},\n+\t\t\t{\"~@|[`\\\\'#^~&@]\", Operator, nil},\n+\t\t\t{Words(``, ` `, `#`, `%`, `*`, `+`, `-`, `->`, `->>`, `-?>`, `-?>>`, `.`, `..`, `/`, `//`, `:`, `<`, `<=`, `=`, `>`, `>=`, `?.`, `^`, `accumulate`, `and`, `band`, `bnot`, `bor`, `bxor`, `collect`, `comment`, `do`, `doc`, `doto`, `each`, `eval-compiler`, `for`, `hashfn`, `icollect`, `if`, `import-macros`, `include`, `length`, `let`, `lshift`, `lua`, `macrodebug`, `match`, `not`, `not=`, `or`, `partial`, `pick-args`, `pick-values`, `quote`, `require-macros`, `rshift`, `set`, `set-forcibly!`, `tset`, `values`, `when`, `while`, `with-open`, `~=`), Keyword, nil},\n+\t\t\t{Words(``, ` `, `fn`, `global`, `lambda`, `local`, `macro`, `macros`, `var`, ``), KeywordDeclaration, nil},\n+\t\t\t{Words(``, ` `, `_G`, `arg`, `assert`, `bit32`, `bit32.arshift`, `bit32.band`, `bit32.bnot`, `bit32.bor`, `bit32.btest`, `bit32.bxor`, `bit32.extract`, `bit32.lrotate`, `bit32.lshift`, `bit32.replace`, `bit32.rrotate`, `bit32.rshift`, `collectgarbage`, `coroutine`, `coroutine.create`, `coroutine.resume`, `coroutine.running`, `coroutine.status`, `coroutine.wrap`, `coroutine.yield`, `debug`, `debug.debug`, `debug.gethook`, `debug.getinfo`, `debug.getlocal`, `debug.getmetatable`, `debug.getregistry`, `debug.getupvalue`, `debug.getuservalue`, `debug.sethook`, `debug.setlocal`, `debug.setmetatable`, `debug.setupvalue`, `debug.setuservalue`, `debug.traceback`, `debug.upvalueid`, `debug.upvaluejoin`, `dofile`, `error`, `getmetatable`, `io`, `io.close`, `io.flush`, `io.input`, `io.lines`, `io.open`, `io.output`, `io.popen`, `io.read`, `io.tmpfile`, `io.type`, `io.write`, `ipairs`, `load`, `loadfile`, `loadstring`, `math`, `math.abs`, `math.acos`, `math.asin`, `math.atan`, `math.atan2`, `math.ceil`, `math.cos`, `math.cosh`, `math.deg`, `math.exp`, `math.floor`, `math.fmod`, `math.frexp`, `math.ldexp`, `math.log`, `math.log10`, `math.max`, `math.min`, `math.modf`, `math.pow`, `math.rad`, `math.random`, `math.randomseed`, `math.sin`, `math.sinh`, `math.sqrt`, `math.tan`, `math.tanh`, `module`, `next`, `os`, `os.clock`, `os.date`, `os.difftime`, `os.execute`, `os.exit`, `os.getenv`, `os.remove`, `os.rename`, `os.setlocale`, `os.time`, `os.tmpname`, `package`, `package.loadlib`, `package.searchpath`, `package.seeall`, `pairs`, `pcall`, `print`, `rawequal`, `rawget`, `rawlen`, `rawset`, `require`, `select`, `setmetatable`, `string`, `string.byte`, `string.char`, `string.dump`, `string.find`, `string.format`, `string.gmatch`, `string.gsub`, `string.len`, `string.lower`, `string.match`, `string.rep`, `string.reverse`, `string.sub`, `string.upper`, `table`, `table.concat`, `table.insert`, `table.maxn`, `table.pack`, `table.remove`, `table.sort`, `table.unpack`, `tonumber`, `tostring`, `type`, `unpack`, `xpcall`), NameBuiltin, nil},\n+\t\t\t{`(?<=\\()(?!#)[\\w!$%*+<=>?/.#-]+`, NameFunction, nil},\n+\t\t\t{`(?!#)[\\w!$%*+<=>?/.#-]+`, NameVariable, nil},\n+\t\t\t{`(\\[|\\])`, Punctuation, nil},\n+\t\t\t{`(\\{|\\})`, Punctuation, nil},\n+\t\t\t{`(\\(|\\))`, Punctuation, nil},\n+\t\t},\n+\t}\n+}"
    },
    {
      "sha": "29d5028d5dc57680be5d45668ccc6f96b42a03c2",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/f/fish.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/f/fish.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/f/fish.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/f/fish.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -74,7 +74,7 @@ func fishRules() Rules {\n \t\t\t{`&&|\\|\\||&|\\||\\^|<|>`, Operator, nil},\n \t\t\t{`\\s+`, Text, nil},\n \t\t\t{`\\b\\d+\\b`, LiteralNumber, nil},\n-\t\t\t{`--?[^\\d][\\w-]*`, NameAttribute, nil},\n+\t\t\t{`(?<=\\s+)--?[^\\d][\\w-]*`, NameAttribute, nil},\n \t\t\t{\".+?\", Text, nil},\n \t\t},\n \t\t\"string\": {"
    },
    {
      "sha": "9dc4075bfeb7a4b8ce893f12f363e8afae2f6fc4",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/g/go.go",
      "status": "modified",
      "additions": 2,
      "deletions": 0,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/g/go.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/g/go.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/g/go.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -50,6 +50,7 @@ func goRules() Rules {\n \t\t\t{`\\.\\d+([eE][+\\-]?\\d+)?`, LiteralNumberFloat, nil},\n \t\t\t{`0[0-7]+`, LiteralNumberOct, nil},\n \t\t\t{`0[xX][0-9a-fA-F_]+`, LiteralNumberHex, nil},\n+\t\t\t{`0b[01_]+`, LiteralNumberBin, nil},\n \t\t\t{`(0|[1-9][0-9_]*)`, LiteralNumberInteger, nil},\n \t\t\t{`'(\\\\['\"\\\\abfnrtv]|\\\\x[0-9a-fA-F]{2}|\\\\[0-7]{1,3}|\\\\u[0-9a-fA-F]{4}|\\\\U[0-9a-fA-F]{8}|[^\\\\])'`, LiteralStringChar, nil},\n \t\t\t{\"(`)([^`]*)(`)\", ByGroups(LiteralString, Using(TypeRemappingLexer(GoTextTemplate, TypeMapping{{Other, LiteralString, nil}})), LiteralString), nil},\n@@ -97,6 +98,7 @@ func goTemplateRules() Rules {\n \t\t\t{`-?\\.\\d+([eE][+\\-]?\\d+)?`, LiteralNumberFloat, nil},\n \t\t\t{`-?0[0-7]+`, LiteralNumberOct, nil},\n \t\t\t{`-?0[xX][0-9a-fA-F]+`, LiteralNumberHex, nil},\n+\t\t\t{`-?0b[01_]+`, LiteralNumberBin, nil},\n \t\t\t{`-?(0|[1-9][0-9]*)`, LiteralNumberInteger, nil},\n \t\t\t{`'(\\\\['\"\\\\abfnrtv]|\\\\x[0-9a-fA-F]{2}|\\\\[0-7]{1,3}|\\\\u[0-9a-fA-F]{4}|\\\\U[0-9a-fA-F]{8}|[^\\\\])'`, LiteralStringChar, nil},\n \t\t\t{\"`[^`]*`\", LiteralString, nil},"
    },
    {
      "sha": "e34f03ef16cda4b0541c15bbb65fa3d86e6d15dd",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/h/haskell.go",
      "status": "modified",
      "additions": 12,
      "deletions": 12,
      "changes": 24,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/h/haskell.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/h/haskell.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/h/haskell.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -27,10 +27,10 @@ func haskellRules() Rules {\n \t\t\t{`\\berror\\b`, NameException, nil},\n \t\t\t{`\\b(case|class|data|default|deriving|do|else|family|if|in|infix[lr]?|instance|let|newtype|of|then|type|where|_)(?!\\')\\b`, KeywordReserved, nil},\n \t\t\t{`'[^\\\\]'`, LiteralStringChar, nil},\n-\t\t\t{`^[_a-z------------------------------------------------------------------------------------------][\\w\\']*`, NameFunction, nil},\n-\t\t\t{`'?[_a-z------------------------------------------------------------------------------------------][\\w']*`, Name, nil},\n-\t\t\t{`('')?[A-Z--------------------------------------------------------------------------------][\\w\\']*`, KeywordType, nil},\n-\t\t\t{`(')[A-Z--------------------------------------------------------------------------------][\\w\\']*`, KeywordType, nil},\n+\t\t\t{`^[_\\p{Ll}][\\w\\']*`, NameFunction, nil},\n+\t\t\t{`'?[_\\p{Ll}][\\w']*`, Name, nil},\n+\t\t\t{`('')?[\\p{Lu}][\\w\\']*`, KeywordType, nil},\n+\t\t\t{`(')[\\p{Lu}][\\w\\']*`, KeywordType, nil},\n \t\t\t{`(')\\[[^\\]]*\\]`, KeywordType, nil},\n \t\t\t{`(')\\([^)]*\\)`, KeywordType, nil},\n \t\t\t{`\\\\(?![:!#$%&*+.\\\\/<=>?@^|~-]+)`, NameFunction, nil},\n@@ -53,20 +53,20 @@ func haskellRules() Rules {\n \t\t\t{`\"`, LiteralString, Push(\"string\")},\n \t\t\t{`\\)`, Punctuation, Pop(1)},\n \t\t\t{`qualified\\b`, Keyword, nil},\n-\t\t\t{`([A-Z--------------------------------------------------------------------------------][\\w.]*)(\\s+)(as)(\\s+)([A-Z--------------------------------------------------------------------------------][\\w.]*)`, ByGroups(NameNamespace, Text, Keyword, Text, Name), Pop(1)},\n-\t\t\t{`([A-Z--------------------------------------------------------------------------------][\\w.]*)(\\s+)(hiding)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Keyword, Text, Punctuation), Push(\"funclist\")},\n-\t\t\t{`([A-Z--------------------------------------------------------------------------------][\\w.]*)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Punctuation), Push(\"funclist\")},\n+\t\t\t{`([\\p{Lu}][\\w.]*)(\\s+)(as)(\\s+)([\\p{Lu}][\\w.]*)`, ByGroups(NameNamespace, Text, Keyword, Text, Name), Pop(1)},\n+\t\t\t{`([\\p{Lu}][\\w.]*)(\\s+)(hiding)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Keyword, Text, Punctuation), Push(\"funclist\")},\n+\t\t\t{`([\\p{Lu}][\\w.]*)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Punctuation), Push(\"funclist\")},\n \t\t\t{`[\\w.]+`, NameNamespace, Pop(1)},\n \t\t},\n \t\t\"module\": {\n \t\t\t{`\\s+`, Text, nil},\n-\t\t\t{`([A-Z--------------------------------------------------------------------------------][\\w.]*)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Punctuation), Push(\"funclist\")},\n-\t\t\t{`[A-Z--------------------------------------------------------------------------------][\\w.]*`, NameNamespace, Pop(1)},\n+\t\t\t{`([\\p{Lu}][\\w.]*)(\\s+)(\\()`, ByGroups(NameNamespace, Text, Punctuation), Push(\"funclist\")},\n+\t\t\t{`[\\p{Lu}][\\w.]*`, NameNamespace, Pop(1)},\n \t\t},\n \t\t\"funclist\": {\n \t\t\t{`\\s+`, Text, nil},\n-\t\t\t{`[A-Z--------------------------------------------------------------------------------]\\w*`, KeywordType, nil},\n-\t\t\t{`(_[\\w\\']+|[a-z------------------------------------------------------------------------------------------][\\w\\']*)`, NameFunction, nil},\n+\t\t\t{`[\\p{Lu}]\\w*`, KeywordType, nil},\n+\t\t\t{`(_[\\w\\']+|[\\p{Ll}][\\w\\']*)`, NameFunction, nil},\n \t\t\t{`--(?![!#$%&*+./<=>?@^|_~:\\\\]).*?$`, CommentSingle, nil},\n \t\t\t{`\\{-`, CommentMultiline, Push(\"comment\")},\n \t\t\t{`,`, Punctuation, nil},\n@@ -92,7 +92,7 @@ func haskellRules() Rules {\n \t\t},\n \t\t\"escape\": {\n \t\t\t{`[abfnrtv\"\\'&\\\\]`, LiteralStringEscape, Pop(1)},\n-\t\t\t{`\\^[][A-Z--------------------------------------------------------------------------------@^_]`, LiteralStringEscape, Pop(1)},\n+\t\t\t{`\\^[][\\p{Lu}@^_]`, LiteralStringEscape, Pop(1)},\n \t\t\t{`NUL|SOH|[SE]TX|EOT|ENQ|ACK|BEL|BS|HT|LF|VT|FF|CR|S[OI]|DLE|DC[1-4]|NAK|SYN|ETB|CAN|EM|SUB|ESC|[FGRU]S|SP|DEL`, LiteralStringEscape, Pop(1)},\n \t\t\t{`o[0-7]+`, LiteralStringEscape, Pop(1)},\n \t\t\t{`x[\\da-fA-F]+`, LiteralStringEscape, Pop(1)},"
    },
    {
      "sha": "12fa45ff84c67d670b432fe6b91fec8cbcdcbbc0",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/internal/api.go",
      "status": "modified",
      "additions": 18,
      "deletions": 8,
      "changes": 26,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/internal/api.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/internal/api.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/internal/api.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -6,17 +6,15 @@ import (\n \t\"sort\"\n \t\"strings\"\n \n-\t\"github.com/danwakefield/fnmatch\"\n-\n \t\"github.com/alecthomas/chroma\"\n )\n \n var (\n \tignoredSuffixes = [...]string{\n \t\t// Editor backups\n \t\t\"~\", \".bak\", \".old\", \".orig\",\n-\t\t// Debian and derivatives apt/dpkg backups\n-\t\t\".dpkg-dist\", \".dpkg-old\",\n+\t\t// Debian and derivatives apt/dpkg/ucf backups\n+\t\t\".dpkg-dist\", \".dpkg-old\", \".ucf-dist\", \".ucf-new\", \".ucf-old\",\n \t\t// Red Hat and derivatives rpm backups\n \t\t\".rpmnew\", \".rpmorig\", \".rpmsave\",\n \t\t// Build system input/template files\n@@ -104,11 +102,17 @@ func Match(filename string) chroma.Lexer {\n \tfor _, lexer := range Registry.Lexers {\n \t\tconfig := lexer.Config()\n \t\tfor _, glob := range config.Filenames {\n-\t\t\tif fnmatch.Match(glob, filename, 0) {\n+\t\t\tok, err := filepath.Match(glob, filename)\n+\t\t\tif err != nil { // nolint\n+\t\t\t\tpanic(err)\n+\t\t\t} else if ok {\n \t\t\t\tmatched = append(matched, lexer)\n \t\t\t} else {\n \t\t\t\tfor _, suf := range &ignoredSuffixes {\n-\t\t\t\t\tif fnmatch.Match(glob+suf, filename, 0) {\n+\t\t\t\t\tok, err := filepath.Match(glob+suf, filename)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\tpanic(err)\n+\t\t\t\t\t} else if ok {\n \t\t\t\t\t\tmatched = append(matched, lexer)\n \t\t\t\t\t\tbreak\n \t\t\t\t\t}\n@@ -125,11 +129,17 @@ func Match(filename string) chroma.Lexer {\n \tfor _, lexer := range Registry.Lexers {\n \t\tconfig := lexer.Config()\n \t\tfor _, glob := range config.AliasFilenames {\n-\t\t\tif fnmatch.Match(glob, filename, 0) {\n+\t\t\tok, err := filepath.Match(glob, filename)\n+\t\t\tif err != nil { // nolint\n+\t\t\t\tpanic(err)\n+\t\t\t} else if ok {\n \t\t\t\tmatched = append(matched, lexer)\n \t\t\t} else {\n \t\t\t\tfor _, suf := range &ignoredSuffixes {\n-\t\t\t\t\tif fnmatch.Match(glob+suf, filename, 0) {\n+\t\t\t\t\tok, err := filepath.Match(glob+suf, filename)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\tpanic(err)\n+\t\t\t\t\t} else if ok {\n \t\t\t\t\t\tmatched = append(matched, lexer)\n \t\t\t\t\t\tbreak\n \t\t\t\t\t}"
    },
    {
      "sha": "5c6b9379418b639bbe2432c432654f524803adfb",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/j/javascript.go",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/javascript.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/javascript.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/j/javascript.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -30,7 +30,7 @@ var JavascriptRules = Rules{\n \t\t{`0[bB][01]+`, LiteralNumberBin, nil},\n \t\t{`0[oO][0-7]+`, LiteralNumberOct, nil},\n \t\t{`0[xX][0-9a-fA-F]+`, LiteralNumberHex, nil},\n-\t\t{`[0-9_]+`, LiteralNumberInteger, nil},\n+\t\t{`[0-9][0-9_]*`, LiteralNumberInteger, nil},\n \t\t{`\\.\\.\\.|=>`, Punctuation, nil},\n \t\t{`\\+\\+|--|~|&&|\\?|:|\\|\\||\\\\(?=\\n)|(<<|>>>?|==?|!=?|[-<>+*%&|^/])=?`, Operator, Push(\"slashstartsregex\")},\n \t\t{`[{(\\[;,]`, Punctuation, Push(\"slashstartsregex\")},\n@@ -40,7 +40,7 @@ var JavascriptRules = Rules{\n \t\t{`(abstract|async|await|boolean|byte|char|class|const|debugger|double|enum|export|extends|final|float|goto|implements|import|int|interface|long|native|package|private|protected|public|short|static|super|synchronized|throws|transient|volatile)\\b`, KeywordReserved, nil},\n \t\t{`(true|false|null|NaN|Infinity|undefined)\\b`, KeywordConstant, nil},\n \t\t{`(Array|Boolean|Date|Error|Function|Math|netscape|Number|Object|Packages|RegExp|String|Promise|Proxy|sun|decodeURI|decodeURIComponent|encodeURI|encodeURIComponent|Error|eval|isFinite|isNaN|isSafeInteger|parseFloat|parseInt|document|this|window)\\b`, NameBuiltin, nil},\n-\t\t{`(?:[$_A-Z------------------------------------------------------------------------------------------a-z-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]|\\\\u[a-fA-F0-9]{4})(?:(?:[$A-Z------------------------------------------------------------------------------------------a-z---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------0-9--------------------------------------------------------_---]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n+\t\t{`(?:[$_\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4})(?:(?:[$\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n \t\t{`\"(\\\\\\\\|\\\\\"|[^\"])*\"`, LiteralStringDouble, nil},\n \t\t{`'(\\\\\\\\|\\\\'|[^'])*'`, LiteralStringSingle, nil},\n \t\t{\"`\", LiteralStringBacktick, Push(\"interp\")},"
    },
    {
      "sha": "daf6dc3105736c24552871917a96f7aaac162572",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/j/json.go",
      "status": "modified",
      "additions": 6,
      "deletions": 0,
      "changes": 6,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/json.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/json.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/j/json.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -23,6 +23,9 @@ func jsonRules() Rules {\n \t\t\"whitespace\": {\n \t\t\t{`\\s+`, Text, nil},\n \t\t},\n+\t\t\"comment\": {\n+\t\t\t{`//.*?\\n`, CommentSingle, nil},\n+\t\t},\n \t\t\"simplevalue\": {\n \t\t\t{`(true|false|null)\\b`, KeywordConstant, nil},\n \t\t\t{`-?(0|[1-9]\\d*)(\\.\\d+[eE](\\+|-)?\\d+|[eE](\\+|-)?\\d+|\\.\\d+)`, LiteralNumberFloat, nil},\n@@ -37,18 +40,21 @@ func jsonRules() Rules {\n \t\t},\n \t\t\"objectvalue\": {\n \t\t\tInclude(\"whitespace\"),\n+\t\t\tInclude(\"comment\"),\n \t\t\t{`\"(\\\\\\\\|\\\\\"|[^\"])*\"`, NameTag, Push(\"objectattribute\")},\n \t\t\t{`\\}`, Punctuation, Pop(1)},\n \t\t},\n \t\t\"arrayvalue\": {\n \t\t\tInclude(\"whitespace\"),\n \t\t\tInclude(\"value\"),\n+\t\t\tInclude(\"comment\"),\n \t\t\t{`,`, Punctuation, nil},\n \t\t\t{`\\]`, Punctuation, Pop(1)},\n \t\t},\n \t\t\"value\": {\n \t\t\tInclude(\"whitespace\"),\n \t\t\tInclude(\"simplevalue\"),\n+\t\t\tInclude(\"comment\"),\n \t\t\t{`\\{`, Punctuation, Push(\"objectvalue\")},\n \t\t\t{`\\[`, Punctuation, Push(\"arrayvalue\")},\n \t\t},"
    },
    {
      "sha": "e98526b89be31883f1780e05f3052e4be0921e0e",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/j/jsx.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/jsx.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/j/jsx.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/j/jsx.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -55,7 +55,7 @@ func jsxRules() Rules {\n \t\t\t{`(abstract|async|await|boolean|byte|char|class|const|debugger|double|enum|export|extends|final|float|goto|implements|import|int|interface|long|native|package|private|protected|public|short|static|super|synchronized|throws|transient|volatile)\\b`, KeywordReserved, nil},\n \t\t\t{`(true|false|null|NaN|Infinity|undefined)\\b`, KeywordConstant, nil},\n \t\t\t{`(Array|Boolean|Date|Error|Function|Math|netscape|Number|Object|Packages|RegExp|String|Promise|Proxy|sun|decodeURI|decodeURIComponent|encodeURI|encodeURIComponent|Error|eval|isFinite|isNaN|isSafeInteger|parseFloat|parseInt|document|this|window)\\b`, NameBuiltin, nil},\n-\t\t\t{`(?:[$_A-Z------------------------------------------------------------------------------------------a-z-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]|\\\\u[a-fA-F0-9]{4})(?:(?:[$A-Z------------------------------------------------------------------------------------------a-z---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------0-9--------------------------------------------------------_---]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n+\t\t\t{`(?:[$_\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4})(?:(?:[$\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n \t\t\t{`\"(\\\\\\\\|\\\\\"|[^\"])*\"`, LiteralStringDouble, nil},\n \t\t\t{`'(\\\\\\\\|\\\\'|[^'])*'`, LiteralStringSingle, nil},\n \t\t\t{\"`\", LiteralStringBacktick, Push(\"interp\")},"
    },
    {
      "sha": "b6be884e9eeed2017d95c9b7ee823e75fa0a1e59",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/k/kotlin.go",
      "status": "modified",
      "additions": 8,
      "deletions": 8,
      "changes": 16,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/k/kotlin.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/k/kotlin.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/k/kotlin.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -18,7 +18,7 @@ var Kotlin = internal.Register(MustNewLazyLexer(\n ))\n \n func kotlinRules() Rules {\n-\tconst kotlinIdentifier = \"_A-Z\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa\\uff21-\\uff3aa-z\\u00b5\\u00df-\\u00f6\\u00f8-\\u00ff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0561-\\u0587\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7fa\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uff70\\uff9e-\\uff9f\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef][A-Z\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa\\uff21-\\uff3aa-z\\u00b5\\u00df-\\u00f6\\u00f8-\\u00ff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0561-\\u0587\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7fa\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uff70\\uff9e-\\uff9f\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef0-9\\u0660-\\u0669\\u06f0-\\u06f9\\u07c0-\\u07c9\\u0966-\\u096f\\u09e6-\\u09ef\\u0a66-\\u0a6f\\u0ae6-\\u0aef\\u0b66-\\u0b6f\\u0be6-\\u0bef\\u0c66-\\u0c6f\\u0ce6-\\u0cef\\u0d66-\\u0d6f\\u0e50-\\u0e59\\u0ed0-\\u0ed9\\u0f20-\\u0f29\\u1040-\\u1049\\u1090-\\u1099\\u17e0-\\u17e9\\u1810-\\u1819\\u1946-\\u194f\\u19d0-\\u19d9\\u1a80-\\u1a89\\u1a90-\\u1a99\\u1b50-\\u1b59\\u1bb0-\\u1bb9\\u1c40-\\u1c49\\u1c50-\\u1c59\\ua620-\\ua629\\ua8d0-\\ua8d9\\ua900-\\ua909\\ua9d0-\\ua9d9\\uaa50-\\uaa59\\uabf0-\\uabf9\\uff10-\\uff19_\\u203f-\\u2040\\u2054\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\uff3f\\u00ad\\u0600-\\u0604\\u061c\\u06dd\\u070f\\u180e\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u2064\\u2066-\\u206f\\ufeff\\ufff9-\\ufffb\\u0300-\\u036f\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u065f\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7-\\u06e8\\u06ea-\\u06ed\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07eb-\\u07f3\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u08e4-\\u08fe\\u0900-\\u0902\\u093a\\u093c\\u0941-\\u0948\\u094d\\u0951-\\u0957\\u0962-\\u0963\\u0981\\u09bc\\u09c1-\\u09c4\\u09cd\\u09e2-\\u09e3\\u0a01-\\u0a02\\u0a3c\\u0a41-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a70-\\u0a71\\u0a75\\u0a81-\\u0a82\\u0abc\\u0ac1-\\u0ac5\\u0ac7-\\u0ac8\\u0acd\\u0ae2-\\u0ae3\\u0b01\\u0b3c\\u0b3f\\u0b41-\\u0b44\\u0b4d\\u0b56\\u0b62-\\u0b63\\u0b82\\u0bc0\\u0bcd\\u0c3e-\\u0c40\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c62-\\u0c63\\u0cbc\\u0cbf\\u0cc6\\u0ccc-\\u0ccd\\u0ce2-\\u0ce3\\u0d41-\\u0d44\\u0d4d\\u0d62-\\u0d63\\u0dca\\u0dd2-\\u0dd4\\u0dd6\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0eb1\\u0eb4-\\u0eb9\\u0ebb-\\u0ebc\\u0ec8-\\u0ecd\\u0f18-\\u0f19\\u0f35\\u0f37\\u0f39\\u0f71-\\u0f7e\\u0f80-\\u0f84\\u0f86-\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102d-\\u1030\\u1032-\\u1037\\u1039-\\u103a\\u103d-\\u103e\\u1058-\\u1059\\u105e-\\u1060\\u1071-\\u1074\\u1082\\u1085-\\u1086\\u108d\\u109d\\u135d-\\u135f\\u1712-\\u1714\\u1732-\\u1734\\u1752-\\u1753\\u1772-\\u1773\\u17b4-\\u17b5\\u17b7-\\u17bd\\u17c6\\u17c9-\\u17d3\\u17dd\\u180b-\\u180d\\u18a9\\u1920-\\u1922\\u1927-\\u1928\\u1932\\u1939-\\u193b\\u1a17-\\u1a18\\u1a1b\\u1a56\\u1a58-\\u1a5e\\u1a60\\u1a62\\u1a65-\\u1a6c\\u1a73-\\u1a7c\\u1a7f\\u1b00-\\u1b03\\u1b34\\u1b36-\\u1b3a\\u1b3c\\u1b42\\u1b6b-\\u1b73\\u1b80-\\u1b81\\u1ba2-\\u1ba5\\u1ba8-\\u1ba9\\u1bab\\u1be6\\u1be8-\\u1be9\\u1bed\\u1bef-\\u1bf1\\u1c2c-\\u1c33\\u1c36-\\u1c37\\u1cd0-\\u1cd2\\u1cd4-\\u1ce0\\u1ce2-\\u1ce8\\u1ced\\u1cf4\\u1dc0-\\u1de6\\u1dfc-\\u1dff\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302d\\u3099-\\u309a\\ua66f\\ua674-\\ua67d\\ua69f\\ua6f0-\\ua6f1\\ua802\\ua806\\ua80b\\ua825-\\ua826\\ua8c4\\ua8e0-\\ua8f1\\ua926-\\ua92d\\ua947-\\ua951\\ua980-\\ua982\\ua9b3\\ua9b6-\\ua9b9\\ua9bc\\uaa29-\\uaa2e\\uaa31-\\uaa32\\uaa35-\\uaa36\\uaa43\\uaa4c\\uaab0\\uaab2-\\uaab4\\uaab7-\\uaab8\\uaabe-\\uaabf\\uaac1\\uaaec-\\uaaed\\uaaf6\\uabe5\\uabe8\\uabed\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe26\\u0903\\u093b\\u093e-\\u0940\\u0949-\\u094c\\u094e-\\u094f\\u0982-\\u0983\\u09be-\\u09c0\\u09c7-\\u09c8\\u09cb-\\u09cc\\u09d7\\u0a03\\u0a3e-\\u0a40\\u0a83\\u0abe-\\u0ac0\\u0ac9\\u0acb-\\u0acc\\u0b02-\\u0b03\\u0b3e\\u0b40\\u0b47-\\u0b48\\u0b4b-\\u0b4c\\u0b57\\u0bbe-\\u0bbf\\u0bc1-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcc\\u0bd7\\u0c01-\\u0c03\\u0c41-\\u0c44\\u0c82-\\u0c83\\u0cbe\\u0cc0-\\u0cc4\\u0cc7-\\u0cc8\\u0cca-\\u0ccb\\u0cd5-\\u0cd6\\u0d02-\\u0d03\\u0d3e-\\u0d40\\u0d46-\\u0d48\\u0d4a-\\u0d4c\\u0d57\\u0d82-\\u0d83\\u0dcf-\\u0dd1\\u0dd8-\\u0ddf\\u0df2-\\u0df3\\u0f3e-\\u0f3f\\u0f7f\\u102b-\\u102c\\u1031\\u1038\\u103b-\\u103c\\u1056-\\u1057\\u1062-\\u1064\\u1067-\\u106d\\u1083-\\u1084\\u1087-\\u108c\\u108f\\u109a-\\u109c\\u17b6\\u17be-\\u17c5\\u17c7-\\u17c8\\u1923-\\u1926\\u1929-\\u192b\\u1930-\\u1931\\u1933-\\u1938\\u19b0-\\u19c0\\u19c8-\\u19c9\\u1a19-\\u1a1a\\u1a55\\u1a57\\u1a61\\u1a63-\\u1a64\\u1a6d-\\u1a72\\u1b04\\u1b35\\u1b3b\\u1b3d-\\u1b41\\u1b43-\\u1b44\\u1b82\\u1ba1\\u1ba6-\\u1ba7\\u1baa\\u1bac-\\u1bad\\u1be7\\u1bea-\\u1bec\\u1bee\\u1bf2-\\u1bf3\\u1c24-\\u1c2b\\u1c34-\\u1c35\\u1ce1\\u1cf2-\\u1cf3\\u302e-\\u302f\\ua823-\\ua824\\ua827\\ua880-\\ua881\\ua8b4-\\ua8c3\\ua952-\\ua953\\ua983\\ua9b4-\\ua9b5\\ua9ba-\\ua9bb\\ua9bd-\\ua9c0\\uaa2f-\\uaa30\\uaa33-\\uaa34\\uaa4d\\uaa7b\\uaaeb\\uaaee-\\uaaef\\uaaf5\\uabe3-\\uabe4\\uabe6-\\uabe7\\uabe9-\\uabea\\uabec]*|`@?[_A-Z\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa\\uff21-\\uff3aa-z\\u00b5\\u00df-\\u00f6\\u00f8-\\u00ff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0561-\\u0587\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7fa\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uff70\\uff9e-\\uff9f\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef][A-Z\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa\\uff21-\\uff3aa-z\\u00b5\\u00df-\\u00f6\\u00f8-\\u00ff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0561-\\u0587\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7fa\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uff70\\uff9e-\\uff9f\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef0-9\\u0660-\\u0669\\u06f0-\\u06f9\\u07c0-\\u07c9\\u0966-\\u096f\\u09e6-\\u09ef\\u0a66-\\u0a6f\\u0ae6-\\u0aef\\u0b66-\\u0b6f\\u0be6-\\u0bef\\u0c66-\\u0c6f\\u0ce6-\\u0cef\\u0d66-\\u0d6f\\u0e50-\\u0e59\\u0ed0-\\u0ed9\\u0f20-\\u0f29\\u1040-\\u1049\\u1090-\\u1099\\u17e0-\\u17e9\\u1810-\\u1819\\u1946-\\u194f\\u19d0-\\u19d9\\u1a80-\\u1a89\\u1a90-\\u1a99\\u1b50-\\u1b59\\u1bb0-\\u1bb9\\u1c40-\\u1c49\\u1c50-\\u1c59\\ua620-\\ua629\\ua8d0-\\ua8d9\\ua900-\\ua909\\ua9d0-\\ua9d9\\uaa50-\\uaa59\\uabf0-\\uabf9\\uff10-\\uff19_\\u203f-\\u2040\\u2054\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\uff3f\\u00ad\\u0600-\\u0604\\u061c\\u06dd\\u070f\\u180e\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u2064\\u2066-\\u206f\\ufeff\\ufff9-\\ufffb\\u0300-\\u036f\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u065f\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7-\\u06e8\\u06ea-\\u06ed\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07eb-\\u07f3\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u08e4-\\u08fe\\u0900-\\u0902\\u093a\\u093c\\u0941-\\u0948\\u094d\\u0951-\\u0957\\u0962-\\u0963\\u0981\\u09bc\\u09c1-\\u09c4\\u09cd\\u09e2-\\u09e3\\u0a01-\\u0a02\\u0a3c\\u0a41-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a70-\\u0a71\\u0a75\\u0a81-\\u0a82\\u0abc\\u0ac1-\\u0ac5\\u0ac7-\\u0ac8\\u0acd\\u0ae2-\\u0ae3\\u0b01\\u0b3c\\u0b3f\\u0b41-\\u0b44\\u0b4d\\u0b56\\u0b62-\\u0b63\\u0b82\\u0bc0\\u0bcd\\u0c3e-\\u0c40\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c62-\\u0c63\\u0cbc\\u0cbf\\u0cc6\\u0ccc-\\u0ccd\\u0ce2-\\u0ce3\\u0d41-\\u0d44\\u0d4d\\u0d62-\\u0d63\\u0dca\\u0dd2-\\u0dd4\\u0dd6\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0eb1\\u0eb4-\\u0eb9\\u0ebb-\\u0ebc\\u0ec8-\\u0ecd\\u0f18-\\u0f19\\u0f35\\u0f37\\u0f39\\u0f71-\\u0f7e\\u0f80-\\u0f84\\u0f86-\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102d-\\u1030\\u1032-\\u1037\\u1039-\\u103a\\u103d-\\u103e\\u1058-\\u1059\\u105e-\\u1060\\u1071-\\u1074\\u1082\\u1085-\\u1086\\u108d\\u109d\\u135d-\\u135f\\u1712-\\u1714\\u1732-\\u1734\\u1752-\\u1753\\u1772-\\u1773\\u17b4-\\u17b5\\u17b7-\\u17bd\\u17c6\\u17c9-\\u17d3\\u17dd\\u180b-\\u180d\\u18a9\\u1920-\\u1922\\u1927-\\u1928\\u1932\\u1939-\\u193b\\u1a17-\\u1a18\\u1a1b\\u1a56\\u1a58-\\u1a5e\\u1a60\\u1a62\\u1a65-\\u1a6c\\u1a73-\\u1a7c\\u1a7f\\u1b00-\\u1b03\\u1b34\\u1b36-\\u1b3a\\u1b3c\\u1b42\\u1b6b-\\u1b73\\u1b80-\\u1b81\\u1ba2-\\u1ba5\\u1ba8-\\u1ba9\\u1bab\\u1be6\\u1be8-\\u1be9\\u1bed\\u1bef-\\u1bf1\\u1c2c-\\u1c33\\u1c36-\\u1c37\\u1cd0-\\u1cd2\\u1cd4-\\u1ce0\\u1ce2-\\u1ce8\\u1ced\\u1cf4\\u1dc0-\\u1de6\\u1dfc-\\u1dff\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302d\\u3099-\\u309a\\ua66f\\ua674-\\ua67d\\ua69f\\ua6f0-\\ua6f1\\ua802\\ua806\\ua80b\\ua825-\\ua826\\ua8c4\\ua8e0-\\ua8f1\\ua926-\\ua92d\\ua947-\\ua951\\ua980-\\ua982\\ua9b3\\ua9b6-\\ua9b9\\ua9bc\\uaa29-\\uaa2e\\uaa31-\\uaa32\\uaa35-\\uaa36\\uaa43\\uaa4c\\uaab0\\uaab2-\\uaab4\\uaab7-\\uaab8\\uaabe-\\uaabf\\uaac1\\uaaec-\\uaaed\\uaaf6\\uabe5\\uabe8\\uabed\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe26\\u0903\\u093b\\u093e-\\u0940\\u0949-\\u094c\\u094e-\\u094f\\u0982-\\u0983\\u09be-\\u09c0\\u09c7-\\u09c8\\u09cb-\\u09cc\\u09d7\\u0a03\\u0a3e-\\u0a40\\u0a83\\u0abe-\\u0ac0\\u0ac9\\u0acb-\\u0acc\\u0b02-\\u0b03\\u0b3e\\u0b40\\u0b47-\\u0b48\\u0b4b-\\u0b4c\\u0b57\\u0bbe-\\u0bbf\\u0bc1-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcc\\u0bd7\\u0c01-\\u0c03\\u0c41-\\u0c44\\u0c82-\\u0c83\\u0cbe\\u0cc0-\\u0cc4\\u0cc7-\\u0cc8\\u0cca-\\u0ccb\\u0cd5-\\u0cd6\\u0d02-\\u0d03\\u0d3e-\\u0d40\\u0d46-\\u0d48\\u0d4a-\\u0d4c\\u0d57\\u0d82-\\u0d83\\u0dcf-\\u0dd1\\u0dd8-\\u0ddf\\u0df2-\\u0df3\\u0f3e-\\u0f3f\\u0f7f\\u102b-\\u102c\\u1031\\u1038\\u103b-\\u103c\\u1056-\\u1057\\u1062-\\u1064\\u1067-\\u106d\\u1083-\\u1084\\u1087-\\u108c\\u108f\\u109a-\\u109c\\u17b6\\u17be-\\u17c5\\u17c7-\\u17c8\\u1923-\\u1926\\u1929-\\u192b\\u1930-\\u1931\\u1933-\\u1938\\u19b0-\\u19c0\\u19c8-\\u19c9\\u1a19-\\u1a1a\\u1a55\\u1a57\\u1a61\\u1a63-\\u1a64\\u1a6d-\\u1a72\\u1b04\\u1b35\\u1b3b\\u1b3d-\\u1b41\\u1b43-\\u1b44\\u1b82\\u1ba1\\u1ba6-\\u1ba7\\u1baa\\u1bac-\\u1bad\\u1be7\\u1bea-\\u1bec\\u1bee\\u1bf2-\\u1bf3\\u1c24-\\u1c2b\\u1c34-\\u1c35\\u1ce1\\u1cf2-\\u1cf3\\u302e-\\u302f\\ua823-\\ua824\\ua827\\ua880-\\ua881\\ua8b4-\\ua8c3\\ua952-\\ua953\\ua983\\ua9b4-\\ua9b5\\ua9ba-\\ua9bb\\ua9bd-\\ua9c0\\uaa2f-\\uaa30\\uaa33-\\uaa34\\uaa4d\\uaa7b\\uaaeb\\uaaee-\\uaaef\\uaaf5\\uabe3-\\uabe4\\uabe6-\\uabe7\\uabe9-\\uabea\\uabec\"\n+\tconst kotlinIdentifier = \"(?:[_\\\\p{L}][\\\\p{L}\\\\p{N}]*|`@?[_\\\\p{L}][\\\\p{L}\\\\p{N}]+)\"\n \n \treturn Rules{\n \t\t\"root\": {\n@@ -43,34 +43,34 @@ func kotlinRules() Rules {\n \t\t\t{`(val|var)(\\s+)`, ByGroups(Keyword, Text), Push(\"property\")},\n \t\t\t{`(fun)(\\s+)`, ByGroups(Keyword, Text), Push(\"function\")},\n \t\t\t{`(abstract|actual|annotation|as|as\\?|break|by|catch|class|companion|const|constructor|continue|crossinline|data|delegate|do|dynamic|else|enum|expect|external|false|field|file|final|finally|for|fun|get|if|import|in|infix|init|inline|inner|interface|internal|is|it|lateinit|noinline|null|object|open|operator|out|override|package|param|private|property|protected|public|receiver|reified|return|sealed|set|setparam|super|suspend|tailrec|this|throw|true|try|typealias|typeof|val|var|vararg|when|where|while)\\b`, Keyword, nil},\n-\t\t\t{`@[` + kotlinIdentifier + `]+`, NameDecorator, nil},\n-\t\t\t{`[` + kotlinIdentifier + `]+`, Name, nil},\n+\t\t\t{`@` + kotlinIdentifier, NameDecorator, nil},\n+\t\t\t{kotlinIdentifier, Name, nil},\n \t\t},\n \t\t\"package\": {\n \t\t\t{`\\S+`, NameNamespace, Pop(1)},\n \t\t},\n \t\t\"class\": {\n \t\t\t// \\x60 is the back tick character (`)\n \t\t\t{`\\x60[^\\x60]+?\\x60`, NameClass, Pop(1)},\n-\t\t\t{`[` + kotlinIdentifier + `]+`, NameClass, Pop(1)},\n+\t\t\t{kotlinIdentifier, NameClass, Pop(1)},\n \t\t},\n \t\t\"property\": {\n \t\t\t{`\\x60[^\\x60]+?\\x60`, NameProperty, Pop(1)},\n-\t\t\t{`[` + kotlinIdentifier + `]+`, NameProperty, Pop(1)},\n+\t\t\t{kotlinIdentifier, NameProperty, Pop(1)},\n \t\t},\n \t\t\"generics-specification\": {\n \t\t\t{`<`, Punctuation, Push(\"generics-specification\")}, // required for generics inside generics e.g. <T : List<Int> >\n \t\t\t{`>`, Punctuation, Pop(1)},\n \t\t\t{`[,:*?]`, Punctuation, nil},\n \t\t\t{`(in|out|reified)`, Keyword, nil},\n \t\t\t{`\\x60[^\\x60]+?\\x60`, NameClass, nil},\n-\t\t\t{`[` + kotlinIdentifier + `]+`, NameClass, nil},\n+\t\t\t{kotlinIdentifier, NameClass, nil},\n \t\t\t{`\\s+`, Text, nil},\n \t\t},\n \t\t\"function\": {\n \t\t\t{`<`, Punctuation, Push(\"generics-specification\")},\n \t\t\t{`\\x60[^\\x60]+?\\x60`, NameFunction, Pop(1)},\n-\t\t\t{`[` + kotlinIdentifier + `]+`, NameFunction, Pop(1)},\n+\t\t\t{kotlinIdentifier, NameFunction, Pop(1)},\n \t\t\t{`\\s+`, Text, nil},\n \t\t},\n \t\t\"rawstring\": {\n@@ -91,7 +91,7 @@ func kotlinRules() Rules {\n \t\t\t{`\\$`, LiteralStringDouble, nil},\n \t\t},\n \t\t\"string-interpol\": {\n-\t\t\t{`\\$[` + kotlinIdentifier + `]+`, LiteralStringInterpol, nil},\n+\t\t\t{`\\$` + kotlinIdentifier, LiteralStringInterpol, nil},\n \t\t\t{`\\${[^}\\n]*}`, LiteralStringInterpol, nil},\n \t\t},\n \t}"
    },
    {
      "sha": "2a6a22f898ed6f062f676a85c953875e0bb66596",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/m/meson.go",
      "status": "added",
      "additions": 51,
      "deletions": 0,
      "changes": 51,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/m/meson.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/m/meson.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/m/meson.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,51 @@\n+package m\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+// Meson lexer.\n+var Meson = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:      \"Meson\",\n+\t\tAliases:   []string{\"meson\", \"meson.build\"},\n+\t\tFilenames: []string{\"meson.build\", \"meson_options.txt\"},\n+\t\tMimeTypes: []string{\"text/x-meson\"},\n+\t},\n+\tfunc() Rules {\n+\t\treturn Rules{\n+\t\t\t\"root\": {\n+\t\t\t\t{`#.*?$`, Comment, nil},\n+\t\t\t\t{`'''.*'''`, LiteralStringSingle, nil},\n+\t\t\t\t{`[1-9][0-9]*`, LiteralNumberInteger, nil},\n+\t\t\t\t{`0o[0-7]+`, LiteralNumberOct, nil},\n+\t\t\t\t{`0x[a-fA-F0-9]+`, LiteralNumberHex, nil},\n+\t\t\t\tInclude(\"string\"),\n+\t\t\t\tInclude(\"keywords\"),\n+\t\t\t\tInclude(\"expr\"),\n+\t\t\t\t{`[a-zA-Z_][a-zA-Z_0-9]*`, Name, nil},\n+\t\t\t\t{`\\s+`, TextWhitespace, nil},\n+\t\t\t},\n+\t\t\t\"string\": {\n+\t\t\t\t{`[']{3}([']{0,2}([^\\\\']|\\\\(.|\\n)))*[']{3}`, LiteralString, nil},\n+\t\t\t\t{`'.*?(?<!\\\\)(\\\\\\\\)*?'`, LiteralString, nil},\n+\t\t\t},\n+\t\t\t\"keywords\": {\n+\t\t\t\t{Words(``, `\\b`, `if`, `elif`, `else`, `endif`, `foreach`, `endforeach`, `break`, `continue`), Keyword, nil},\n+\t\t\t},\n+\t\t\t\"expr\": {\n+\t\t\t\t{`(in|and|or|not)\\b`, OperatorWord, nil},\n+\t\t\t\t{`(\\*=|/=|%=|\\+]=|-=|==|!=|\\+|-|=)`, Operator, nil},\n+\t\t\t\t{`[\\[\\]{}:().,?]`, Punctuation, nil},\n+\t\t\t\t{Words(``, `\\b`, `true`, `false`), KeywordConstant, nil},\n+\t\t\t\tInclude(\"builtins\"),\n+\t\t\t\t{Words(``, `\\b`, `meson`, `build_machine`, `host_machine`, `target_machine`), NameVariableMagic, nil},\n+\t\t\t},\n+\t\t\t\"builtins\": {\n+\t\t\t\t{Words(`(?<!\\.)`, `\\b`, `add_global_arguments`, `add_global_link_arguments`, `add_languages`, `add_project_arguments`, `add_project_link_arguments`, `add_test_setup`, `assert`, `benchmark`, `both_libraries`, `build_target`, `configuration_data`, `configure_file`, `custom_target`, `declare_dependency`, `dependency`, `disabler`, `environment`, `error`, `executable`, `files`, `find_library`, `find_program`, `generator`, `get_option`, `get_variable`, `include_directories`, `install_data`, `install_headers`, `install_man`, `install_subdir`, `is_disabler`, `is_variable`, `jar`, `join_paths`, `library`, `message`, `project`, `range`, `run_command`, `set_variable`, `shared_library`, `shared_module`, `static_library`, `subdir`, `subdir_done`, `subproject`, `summary`, `test`, `vcs_tag`, `warning`), NameBuiltin, nil},\n+\t\t\t\t{`(?<!\\.)import\\b`, NameNamespace, nil},\n+\t\t\t},\n+\t\t}\n+\t},\n+))"
    },
    {
      "sha": "cb51b715b5d56eeba1d7552c4106e94f5ef8734a",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/o/onesenterprise.go",
      "status": "added",
      "additions": 50,
      "deletions": 0,
      "changes": 50,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/o/onesenterprise.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/o/onesenterprise.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/o/onesenterprise.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,50 @@\n+package o\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+// 1S:Enterprise lexer.\n+var OnesEnterprise = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:            \"OnesEnterprise\",\n+\t\tAliases:         []string{\"ones\", \"onesenterprise\", \"1S\", \"1S:Enterprise\"},\n+\t\tFilenames:       []string{\"*.EPF\", \"*.epf\", \"*.ERF\", \"*.erf\"},\n+\t\tMimeTypes:       []string{\"application/octet-stream\"},\n+\t\tCaseInsensitive: true,\n+\t},\n+\tonesRules,\n+))\n+\n+func onesRules() Rules {\n+\treturn Rules{\n+\t\t\"root\": {\n+\t\t\t{`\\n`, Text, nil},\n+\t\t\t{`\\s+`, Text, nil},\n+\t\t\t{`\\\\\\n`, Text, nil},\n+\t\t\t{`[^\\S\\n]+`, Text, nil},\n+\t\t\t{`//(.*?)\\n`, Comment, nil},\n+\t\t\t{`(#|#region|#|#endregion|#|#if|#|#else|#|#endif).*`, CommentPreproc, nil},\n+\t\t\t{`(&|&atclient|&|&atserver|&|&atservernocontext|&|&atclientatservernocontext).*`, CommentPreproc, nil},\n+\t\t\t{`(>=|<=|<>|\\+|-|=|>|<|\\*|/|%)`, Operator, nil},\n+\t\t\t{`(;|,|\\)|\\(|\\.)`, Punctuation, nil},\n+\t\t\t{Words(``, `\\b`, ``, `true`, ``, `false`, ``, `and`, ``, `or`, ``, `not`), Operator, nil},\n+\t\t\t{Words(``, `\\b`, ``, `if`, ``, `then`, ``, `else`, ``, `elsif`, ``, `endif`), Operator, nil},\n+\t\t\t{Words(``, `\\b`, ``, `for`, ``, `each`, ``, `in`, ``, `do`, ``, `while`, ``, `enddo`, ``, `to`), Operator, nil},\n+\t\t\t{Words(``, `\\b`, ``, `break`, ``, `continue`, ``, `return`, ``, `goto`), Operator, nil},\n+\t\t\t{Words(``, `\\b`, ``, `procedure`, ``, `endprocedure`, ``, `function`, ``, `endfunction`), Keyword, nil},\n+\t\t\t{Words(``, `\\b`, ``, `new`, ``, `val`, ``, `export`, ``, `var`), Keyword, nil},\n+\t\t\t{Words(``, `\\b`, ``, `try`, ``, `except`, ``, `raise`, ``, `endtry`), Keyword, nil},\n+\t\t\t{Words(``, `\\b`, ``, `execute`, ``, `eval`), Keyword, nil},\n+\t\t\t{`\"`, LiteralString, Push(\"string\")},\n+\t\t\t{`[_--0-9][--0-9]*`, Name, nil},\n+\t\t\t{`[_\\w][\\w]*`, Name, nil},\n+\t\t},\n+\t\t\"string\": {\n+\t\t\t{`\"\"`, LiteralString, nil},\n+\t\t\t{`\"C?`, LiteralString, Pop(1)},\n+\t\t\t{`[^\"]+`, LiteralString, nil},\n+\t\t},\n+\t}\n+}"
    },
    {
      "sha": "ad10a322ed04afca2f75edbf99e7ae274f2e8841",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/p/python.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/p/python.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/p/python.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/p/python.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -17,7 +17,7 @@ var Python = internal.Register(MustNewLazyLexer(\n ))\n \n func pythonRules() Rules {\n-\tconst pythonIdentifier = `[A-Z_a-z-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------][0-9A-Z_a-z--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]*`\n+\tconst pythonIdentifier = `[_\\p{L}][_\\p{L}\\p{N}]*`\n \n \treturn Rules{\n \t\t\"root\": {"
    },
    {
      "sha": "349cb98c00d35d26e149f30c9e16922a8f777934",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/r/raku.go",
      "status": "modified",
      "additions": 498,
      "deletions": 273,
      "changes": 771,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/r/raku.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/r/raku.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/r/raku.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -33,26 +33,24 @@ func rakuRules() Rules {\n \n \tconst (\n \t\trakuQuote RakuToken = iota\n-\t\trakuName\n \t\trakuNameAttribute\n \t\trakuPod\n \t\trakuPodFormatter\n \t\trakuPodDeclaration\n \t\trakuMultilineComment\n-\t\trakuSlashRegex\n \t\trakuMatchRegex\n \t\trakuSubstitutionRegex\n-\t\trakuSubstitutionSingleRegex\n-\t\trakuRegexInsideToken\n \t)\n \n \tconst (\n \t\tcolonPairOpeningBrackets = `(?:<<|<||\\(|\\[|\\{)`\n \t\tcolonPairClosingBrackets = `(?:>>|>||\\)|\\]|\\})`\n-\t\tcolonPairPattern         = `(?<colon>:)(?<key>\\w[\\w'-]*)(?<opening_delimiters>` + colonPairOpeningBrackets + `)`\n-\t\tnamePattern              = `((?:(?!` + colonPairPattern + `)[\\w':-])+)`\n-\t\tvariablePattern          = `[$@%&]+[.^:?=!~]?` + namePattern\n-\t\tglobalVariablePattern    = `[$@%&]+\\*` + namePattern\n+\t\tcolonPairPattern         = `(?<!:)(?<colon>:)(?<key>\\w[\\w'-]*)(?<opening_delimiters>` + colonPairOpeningBrackets + `)`\n+\t\tcolonPairLookahead       = `(?=(:['\\w-]+` +\n+\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `)?`\n+\t\tnamePattern           = `(?:(?!` + colonPairPattern + `)(?:::|[\\w':-]))+`\n+\t\tvariablePattern       = `[$@%&]+[.^:?=!~]?` + namePattern\n+\t\tglobalVariablePattern = `[$@%&]+\\*` + namePattern\n \t)\n \n \tkeywords := []string{\n@@ -339,13 +337,11 @@ func rakuRules() Rules {\n \n \t// Finds opening brackets and their closing counterparts (including pod and heredoc)\n \t// and modifies state groups and position accordingly\n-\tbracketsFinder := func(tokenClass RakuToken) MutatorFunc {\n+\tfindBrackets := func(tokenClass RakuToken) MutatorFunc {\n \t\treturn func(state *LexerState) error {\n \t\t\tvar openingChars []rune\n \t\t\tvar adverbs []rune\n \t\t\tswitch tokenClass {\n-\t\t\tcase rakuRegexInsideToken:\n-\t\t\t\topeningChars = []rune(\"{\")\n \t\t\tcase rakuPod:\n \t\t\t\topeningChars = []rune(strings.Join(state.Groups[1:5], ``))\n \t\t\tdefault:\n@@ -363,25 +359,15 @@ func rakuRules() Rules {\n \n \t\t\tswitch tokenClass {\n \t\t\tcase rakuPod:\n-\t\t\t\tclosingChars = []rune(state.NamedGroups[`ws`] + `=end ` + state.NamedGroups[`name`])\n \t\t\t\tclosingCharExists = true\n \t\t\tdefault:\n \t\t\t\tclosingChar, closingCharExists = brackets[openingChar]\n \t\t\t}\n \n \t\t\tswitch tokenClass {\n \t\t\tcase rakuPodFormatter:\n-\t\t\t\tstack, ok := state.Get(\"pod_formatter_stack\").([]RakuFormatterRules)\n-\t\t\t\tif !ok {\n-\t\t\t\t\tstack = []RakuFormatterRules{}\n-\t\t\t\t}\n-\t\t\t\tpopRule := makeRuleAndPushMaybe(RuleMakingConfig{\n-\t\t\t\t\tdelimiter:              []rune{closingChar},\n-\t\t\t\t\tnumberOfDelimiterChars: nChars,\n-\t\t\t\t\ttokenType:              Punctuation,\n-\t\t\t\t\tmutator:                Mutators(Pop(1), MutatorFunc(podFormatterPopper)),\n-\t\t\t\t})\n-\t\t\t\tvar formatter TokenType = StringOther\n+\t\t\t\tformatter := StringOther\n+\n \t\t\t\tswitch state.NamedGroups[`keyword`] {\n \t\t\t\tcase \"B\":\n \t\t\t\t\tformatter = GenericStrong\n@@ -390,37 +376,67 @@ func rakuRules() Rules {\n \t\t\t\tcase \"U\":\n \t\t\t\t\tformatter = GenericUnderline\n \t\t\t\t}\n-\t\t\t\tformattingRule := makeRuleAndPushMaybe(RuleMakingConfig{\n-\t\t\t\t\tpattern:   `.+?`,\n-\t\t\t\t\ttokenType: formatter,\n-\t\t\t\t\tmutator:   nil,\n-\t\t\t\t})\n-\t\t\t\tstate.Set(\"pod_formatter_stack\",\n-\t\t\t\t\tappend(stack, RakuFormatterRules{popRule, formattingRule}))\n+\n+\t\t\t\tformatterRule := ruleReplacingConfig{\n+\t\t\t\t\tpattern:      `.+?`,\n+\t\t\t\t\ttokenType:    formatter,\n+\t\t\t\t\tmutator:      nil,\n+\t\t\t\t\tstateName:    `pod-formatter`,\n+\t\t\t\t\trulePosition: bottomRule,\n+\t\t\t\t}\n+\n+\t\t\t\terr := replaceRule(formatterRule)(state)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tpanic(err)\n+\t\t\t\t}\n+\n+\t\t\t\terr = replaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter:              []rune{closingChar},\n+\t\t\t\t\ttokenType:              Punctuation,\n+\t\t\t\t\tstateName:              `pod-formatter`,\n+\t\t\t\t\tpushState:              true,\n+\t\t\t\t\tnumberOfDelimiterChars: nChars,\n+\t\t\t\t\tappendMutator:          popRule(formatterRule),\n+\t\t\t\t})(state)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tpanic(err)\n+\t\t\t\t}\n \n \t\t\t\treturn nil\n-\t\t\tcase rakuMatchRegex, rakuSubstitutionSingleRegex, rakuRegexInsideToken:\n-\t\t\t\t// We're inside a regex\n-\t\t\t\t// While matching a regex, the closing chars may have been used inside the regex\n-\t\t\t\t// so we have to push to regex state and pop on the matched closing chars\n-\t\t\t\t// and return\n+\t\t\tcase rakuMatchRegex:\n \t\t\t\tvar delimiter []rune\n \t\t\t\tif closingCharExists {\n \t\t\t\t\tdelimiter = []rune{closingChar}\n \t\t\t\t} else {\n \t\t\t\t\tdelimiter = openingChars\n \t\t\t\t}\n \n-\t\t\t\tmakeRuleAndPushMaybe(RuleMakingConfig{\n-\t\t\t\t\tdelimiter:              delimiter,\n-\t\t\t\t\ttokenType:              Punctuation,\n-\t\t\t\t\tmutator:                Pop(1),\n-\t\t\t\t\trulePosition:           topRule,\n-\t\t\t\t\tstate:                  state,\n-\t\t\t\t\tstateName:              \"regex\",\n-\t\t\t\t\tpushToStack:            true,\n-\t\t\t\t\tnumberOfDelimiterChars: nChars,\n-\t\t\t\t})\n+\t\t\t\terr := replaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: delimiter,\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `regex`,\n+\t\t\t\t\tpopState:  true,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t})(state)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tpanic(err)\n+\t\t\t\t}\n+\n+\t\t\t\treturn nil\n+\t\t\tcase rakuSubstitutionRegex:\n+\t\t\t\tdelimiter := regexp2.Escape(string(openingChars))\n+\n+\t\t\t\terr := replaceRule(ruleReplacingConfig{\n+\t\t\t\t\tpattern:      `(` + delimiter + `)` + `((?:\\\\\\\\|\\\\/|.)*?)` + `(` + delimiter + `)`,\n+\t\t\t\t\ttokenType:    ByGroups(Punctuation, UsingSelf(`qq`), Punctuation),\n+\t\t\t\t\trulePosition: topRule,\n+\t\t\t\t\tstateName:    `regex`,\n+\t\t\t\t\tpopState:     true,\n+\t\t\t\t\tpushState:    true,\n+\t\t\t\t})(state)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tpanic(err)\n+\t\t\t\t}\n \n \t\t\t\treturn nil\n \t\t\t}\n@@ -434,10 +450,17 @@ func rakuRules() Rules {\n \t\t\tif !closingCharExists {\n \t\t\t\t// it's not a mirrored character, which means we\n \t\t\t\t// just need to look for the next occurrence\n-\t\t\t\tnonMirroredOpeningCharPosition = indexAt(text, openingChars, state.Pos)\n+\t\t\t\tclosingChars = openingChars\n+\t\t\t\tnonMirroredOpeningCharPosition = indexAt(text, closingChars, state.Pos)\n \t\t\t\tendPos = nonMirroredOpeningCharPosition\n \t\t\t} else {\n-\t\t\t\tif tokenClass != rakuPod {\n+\t\t\t\tvar podRegex *regexp2.Regexp\n+\t\t\t\tif tokenClass == rakuPod {\n+\t\t\t\t\tpodRegex = regexp2.MustCompile(\n+\t\t\t\t\t\tstate.NamedGroups[`ws`]+`=end`+`\\s+`+regexp2.Escape(state.NamedGroups[`name`]),\n+\t\t\t\t\t\t0,\n+\t\t\t\t\t)\n+\t\t\t\t} else {\n \t\t\t\t\tclosingChars = []rune(strings.Repeat(string(closingChar), nChars))\n \t\t\t\t}\n \n@@ -450,8 +473,19 @@ func rakuRules() Rules {\n \t\t\t\tvar nextClosePos int\n \n \t\t\t\tfor nestingLevel > 0 {\n+\t\t\t\t\tif tokenClass == rakuPod {\n+\t\t\t\t\t\tmatch, err := podRegex.FindRunesMatchStartingAt(text, searchPos+nChars)\n+\t\t\t\t\t\tif err == nil {\n+\t\t\t\t\t\t\tclosingChars = match.Runes()\n+\t\t\t\t\t\t\tnextClosePos = match.Index\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnextClosePos = -1\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tnextClosePos = indexAt(text, closingChars, searchPos+nChars)\n+\t\t\t\t\t}\n+\n \t\t\t\t\tnextOpenPos := indexAt(text, openingChars, searchPos+nChars)\n-\t\t\t\t\tnextClosePos = indexAt(text, closingChars, searchPos+nChars)\n \n \t\t\t\t\tswitch {\n \t\t\t\t\tcase nextClosePos == -1:\n@@ -479,14 +513,24 @@ func rakuRules() Rules {\n \n \t\t\tadverbre := regexp.MustCompile(`:to\\b|:heredoc\\b`)\n \t\t\tvar heredocTerminator []rune\n+\t\t\tvar endHeredocPos int\n \t\t\tif adverbre.MatchString(string(adverbs)) {\n-\t\t\t\theredocTerminator = text[state.Pos:endPos]\n-\t\t\t\tif len(heredocTerminator) > 0 {\n-\t\t\t\t\tendHeredocPos := indexAt(text[endPos:], heredocTerminator, 0)\n+\t\t\t\tif endPos != len(text) {\n+\t\t\t\t\theredocTerminator = text[state.Pos:endPos]\n \t\t\t\t\tnChars = len(heredocTerminator)\n-\t\t\t\t\tendPos += endHeredocPos\n \t\t\t\t} else {\n-\t\t\t\t\tendPos = len(text)\n+\t\t\t\t\tendPos = state.Pos + 1\n+\t\t\t\t\theredocTerminator = []rune{}\n+\t\t\t\t\tnChars = 0\n+\t\t\t\t}\n+\n+\t\t\t\tif nChars > 0 {\n+\t\t\t\t\tendHeredocPos = indexAt(text[endPos:], heredocTerminator, 0)\n+\t\t\t\t\tif endHeredocPos > -1 {\n+\t\t\t\t\t\tendPos += endHeredocPos\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tendPos = len(text)\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \n@@ -498,18 +542,22 @@ func rakuRules() Rules {\n \t\t\tcase rakuQuote:\n \t\t\t\tif len(heredocTerminator) > 0 {\n \t\t\t\t\t// Length of heredoc terminator + closing chars + `;`\n-\t\t\t\t\theredocFristPunctuationLen := len(heredocTerminator) + len(openingChars) + 1\n+\t\t\t\t\theredocFristPunctuationLen := nChars + len(openingChars) + 1\n \n \t\t\t\t\tstate.NamedGroups[`opening_delimiters`] = string(openingChars) +\n \t\t\t\t\t\tstring(text[state.Pos:state.Pos+heredocFristPunctuationLen])\n \n \t\t\t\t\tstate.NamedGroups[`value`] =\n \t\t\t\t\t\tstring(text[state.Pos+heredocFristPunctuationLen : endPos])\n \n-\t\t\t\t\tstate.NamedGroups[`closing_delimiters`] = string(heredocTerminator)\n+\t\t\t\t\tif endHeredocPos > -1 {\n+\t\t\t\t\t\tstate.NamedGroups[`closing_delimiters`] = string(heredocTerminator)\n+\t\t\t\t\t}\n \t\t\t\t} else {\n \t\t\t\t\tstate.NamedGroups[`value`] = textBetweenBrackets\n-\t\t\t\t\tstate.NamedGroups[`closing_delimiters`] = string(closingChars)\n+\t\t\t\t\tif nChars > 0 {\n+\t\t\t\t\t\tstate.NamedGroups[`closing_delimiters`] = string(closingChars)\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\tdefault:\n \t\t\t\tstate.Groups = []string{state.Groups[0] + string(text[state.Pos:endPos+nChars])}\n@@ -522,12 +570,17 @@ func rakuRules() Rules {\n \t}\n \n \t// Raku rules\n-\t// Empty capture groups are placeholders and will be replaced by bracketsFinder.\n+\t// Empty capture groups are placeholders and will be replaced by mutators\n \t// DO NOT REMOVE THEM!\n \treturn Rules{\n \t\t\"root\": {\n+\t\t\t// Placeholder, will be overwritten by mutators, DO NOT REMOVE!\n+\t\t\t{`\\A\\z`, nil, nil},\n \t\t\tInclude(\"common\"),\n-\t\t\t{`[{}();]`, Punctuation, nil},\n+\t\t\t{`{`, Punctuation, Push(`root`)},\n+\t\t\t{`\\(`, Punctuation, Push(`root`)},\n+\t\t\t{`[)}]`, Punctuation, Pop(1)},\n+\t\t\t{`;`, Punctuation, nil},\n \t\t\t{`\\[|\\]`, Operator, nil},\n \t\t\t{`.+?`, Text, nil},\n \t\t},\n@@ -538,14 +591,14 @@ func rakuRules() Rules {\n \t\t\t{\n \t\t\t\t\"#`(?<opening_delimiters>(?<delimiter>\" + bracketsPattern + `)\\k<delimiter>*)`,\n \t\t\t\tCommentMultiline,\n-\t\t\t\tbracketsFinder(rakuMultilineComment),\n+\t\t\t\tfindBrackets(rakuMultilineComment),\n \t\t\t},\n \t\t\t{`#[^\\n]*$`, CommentSingle, nil},\n \t\t\t// /regex/\n \t\t\t{\n-\t\t\t\t`(?<=(?:^|\\(|=|:|~~|\\[|,|=>)\\s*)(/)(?!\\]|\\))((?:\\\\\\\\|\\\\/|.)*?)((?<!(?<!\\\\)\\\\)/(?!'|\"))`,\n+\t\t\t\t`(?<=(?:^|\\(|=|:|~~|\\[|{|,|=>)\\s*)(/)(?!\\]|\\))((?:\\\\\\\\|\\\\/|.)*?)((?<!(?<!\\\\)\\\\)/(?!'|\"))`,\n \t\t\t\tByGroups(Punctuation, UsingSelf(\"regex\"), Punctuation),\n-\t\t\t\tMutatorFunc(makeRegexPoppingRule),\n+\t\t\t\tnil,\n \t\t\t},\n \t\t\tInclude(\"variable\"),\n \t\t\t// ::?VARIABLE\n@@ -567,9 +620,9 @@ func rakuRules() Rules {\n \t\t\t{`(>>)(\\S+?)(>>)`, ByGroups(Operator, UsingSelf(\"root\"), Operator), nil},\n \t\t\t{`()(\\S+?)()`, ByGroups(Operator, UsingSelf(\"root\"), Operator), nil},\n \t\t\t// <<quoted words>>\n-\t\t\t{`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%][\\w':-]+\\s+|[\\])}]\\s+)\\s*)(<<)(?!(?:(?!>>)[^\\n])+?[},;] *\\n)(?!(?:(?!>>).)+?>>\\S+?>>)`, Punctuation, Push(\"<<\")},\n+\t\t\t{`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?[\\w':-]+\\s+|[\\])}]\\s+)\\s*)(<<)(?!(?:(?!>>)[^\\n])+?[},;] *\\n)(?!(?:(?!>>).)+?>>\\S+?>>)`, Punctuation, Push(\"<<\")},\n \t\t\t// quoted words\n-\t\t\t{`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%][\\w':-]+\\s+|[\\])}]\\s+)\\s*)()(?![^]+?[},;] *\\n)(?![^]+?\\S+?)`, Punctuation, Push(\"\")},\n+\t\t\t{`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?[\\w':-]+\\s+|[\\])}]\\s+)\\s*)()(?![^]+?[},;] *\\n)(?![^]+?\\S+?)`, Punctuation, Push(\"\")},\n \t\t\t// [<]\n \t\t\t{`(?<=\\[\\\\?)<(?=\\])`, Operator, nil},\n \t\t\t// < and > operators | something < onething > something\n@@ -580,39 +633,25 @@ func rakuRules() Rules {\n \t\t\t},\n \t\t\t// <quoted words>\n \t\t\t{\n-\t\t\t\t`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%][\\w':-]+\\s+|[\\])}]\\s+)\\s*)(<)((?:(?![,;)}] *(?:#[^\\n]+)?\\n)[^<>])+?)(>)(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\w[\\w':-]*[^(]|\\s+\\[))`,\n+\t\t\t\t`(?<!(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?[\\w':-]+\\s+|[\\])}]\\s+)\\s*)(<)((?:(?![,;)}] *(?:#[^\\n]+)?\\n)[^<>])+?)(>)(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?\\w[\\w':-]*[^(]|\\s+\\[))`,\n \t\t\t\tByGroups(Punctuation, String, Punctuation),\n \t\t\t\tnil,\n \t\t\t},\n \t\t\t{`C?X::['\\w:-]+`, NameException, nil},\n \t\t\tInclude(\"metaoperator\"),\n-\t\t\t// Pair | (key) => value\n-\t\t\t{\n-\t\t\t\t`(\\([^)]+\\))(\\s*)(=>)(\\s*)([^,\\n]+)(,?\\n*)`,\n-\t\t\t\tByGroups(UsingSelf(\"root\"), Text, Operator, Text, UsingSelf(\"root\"), Text),\n-\t\t\t\tnil,\n-\t\t\t},\n \t\t\t// Pair | key => value\n \t\t\t{\n-\t\t\t\t`(\\w[\\w'-]*)(\\s*)(=>)(\\s*)([^,\\n]+)(,?\\n*)`,\n-\t\t\t\tByGroups(String, Text, Operator, Text, UsingSelf(\"root\"), Text),\n+\t\t\t\t`(\\w[\\w'-]*)(\\s*)(=>)`,\n+\t\t\t\tByGroups(String, Text, Operator),\n \t\t\t\tnil,\n \t\t\t},\n \t\t\tInclude(\"colon-pair\"),\n \t\t\t// Token\n \t\t\t{\n-\t\t\t\t// Token with adverbs\n-\t\t\t\t`(?<=(?:^|\\s)(?:regex|token|rule)(\\s+))(['\\w:-]+)(?=:['\\w-]+` +\n-\t\t\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `[({])`,\n+\t\t\t\t`(?<=(?:^|\\s)(?:regex|token|rule)(\\s+))` + namePattern + colonPairLookahead + `\\s*[({])`,\n \t\t\t\tNameFunction,\n \t\t\t\tPush(\"token\", \"name-adverb\"),\n \t\t\t},\n-\t\t\t{\n-\t\t\t\t// Token without adverbs\n-\t\t\t\t`(?<=(?:^|\\s)(?:regex|token|rule)(?:\\s+))(['\\w:-]+)`,\n-\t\t\t\tNameFunction,\n-\t\t\t\tPush(\"token\"),\n-\t\t\t},\n \t\t\t// Substitution\n \t\t\t{`(?<=^|\\b|\\s)(?<!\\.)(ss|S|s|TR|tr)\\b(\\s*)`, ByGroups(Keyword, Text), Push(\"substitution\")},\n \t\t\t{keywordsPattern, Keyword, nil},\n@@ -626,18 +665,10 @@ func rakuRules() Rules {\n \t\t\t},\n \t\t\t//  Routine\n \t\t\t{\n-\t\t\t\t// Routine with adverbs\n-\t\t\t\t`(?<=(?:^|\\s)(?:sub|method|multi sub|multi)\\s+)!?['\\w:-]+(?=:['\\w-]+` +\n-\t\t\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `[({])`,\n+\t\t\t\t`(?<=(?:^|\\s)(?:sub|method|multi sub|multi)\\s+)!?` + namePattern + colonPairLookahead + `\\s*[({])`,\n \t\t\t\tNameFunction,\n \t\t\t\tPush(\"name-adverb\"),\n \t\t\t},\n-\t\t\t{\n-\t\t\t\t// Routine without adverbs\n-\t\t\t\t`(?<=(?:^|\\s)(?:sub|submethod|method|multi)\\s+)!?['\\w:-]+`,\n-\t\t\t\tNameFunction,\n-\t\t\t\tnil,\n-\t\t\t},\n \t\t\t// Constant\n \t\t\t{`(?<=\\bconstant\\s+)` + namePattern, NameConstant, Push(\"name-adverb\")},\n \t\t\t// Namespace\n@@ -651,26 +682,20 @@ func rakuRules() Rules {\n \t\t\t{\n \t\t\t\t`(?<=^|\\b|\\s)(?<keyword>(?:qq|q|Q))(?<adverbs>(?::?(?:heredoc|to|qq|ww|q|w|s|a|h|f|c|b|to|v|x))*)(?<ws>\\s*)(?<opening_delimiters>(?<delimiter>[^0-9a-zA-Z:\\s])\\k<delimiter>*)`,\n \t\t\t\tEmitterFunc(quote),\n-\t\t\t\tbracketsFinder(rakuQuote),\n+\t\t\t\tfindBrackets(rakuQuote),\n \t\t\t},\n \t\t\t// Function\n \t\t\t{\n-\t\t\t\t`\\b(?:\\w['\\w:-]*)(?=:['\\w-]+` +\n-\t\t\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `\\()`,\n+\t\t\t\t`\\b` + namePattern + colonPairLookahead + `\\()`,\n \t\t\t\tNameFunction,\n \t\t\t\tPush(\"name-adverb\"),\n \t\t\t},\n-\t\t\t{`\\b(?:\\w['\\w:-]*)(?=\\()`, NameFunction, nil},\n \t\t\t// Method\n-\t\t\t// Method with adverb\n \t\t\t{\n-\t\t\t\t`(?<!\\.\\.[?^*+]?)(?<=(?:\\.[?^*+&]?)|self!)['\\w:-]+(?=:['\\w-]+` +\n-\t\t\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `$)`,\n+\t\t\t\t`(?<!\\.\\.[?^*+]?)(?<=(?:\\.[?^*+&]?)|self!)` + namePattern + colonPairLookahead + `\\b)`,\n \t\t\t\tNameFunction,\n \t\t\t\tPush(\"name-adverb\"),\n \t\t\t},\n-\t\t\t// Method without adverb\n-\t\t\t{`(?<!\\.\\.[?^*+]?)(?<=(?:\\.[?^*+&]?)|self!)['\\w:-]+`, NameFunction, nil},\n \t\t\t// Indirect invocant\n \t\t\t{namePattern + `(?=\\s+\\W?['\\w:-]+:\\W)`, NameFunction, Push(\"name-adverb\")},\n \t\t\t{`(?<=\\W)(?:|i|e||tau||pi||Inf|)(?=\\W)`, NameConstant, nil},\n@@ -688,11 +713,13 @@ func rakuRules() Rules {\n \t\t\tInclude(\"colon-pair-attribute\"),\n \t\t\t{\n \t\t\t\t`(?<opening_delimiters>(?<delimiter>[^\\w:\\s])\\k<delimiter>*)`,\n-\t\t\t\tByGroupNames(map[string]Emitter{\n-\t\t\t\t\t`opening_delimiters`: Punctuation,\n-\t\t\t\t\t`delimiter`:          nil,\n-\t\t\t\t}),\n-\t\t\t\tMutators(Pop(1), bracketsFinder(rakuMatchRegex)),\n+\t\t\t\tByGroupNames(\n+\t\t\t\t\tmap[string]Emitter{\n+\t\t\t\t\t\t`opening_delimiters`: Punctuation,\n+\t\t\t\t\t\t`delimiter`:          nil,\n+\t\t\t\t\t},\n+\t\t\t\t),\n+\t\t\t\tfindBrackets(rakuMatchRegex),\n \t\t\t},\n \t\t},\n \t\t\"substitution\": {\n@@ -704,15 +731,13 @@ func rakuRules() Rules {\n \t\t\t\t\t`opening_delimiters`: Punctuation,\n \t\t\t\t\t`delimiter`:          nil,\n \t\t\t\t}),\n-\t\t\t\tMutators(Pop(1), bracketsFinder(rakuSubstitutionSingleRegex)),\n+\t\t\t\tfindBrackets(rakuMatchRegex),\n \t\t\t},\n \t\t\t// Substitution | s/regex/string/\n \t\t\t{\n-\t\t\t\t`([^\\w:\\s])((?:\\\\\\\\|\\\\/|.)*?)(\\1)((?:\\\\\\\\|\\\\/|.)*?)(\\1)`,\n-\t\t\t\tByGroups(\n-\t\t\t\t\tPunctuation, UsingSelf(\"regex\"), Punctuation, UsingSelf(\"qq\"), Punctuation,\n-\t\t\t\t),\n-\t\t\t\tMutators(Pop(1), MutatorFunc(makeRegexPoppingRule)),\n+\t\t\t\t`(?<opening_delimiters>[^\\w:\\s])`,\n+\t\t\t\tPunctuation,\n+\t\t\t\tfindBrackets(rakuSubstitutionRegex),\n \t\t\t},\n \t\t},\n \t\t\"number\": {\n@@ -734,33 +759,33 @@ func rakuRules() Rules {\n \t\t},\n \t\t\"colon-pair\": {\n \t\t\t// :key(value)\n-\t\t\t{colonPairPattern, colonPair(String), bracketsFinder(rakuNameAttribute)},\n+\t\t\t{colonPairPattern, colonPair(String), findBrackets(rakuNameAttribute)},\n \t\t\t// :123abc\n \t\t\t{\n-\t\t\t\t`(:)(\\d+)(\\w[\\w'-]*)(\\s*[,;)]?\\s*$)`,\n-\t\t\t\tByGroups(Punctuation, UsingSelf(\"number\"), String, Text),\n+\t\t\t\t`(:)(\\d+)(\\w[\\w'-]*)`,\n+\t\t\t\tByGroups(Punctuation, UsingSelf(\"number\"), String),\n \t\t\t\tnil,\n \t\t\t},\n \t\t\t// :key\n-\t\t\t{`(:!?)(\\w[\\w'-]*)`, ByGroups(Punctuation, String), nil},\n+\t\t\t{`(:)(!?)(\\w[\\w'-]*)`, ByGroups(Punctuation, Operator, String), nil},\n \t\t\t{`\\s+`, Text, nil},\n \t\t},\n \t\t\"colon-pair-attribute\": {\n \t\t\t// :key(value)\n-\t\t\t{colonPairPattern, colonPair(NameAttribute), bracketsFinder(rakuNameAttribute)},\n+\t\t\t{colonPairPattern, colonPair(NameAttribute), findBrackets(rakuNameAttribute)},\n \t\t\t// :123abc\n \t\t\t{\n-\t\t\t\t`(:)(\\d+)(\\w+)(\\s*[,;)]?\\s*$)`,\n-\t\t\t\tByGroups(Punctuation, UsingSelf(\"number\"), NameAttribute, Text),\n+\t\t\t\t`(:)(\\d+)(\\w[\\w'-]*)`,\n+\t\t\t\tByGroups(Punctuation, UsingSelf(\"number\"), NameAttribute),\n \t\t\t\tnil,\n \t\t\t},\n \t\t\t// :key\n-\t\t\t{`(:!?)(\\w[\\w'-]*)`, ByGroups(Punctuation, NameAttribute), nil},\n+\t\t\t{`(:)(!?)(\\w[\\w'-]*)`, ByGroups(Punctuation, Operator, NameAttribute), nil},\n \t\t\t{`\\s+`, Text, nil},\n \t\t},\n \t\t\"colon-pair-attribute-keyvalue\": {\n \t\t\t// :key(value)\n-\t\t\t{colonPairPattern, colonPair(NameAttribute), bracketsFinder(rakuNameAttribute)},\n+\t\t\t{colonPairPattern, colonPair(NameAttribute), findBrackets(rakuNameAttribute)},\n \t\t},\n \t\t\"escape-qq\": {\n \t\t\t{\n@@ -769,6 +794,12 @@ func rakuRules() Rules {\n \t\t\t\tnil,\n \t\t\t},\n \t\t},\n+\t\t`escape-char`: {\n+\t\t\t{`(?<!(?<!\\\\)\\\\)(\\\\[abfrnrt])`, StringEscape, nil},\n+\t\t},\n+\t\t`escape-single-quote`: {\n+\t\t\t{`(?<!(?<!\\\\)\\\\)(\\\\)(['\\\\])`, ByGroups(StringEscape, StringSingle), nil},\n+\t\t},\n \t\t\"escape-c-name\": {\n \t\t\t{\n \t\t\t\t`(?<!(?<!\\\\)\\\\)(\\\\[c|C])(\\[)(.+?)(\\])`,\n@@ -785,14 +816,20 @@ func rakuRules() Rules {\n \t\t\t{`(\\\\[x|X])([0-9a-fA-F]+)`, ByGroups(StringEscape, NumberHex), nil},\n \t\t},\n \t\t\"regex\": {\n-\t\t\t// Placeholder, will be overwritten by bracketsFinder, DO NOT REMOVE!\n-\t\t\t{`^$`, nil, nil},\n+\t\t\t// Placeholder, will be overwritten by mutators, DO NOT REMOVE!\n+\t\t\t{`\\A\\z`, nil, nil},\n \t\t\tInclude(\"regex-escape-class\"),\n+\t\t\tInclude(`regex-character-escape`),\n \t\t\t// $(code)\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)([$@])(\\()(.*?)(\\))`,\n-\t\t\t\tByGroups(Keyword, Punctuation, UsingSelf(\"root\"), Punctuation),\n-\t\t\t\tnil,\n+\t\t\t\t`([$@])((?<!(?<!\\\\)\\\\)\\()`,\n+\t\t\t\tByGroups(Keyword, Punctuation),\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`)`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n \t\t\t// Exclude $/ from variables, because we can't get out of the end of the slash regex: $/;\n \t\t\t{`\\$(?=/)`, NameEntity, nil},\n@@ -805,18 +842,28 @@ func rakuRules() Rules {\n \t\t\tInclude(\"single-quote\"),\n \t\t\t// :my variable code ...\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)(:)(my|our|state|constant|temp|let)(.+?;)`,\n-\t\t\t\tByGroups(Operator, KeywordDeclaration, UsingSelf(\"root\")),\n-\t\t\t\tnil,\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(:)(my|our|state|constant|temp|let)`,\n+\t\t\t\tByGroups(Operator, KeywordDeclaration),\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`;`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n \t\t\t// <{code}>\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([?!])?((?<!(?<!\\\\)\\\\){)(.*?)(}>)`,\n-\t\t\t\tByGroups(Punctuation, Operator, Punctuation, UsingSelf(\"root\"), Punctuation),\n-\t\t\t\tnil,\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([?!.]*)((?<!(?<!\\\\)\\\\){)`,\n+\t\t\t\tByGroups(Punctuation, Operator, Punctuation),\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`}>`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n \t\t\t// {code}\n-\t\t\t{`(?<!(?<!\\\\)\\\\)({)(.*?)(})`, ByGroups(Punctuation, UsingSelf(\"root\"), Punctuation), nil},\n+\t\t\tInclude(`closure`),\n \t\t\t// Properties\n \t\t\t{`(:)(\\w+)`, ByGroups(Punctuation, NameAttribute), nil},\n \t\t\t// Operator\n@@ -827,9 +874,14 @@ func rakuRules() Rules {\n \t\t\t{`#[^\\n]*\\n`, CommentSingle, nil},\n \t\t\t// Lookaround\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)(\\s*)([?!.])(\\s*)(after|before)`,\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)(\\s*)([?!.]+)(\\s*)(after|before)`,\n \t\t\t\tByGroups(Punctuation, Text, Operator, Text, OperatorWord),\n-\t\t\t\tPush(\"regex\"),\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`>`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `regex`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n \t\t\t{\n \t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([|!?.]*)(wb|ww|ws|w)(>)`,\n@@ -838,15 +890,25 @@ func rakuRules() Rules {\n \t\t\t},\n \t\t\t// <$variable>\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([$@]\\w[\\w-:]*)(>)`,\n-\t\t\t\tByGroups(Punctuation, NameVariable, Punctuation),\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([?!.]*)([$@]\\w[\\w:-]*)(>)`,\n+\t\t\t\tByGroups(Punctuation, Operator, NameVariable, Punctuation),\n \t\t\t\tnil,\n \t\t\t},\n \t\t\t// Capture markers\n \t\t\t{`(?<!(?<!\\\\)\\\\)<\\(|\\)>`, Operator, nil},\n+\t\t\t{\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)(\\w[\\w:-]*)(=\\.?)`,\n+\t\t\t\tByGroups(Punctuation, NameVariable, Operator),\n+\t\t\t\tPush(`regex-variable`),\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(<)([|!?.&]*)(\\w(?:(?!:\\s)[\\w':-])*)`,\n+\t\t\t\tByGroups(Punctuation, Operator, NameFunction),\n+\t\t\t\tPush(`regex-function`),\n+\t\t\t},\n \t\t\t{`(?<!(?<!\\\\)\\\\)<`, Punctuation, Push(\"regex-property\")},\n \t\t\t{`(?<!(?<!\\\\)\\\\)\"`, Punctuation, Push(\"double-quotes\")},\n-\t\t\t{`(?<!(?<!\\\\)\\\\)(?:\\]|\\)|>)`, Punctuation, Pop(1)},\n+\t\t\t{`(?<!(?<!\\\\)\\\\)(?:\\]|\\))`, Punctuation, Pop(1)},\n \t\t\t{`(?<!(?<!\\\\)\\\\)(?:\\[|\\()`, Punctuation, Push(\"regex\")},\n \t\t\t{`.+?`, StringRegex, nil},\n \t\t},\n@@ -857,41 +919,85 @@ func rakuRules() Rules {\n \t\t\t\tnil,\n \t\t\t},\n \t\t},\n-\t\t\"regex-property\": {\n+\t\t\"regex-function\": {\n+\t\t\t// <function>\n \t\t\t{`(?<!(?<!\\\\)\\\\)>`, Punctuation, Pop(1)},\n-\t\t\tInclude(\"regex-class-builtin\"),\n-\t\t\tInclude(\"variable\"),\n-\t\t\t// <regexfunc> | <regexfunc(parameter)> | <variable=regexfunc>\n+\t\t\t// <function(parameter)>\n \t\t\t{\n-\t\t\t\t`(?:(\\w[\\w-:]*)(=\\.?))?(&?\\w[\\w'-:]+?)(\\(.+?\\))?(?=>)`,\n-\t\t\t\tByGroups(\n-\t\t\t\t\tNameVariable, Operator, NameFunction, UsingSelf(\"root\"),\n-\t\t\t\t),\n-\t\t\t\tnil,\n+\t\t\t\t`\\(`,\n+\t\t\t\tPunctuation,\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`)>`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpopState:  true,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n-\t\t\t// <func: value>\n+\t\t\t// <function value>\n \t\t\t{\n-\t\t\t\t`(&?\\w[\\w':-]*?)(:)((?:.*?(?:\\$<\\w[\\w':-]*>)?.*?)*?)(?=>)`,\n-\t\t\t\tByGroups(\n-\t\t\t\t\tNameFunction, Punctuation, UsingSelf(\"root\"),\n-\t\t\t\t),\n-\t\t\t\tnil,\n+\t\t\t\t`\\s+`,\n+\t\t\t\tStringRegex,\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`>`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `regex`,\n+\t\t\t\t\tpopState:  true,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n+\t\t\t},\n+\t\t\t// <function: value>\n+\t\t\t{\n+\t\t\t\t`:`,\n+\t\t\t\tPunctuation,\n+\t\t\t\treplaceRule(ruleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`>`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpopState:  true,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n \t\t\t},\n+\t\t},\n+\t\t\"regex-variable\": {\n+\t\t\tInclude(`regex-starting-operators`),\n+\t\t\t// <var=function(\n+\t\t\t{\n+\t\t\t\t`(&)?(\\w(?:(?!:\\s)[\\w':-])*)(?=\\()`,\n+\t\t\t\tByGroups(Operator, NameFunction),\n+\t\t\t\tMutators(Pop(1), Push(`regex-function`)),\n+\t\t\t},\n+\t\t\t// <var=function>\n+\t\t\t{`(&)?(\\w[\\w':-]*)(>)`, ByGroups(Operator, NameFunction, Punctuation), Pop(1)},\n+\t\t\t// <var=\n+\t\t\tDefault(Pop(1), Push(`regex-property`)),\n+\t\t},\n+\t\t\"regex-property\": {\n+\t\t\t{`(?<!(?<!\\\\)\\\\)>`, Punctuation, Pop(1)},\n+\t\t\tInclude(\"regex-class-builtin\"),\n+\t\t\tInclude(\"variable\"),\n+\t\t\tInclude(`regex-starting-operators`),\n \t\t\tInclude(\"colon-pair-attribute\"),\n \t\t\t{`(?<!(?<!\\\\)\\\\)\\[`, Punctuation, Push(\"regex-character-class\")},\n \t\t\t{`\\+|\\-`, Operator, nil},\n-\t\t\t{`@[\\w'-:]+`, NameVariable, nil},\n-\t\t\t{`(?<=<)[|!?.]`, Operator, nil},\n+\t\t\t{`@[\\w':-]+`, NameVariable, nil},\n \t\t\t{`.+?`, StringRegex, nil},\n \t\t},\n+\t\t`regex-starting-operators`: {\n+\t\t\t{`(?<=<)[|!?.]+`, Operator, nil},\n+\t\t},\n \t\t\"regex-escape-class\": {\n \t\t\t{`(?i)\\\\n|\\\\t|\\\\h|\\\\v|\\\\s|\\\\d|\\\\w`, StringEscape, nil},\n \t\t},\n+\t\t`regex-character-escape`: {\n+\t\t\t{`(?<!(?<!\\\\)\\\\)(\\\\)(.)`, ByGroups(StringEscape, StringRegex), nil},\n+\t\t},\n \t\t\"regex-character-class\": {\n \t\t\t{`(?<!(?<!\\\\)\\\\)\\]`, Punctuation, Pop(1)},\n \t\t\tInclude(\"regex-escape-class\"),\n \t\t\tInclude(\"escape-c-name\"),\n \t\t\tInclude(\"escape-hexadecimal\"),\n+\t\t\tInclude(`regex-character-escape`),\n \t\t\tInclude(\"number\"),\n \t\t\t{`\\.\\.`, Operator, nil},\n \t\t\t{`.+?`, StringRegex, nil},\n@@ -923,10 +1029,10 @@ func rakuRules() Rules {\n \t\t\t\t\t\t`keyword`:            Keyword,\n \t\t\t\t\t\t`opening_delimiters`: Punctuation,\n \t\t\t\t\t\t`delimiter`:          nil,\n-\t\t\t\t\t\t`value`:              UsingSelf(\"pod-begin\"),\n+\t\t\t\t\t\t`value`:              UsingSelf(\"pod-declaration\"),\n \t\t\t\t\t\t`closing_delimiters`: Punctuation,\n \t\t\t\t\t}),\n-\t\t\t\tbracketsFinder(rakuPodDeclaration),\n+\t\t\t\tfindBrackets(rakuPodDeclaration),\n \t\t\t},\n \t\t\tInclude(\"pod-blocks\"),\n \t\t},\n@@ -950,7 +1056,7 @@ func rakuRules() Rules {\n \t\t\t\t\t\t`value`:              UsingSelf(\"pod-begin\"),\n \t\t\t\t\t\t`closing_delimiters`: Keyword,\n \t\t\t\t\t}),\n-\t\t\t\tbracketsFinder(rakuPod),\n+\t\t\t\tfindBrackets(rakuPod),\n \t\t\t},\n \t\t\t// =for ...\n \t\t\t{\n@@ -986,13 +1092,13 @@ func rakuRules() Rules {\n \t\t\t{\n \t\t\t\t`(?<=^ *)(?<ws> *)(?<keyword>=head\\d+)(?<ws2> *)(?<config>#?)`,\n \t\t\t\tByGroups(Comment, Keyword, GenericHeading, Keyword),\n-\t\t\t\tPush(\"pod-single-heading\"),\n+\t\t\t\tPush(\"pod-heading\"),\n \t\t\t},\n \t\t\t// =item ...\n \t\t\t{\n \t\t\t\t`(?<=^ *)(?<ws> *)(?<keyword>=(?:item\\d*|comment|data|[A-Z]+))(?<ws2> *)(?<config>#?)`,\n \t\t\t\tByGroups(Comment, Keyword, StringDoc, Keyword),\n-\t\t\t\tPush(\"pod-single\"),\n+\t\t\t\tPush(\"pod-paragraph\"),\n \t\t\t},\n \t\t\t{\n \t\t\t\t`(?<=^ *)(?<ws> *)(?<keyword>=finish)(?<config>[^\\n]*)`,\n@@ -1003,7 +1109,7 @@ func rakuRules() Rules {\n \t\t\t{\n \t\t\t\t`(?<=^ *)(?<ws> *)(?<name>=\\w[\\w'-]*)(?<ws2> *)(?<config>#?)`,\n \t\t\t\tByGroups(Comment, Name, StringDoc, Keyword),\n-\t\t\t\tPush(\"pod-single\"),\n+\t\t\t\tPush(\"pod-paragraph\"),\n \t\t\t},\n \t\t\t// = podconfig\n \t\t\t{\n@@ -1018,8 +1124,12 @@ func rakuRules() Rules {\n \t\t\tInclude(\"pre-pod-formatter\"),\n \t\t\t{`.+?`, StringDoc, nil},\n \t\t},\n+\t\t\"pod-declaration\": {\n+\t\t\tInclude(\"pre-pod-formatter\"),\n+\t\t\t{`.+?`, StringDoc, nil},\n+\t\t},\n \t\t\"pod-paragraph\": {\n-\t\t\t{`\\n\\s*?\\n`, StringDoc, Pop(1)},\n+\t\t\t{`\\n *\\n|\\n(?=^ *=)`, StringDoc, Pop(1)},\n \t\t\tInclude(\"pre-pod-formatter\"),\n \t\t\t{`.+?`, StringDoc, nil},\n \t\t},\n@@ -1028,8 +1138,8 @@ func rakuRules() Rules {\n \t\t\tInclude(\"pre-pod-formatter\"),\n \t\t\t{`.+?`, StringDoc, nil},\n \t\t},\n-\t\t\"pod-single-heading\": {\n-\t\t\t{`\\n`, GenericHeading, Pop(1)},\n+\t\t\"pod-heading\": {\n+\t\t\t{`\\n *\\n|\\n(?=^ *=)`, GenericHeading, Pop(1)},\n \t\t\tInclude(\"pre-pod-formatter\"),\n \t\t\t{`.+?`, GenericHeading, nil},\n \t\t},\n@@ -1043,32 +1153,29 @@ func rakuRules() Rules {\n \t\t\t{\n \t\t\t\t`(?<keyword>[CBIUDTKRPAELZVMSXN])(?<opening_delimiters><+|)`,\n \t\t\t\tByGroups(Keyword, Punctuation),\n-\t\t\t\tMutators(\n-\t\t\t\t\tbracketsFinder(rakuPodFormatter),\n-\t\t\t\t\tPush(\"pod-formatter\"), MutatorFunc(podFormatter),\n-\t\t\t\t),\n+\t\t\t\tfindBrackets(rakuPodFormatter),\n \t\t\t},\n \t\t},\n \t\t\"pod-formatter\": {\n-\t\t\t// Placeholder rule, will be replaced by podFormatter. DO NOT REMOVE!\n+\t\t\t// Placeholder rule, will be replaced by mutators. DO NOT REMOVE!\n \t\t\t{`>`, Punctuation, Pop(1)},\n \t\t\tInclude(\"pre-pod-formatter\"),\n-\t\t\t// Placeholder rule, will be replaced by podFormatter. DO NOT REMOVE!\n+\t\t\t// Placeholder rule, will be replaced by mutators. DO NOT REMOVE!\n \t\t\t{`.+?`, StringOther, nil},\n \t\t},\n \t\t\"variable\": {\n \t\t\t{variablePattern, NameVariable, Push(\"name-adverb\")},\n \t\t\t{globalVariablePattern, NameVariableGlobal, Push(\"name-adverb\")},\n-\t\t\t{`[$@](?:<.*?>)+`, NameVariable, nil},\n-\t\t\t{`\\$/`, NameVariable, nil},\n-\t\t\t{`\\$!`, NameVariable, nil},\n+\t\t\t{`[$@]<[^>]+>`, NameVariable, nil},\n+\t\t\t{`\\$[/!]`, NameVariable, nil},\n \t\t\t{`[$@%]`, NameVariable, nil},\n \t\t},\n \t\t\"single-quote\": {\n \t\t\t{`(?<!(?<!\\\\)\\\\)'`, Punctuation, Push(\"single-quote-inner\")},\n \t\t},\n \t\t\"single-quote-inner\": {\n \t\t\t{`(?<!(?<!(?<!\\\\)\\\\)\\\\)'`, Punctuation, Pop(1)},\n+\t\t\tInclude(\"escape-single-quote\"),\n \t\t\tInclude(\"escape-qq\"),\n \t\t\t{`(?:\\\\\\\\|\\\\[^\\\\]|[^'\\\\])+?`, StringSingle, nil},\n \t\t},\n@@ -1077,11 +1184,11 @@ func rakuRules() Rules {\n \t\t\tInclude(\"qq\"),\n \t\t},\n \t\t\"<<\": {\n-\t\t\t{`>>(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%][\\w':-]+|\\s+\\[))`, Punctuation, Pop(1)},\n+\t\t\t{`>>(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?[\\w':-]+|\\s+\\[))`, Punctuation, Pop(1)},\n \t\t\tInclude(\"ww\"),\n \t\t},\n \t\t\"\": {\n-\t\t\t{`(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%][\\w':-]+|\\s+\\[))`, Punctuation, Pop(1)},\n+\t\t\t{`(?!\\s*(?:\\d+|\\.(?:Int|Numeric)|[$@%]\\*?[\\w':-]+|\\s+\\[))`, Punctuation, Pop(1)},\n \t\t\tInclude(\"ww\"),\n \t\t},\n \t\t\"ww\": {\n@@ -1090,39 +1197,39 @@ func rakuRules() Rules {\n \t\t},\n \t\t\"qq\": {\n \t\t\tInclude(\"qq-variable\"),\n-\t\t\t// Function with adverb\n-\t\t\t{\n-\t\t\t\t`\\w[\\w:'-]+(?=:['\\w-]+` +\n-\t\t\t\t\tcolonPairOpeningBrackets + `.+?` + colonPairClosingBrackets + `\\()`,\n-\t\t\t\tNameFunction,\n-\t\t\t\tPush(\"qq-function\", \"name-adverb\"),\n-\t\t\t},\n-\t\t\t// Function without adverb\n-\t\t\t{`\\w[\\w:'-]+(?=\\((?!\"))`, NameFunction, Push(\"qq-function\")},\n \t\t\tInclude(\"closure\"),\n+\t\t\tInclude(`escape-char`),\n \t\t\tInclude(\"escape-hexadecimal\"),\n \t\t\tInclude(\"escape-c-name\"),\n \t\t\tInclude(\"escape-qq\"),\n \t\t\t{`.+?`, StringDouble, nil},\n \t\t},\n-\t\t\"qq-function\": {\n-\t\t\t{`(\\([^\"]*?\\))`, UsingSelf(\"root\"), nil},\n-\t\t\tDefault(Pop(1)),\n-\t\t},\n \t\t\"qq-variable\": {\n \t\t\t{\n-\t\t\t\t`(?<!(?<!\\\\)\\\\)(?:` + variablePattern + `|` + globalVariablePattern + `)`,\n+\t\t\t\t`(?<!(?<!\\\\)\\\\)(?:` + variablePattern + `|` + globalVariablePattern + `)` + colonPairLookahead + `)`,\n \t\t\t\tNameVariable,\n \t\t\t\tPush(\"qq-variable-extras\", \"name-adverb\"),\n \t\t\t},\n \t\t},\n \t\t\"qq-variable-extras\": {\n-\t\t\t{`(?:\\[.*?\\]|\\{.*?\\}|<<.*?>>|<.*?>|.*?)+`, UsingSelf(\"root\"), nil},\n \t\t\t// Method\n \t\t\t{\n-\t\t\t\t`(\\.)([^(\\s]+)(\\([^\"]*?\\))`,\n-\t\t\t\tByGroups(Operator, NameFunction, UsingSelf(\"root\")),\n-\t\t\t\tnil,\n+\t\t\t\t`(?<operator>\\.)(?<method_name>` + namePattern + `)` + colonPairLookahead + `\\()`,\n+\t\t\t\tByGroupNames(map[string]Emitter{\n+\t\t\t\t\t`operator`:    Operator,\n+\t\t\t\t\t`method_name`: NameFunction,\n+\t\t\t\t}),\n+\t\t\t\tPush(`name-adverb`),\n+\t\t\t},\n+\t\t\t// Function/Signature\n+\t\t\t{\n+\t\t\t\t`\\(`, Punctuation, replaceRule(\n+\t\t\t\t\truleReplacingConfig{\n+\t\t\t\t\t\tdelimiter: []rune(`)`),\n+\t\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\t\tpushState: true,\n+\t\t\t\t\t}),\n \t\t\t},\n \t\t\tDefault(Pop(1)),\n \t\t},\n@@ -1141,35 +1248,70 @@ func rakuRules() Rules {\n \t\t\t{`.+?`, String, nil},\n \t\t},\n \t\t\"closure\": {\n-\t\t\t{`(?<!(?<!\\\\)\\\\)\\{.+?\\}`, UsingSelf(\"root\"), nil},\n+\t\t\t{`(?<!(?<!\\\\)\\\\){`, Punctuation, replaceRule(\n+\t\t\t\truleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`}`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n+\t\t\t},\n \t\t},\n \t\t\"token\": {\n \t\t\t// Token signature\n-\t\t\t{`(\\()(.+?)(\\))`, ByGroups(Punctuation, UsingSelf(\"root\"), Punctuation), nil},\n-\t\t\t{`\\{`, Punctuation, Mutators(Pop(1), bracketsFinder(rakuRegexInsideToken))},\n-\t\t\t{`.+?`, Text, nil},\n+\t\t\t{`\\(`, Punctuation, replaceRule(\n+\t\t\t\truleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`)`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `root`,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n+\t\t\t},\n+\t\t\t{`{`, Punctuation, replaceRule(\n+\t\t\t\truleReplacingConfig{\n+\t\t\t\t\tdelimiter: []rune(`}`),\n+\t\t\t\t\ttokenType: Punctuation,\n+\t\t\t\t\tstateName: `regex`,\n+\t\t\t\t\tpopState:  true,\n+\t\t\t\t\tpushState: true,\n+\t\t\t\t}),\n+\t\t\t},\n+\t\t\t{`\\s*`, Text, nil},\n+\t\t\tDefault(Pop(1)),\n \t\t},\n \t}\n }\n \n-// Joins keys and values of rune map\n+// Joins keys of rune map\n func joinRuneMap(m map[rune]rune) string {\n-\trunes := make([]rune, 0, len(m)*2)\n-\tfor k, v := range m {\n+\trunes := make([]rune, 0, len(m))\n+\tfor k := range m {\n \t\trunes = append(runes, k)\n-\t\trunes = append(runes, v)\n \t}\n \n \treturn string(runes)\n }\n \n // Finds the index of substring in the string starting at position n\n func indexAt(str []rune, substr []rune, pos int) int {\n-\ttext := string(str[pos:])\n+\tstrFromPos := str[pos:]\n+\ttext := string(strFromPos)\n \n \tidx := strings.Index(text, string(substr))\n \tif idx > -1 {\n \t\tidx = utf8.RuneCountInString(text[:idx])\n+\n+\t\t// Search again if the substr is escaped with backslash\n+\t\tif (idx > 1 && strFromPos[idx-1] == '\\\\' && strFromPos[idx-2] != '\\\\') ||\n+\t\t\t(idx == 1 && strFromPos[idx-1] == '\\\\') {\n+\t\t\tidx = indexAt(str[pos:], substr, idx+1)\n+\n+\t\t\tidx = utf8.RuneCountInString(text[:idx])\n+\n+\t\t\tif idx < 0 {\n+\t\t\t\treturn idx\n+\t\t\t}\n+\t\t}\n \t\tidx += pos\n \t}\n \n@@ -1186,107 +1328,190 @@ func contains(s []string, e string) bool {\n \treturn false\n }\n \n-type RakuFormatterRules struct {\n-\tpop, formatter *CompiledRule\n+type rulePosition int\n+\n+const (\n+\ttopRule    rulePosition = 0\n+\tbottomRule              = -1\n+)\n+\n+type ruleMakingConfig struct {\n+\tdelimiter              []rune\n+\tpattern                string\n+\ttokenType              Emitter\n+\tmutator                Mutator\n+\tnumberOfDelimiterChars int\n }\n \n-// Pop from the pod_formatter_stack and reformat the pod code\n-func podFormatterPopper(state *LexerState) error {\n-\tstack, ok := state.Get(\"pod_formatter_stack\").([]RakuFormatterRules)\n+type ruleReplacingConfig struct {\n+\tdelimiter              []rune\n+\tpattern                string\n+\ttokenType              Emitter\n+\tnumberOfDelimiterChars int\n+\tmutator                Mutator\n+\tappendMutator          Mutator\n+\trulePosition           rulePosition\n+\tstateName              string\n+\tpop                    bool\n+\tpopState               bool\n+\tpushState              bool\n+}\n \n-\tif ok && len(stack) > 0 {\n-\t\t// Pop from stack\n-\t\tstack = stack[:len(stack)-1]\n-\t\tstate.Set(\"pod_formatter_stack\", stack)\n-\t\t// Call podFormatter to use the last formatter rules\n-\t\terr := podFormatter(state)\n-\t\tif err != nil {\n-\t\t\tpanic(err)\n+// Pops rule from state-stack and replaces the rule with the previous rule\n+func popRule(rule ruleReplacingConfig) MutatorFunc {\n+\treturn func(state *LexerState) error {\n+\t\tstackName := genStackName(rule.stateName, rule.rulePosition)\n+\n+\t\tstack, ok := state.Get(stackName).([]ruleReplacingConfig)\n+\n+\t\tif ok && len(stack) > 0 {\n+\t\t\t// Pop from stack\n+\t\t\tstack = stack[:len(stack)-1]\n+\t\t\tlastRule := stack[len(stack)-1]\n+\t\t\tlastRule.pushState = false\n+\t\t\tlastRule.popState = false\n+\t\t\tlastRule.pop = true\n+\t\t\tstate.Set(stackName, stack)\n+\n+\t\t\t// Call replaceRule to use the last rule\n+\t\t\terr := replaceRule(lastRule)(state)\n+\t\t\tif err != nil {\n+\t\t\t\tpanic(err)\n+\t\t\t}\n \t\t}\n-\t}\n \n-\treturn nil\n+\t\treturn nil\n+\t}\n }\n \n-// Use the rules from pod_formatter_stack to format the pod code\n-func podFormatter(state *LexerState) error {\n-\tstack, ok := state.Get(\"pod_formatter_stack\").([]RakuFormatterRules)\n-\tif ok && len(stack) > 0 {\n-\t\trules := stack[len(stack)-1]\n-\t\tstate.Rules[\"pod-formatter\"][0] = rules.pop\n-\t\tstate.Rules[\"pod-formatter\"][len(state.Rules[\"pod-formatter\"])-1] = rules.formatter\n-\t}\n+// Replaces a state's rule based on the rule config and position\n+func replaceRule(rule ruleReplacingConfig) MutatorFunc {\n+\treturn func(state *LexerState) error {\n+\t\tstateName := rule.stateName\n+\t\tstackName := genStackName(rule.stateName, rule.rulePosition)\n \n-\treturn nil\n-}\n+\t\tstack, ok := state.Get(stackName).([]ruleReplacingConfig)\n+\t\tif !ok {\n+\t\t\tstack = []ruleReplacingConfig{}\n+\t\t}\n+\n+\t\t// If state-stack is empty fill it with the placeholder rule\n+\t\tif len(stack) == 0 {\n+\t\t\tstack = []ruleReplacingConfig{\n+\t\t\t\t{\n+\t\t\t\t\t// Placeholder, will be overwritten by mutators, DO NOT REMOVE!\n+\t\t\t\t\tpattern:      `\\A\\z`,\n+\t\t\t\t\ttokenType:    nil,\n+\t\t\t\t\tmutator:      nil,\n+\t\t\t\t\tstateName:    stateName,\n+\t\t\t\t\trulePosition: rule.rulePosition,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t\tstate.Set(stackName, stack)\n+\t\t}\n \n-type RulePosition int\n+\t\tvar mutator Mutator\n+\t\tmutators := []Mutator{}\n+\n+\t\tswitch {\n+\t\tcase rule.rulePosition == topRule && rule.mutator == nil:\n+\t\t\t// Default mutator for top rule\n+\t\t\tmutators = []Mutator{Pop(1), popRule(rule)}\n+\t\tcase rule.rulePosition == topRule && rule.mutator != nil:\n+\t\t\t// Default mutator for top rule, when rule.mutator is set\n+\t\t\tmutators = []Mutator{rule.mutator, popRule(rule)}\n+\t\tcase rule.mutator != nil:\n+\t\t\tmutators = []Mutator{rule.mutator}\n+\t\t}\n \n-const (\n-\ttopRule RulePosition = iota + 1000\n-\tbottomRule\n-)\n+\t\tif rule.appendMutator != nil {\n+\t\t\tmutators = append(mutators, rule.appendMutator)\n+\t\t}\n \n-type RuleMakingConfig struct {\n-\tdelimiter              []rune\n-\tpattern                string\n-\ttokenType              TokenType\n-\tmutator                Mutator\n-\trulePosition           RulePosition\n-\tstate                  *LexerState\n-\tstateName              string\n-\tpushToStack            bool\n-\tnumberOfDelimiterChars int\n+\t\tif len(mutators) > 0 {\n+\t\t\tmutator = Mutators(mutators...)\n+\t\t} else {\n+\t\t\tmutator = nil\n+\t\t}\n+\n+\t\truleConfig := ruleMakingConfig{\n+\t\t\tpattern:                rule.pattern,\n+\t\t\tdelimiter:              rule.delimiter,\n+\t\t\tnumberOfDelimiterChars: rule.numberOfDelimiterChars,\n+\t\t\ttokenType:              rule.tokenType,\n+\t\t\tmutator:                mutator,\n+\t\t}\n+\n+\t\tcRule := makeRule(ruleConfig)\n+\n+\t\tswitch rule.rulePosition {\n+\t\tcase topRule:\n+\t\t\tstate.Rules[stateName][0] = cRule\n+\t\tcase bottomRule:\n+\t\t\tstate.Rules[stateName][len(state.Rules[stateName])-1] = cRule\n+\t\t}\n+\n+\t\t// Pop state name from stack if asked. State should be popped first before Pushing\n+\t\tif rule.popState {\n+\t\t\terr := Pop(1)(state)\n+\t\t\tif err != nil {\n+\t\t\t\tpanic(err)\n+\t\t\t}\n+\t\t}\n+\n+\t\t// Push state name to stack if asked\n+\t\tif rule.pushState {\n+\t\t\terr := Push(stateName)(state)\n+\t\t\tif err != nil {\n+\t\t\t\tpanic(err)\n+\t\t\t}\n+\t\t}\n+\n+\t\tif !rule.pop {\n+\t\t\tstate.Set(stackName, append(stack, rule))\n+\t\t}\n+\n+\t\treturn nil\n+\t}\n }\n \n-// Makes compiled rules and returns them, If rule position is given, rules are added to the state\n-// If pushToStack is true, state name will be added to the state stack\n-func makeRuleAndPushMaybe(config RuleMakingConfig) *CompiledRule {\n+// Generates rule replacing stack using state name and rule position\n+func genStackName(stateName string, rulePosition rulePosition) (stackName string) {\n+\tswitch rulePosition {\n+\tcase topRule:\n+\t\tstackName = stateName + `-top-stack`\n+\tcase bottomRule:\n+\t\tstackName = stateName + `-bottom-stack`\n+\t}\n+\treturn\n+}\n+\n+// Makes a compiled rule and returns it\n+func makeRule(config ruleMakingConfig) *CompiledRule {\n \tvar rePattern string\n+\n \tif len(config.delimiter) > 0 {\n-\t\tdelimiter := strings.Repeat(string(config.delimiter), config.numberOfDelimiterChars)\n-\t\trePattern = regexp2.Escape(delimiter)\n+\t\tdelimiter := string(config.delimiter)\n+\n+\t\tif config.numberOfDelimiterChars > 1 {\n+\t\t\tdelimiter = strings.Repeat(delimiter, config.numberOfDelimiterChars)\n+\t\t}\n+\n+\t\trePattern = `(?<!(?<!\\\\)\\\\)` + regexp2.Escape(delimiter)\n \t} else {\n \t\trePattern = config.pattern\n \t}\n+\n \tregex := regexp2.MustCompile(rePattern, regexp2.None)\n \n \tcRule := &CompiledRule{\n \t\tRule:   Rule{rePattern, config.tokenType, config.mutator},\n \t\tRegexp: regex,\n \t}\n-\tstate := config.state\n-\tstateName := config.stateName\n-\tswitch config.rulePosition {\n-\tcase topRule:\n-\t\tstate.Rules[stateName] =\n-\t\t\tappend([]*CompiledRule{cRule}, state.Rules[stateName][1:]...)\n-\tcase bottomRule:\n-\t\tstate.Rules[stateName] =\n-\t\t\tappend(state.Rules[stateName][:len(state.Rules[stateName])-1], cRule)\n-\t}\n-\n-\t// Push state name to stack if asked\n-\tif config.pushToStack {\n-\t\tstate.Stack = append(state.Stack, config.stateName)\n-\t}\n \n \treturn cRule\n }\n \n-// Used when the regex knows its own delimiter and uses `UsingSelf(\"regex\")`,\n-// it only puts a placeholder rule at the top of \"regex\" state\n-func makeRegexPoppingRule(state *LexerState) error {\n-\tmakeRuleAndPushMaybe(RuleMakingConfig{\n-\t\tpattern:      `^$`,\n-\t\trulePosition: topRule,\n-\t\tstate:        state,\n-\t\tstateName:    \"regex\",\n-\t})\n-\n-\treturn nil\n-}\n-\n // Emitter for colon pairs, changes token state based on key and brackets\n func colonPair(tokenClass TokenType) Emitter {\n \treturn EmitterFunc(func(groups []string, state *LexerState) Iterator {"
    },
    {
      "sha": "5399c9d7b252fcbc7a5ff45013e2d62744bcc330",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/r/rust.go",
      "status": "modified",
      "additions": 25,
      "deletions": 31,
      "changes": 56,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/r/rust.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/r/rust.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/r/rust.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -9,9 +9,9 @@ import (\n var Rust = internal.Register(MustNewLazyLexer(\n \t&Config{\n \t\tName:      \"Rust\",\n-\t\tAliases:   []string{\"rust\"},\n+\t\tAliases:   []string{\"rust\", \"rs\"},\n \t\tFilenames: []string{\"*.rs\", \"*.rs.in\"},\n-\t\tMimeTypes: []string{\"text/rust\"},\n+\t\tMimeTypes: []string{\"text/rust\", \"text/x-rust\"},\n \t\tEnsureNL:  true,\n \t},\n \trustRules,\n@@ -35,20 +35,22 @@ func rustRules() Rules {\n \t\t\t{`r#*\"(?:\\\\.|[^\\\\;])*\"#*`, LiteralString, nil},\n \t\t\t{`\"(?:\\\\.|[^\\\\\"])*\"`, LiteralString, nil},\n \t\t\t{`\\$([a-zA-Z_]\\w*|\\(,?|\\),?|,?)`, CommentPreproc, nil},\n-\t\t\t{Words(``, `\\b`, `as`, `async`, `await`, `const`, `crate`, `else`, `extern`, `for`, `if`, `impl`, `in`, `loop`, `match`, `move`, `mut`, `pub`, `ref`, `return`, `static`, `super`, `trait`, `unsafe`, `use`, `where`, `while`), Keyword, nil},\n-\t\t\t{Words(``, `\\b`, `abstract`, `become`, `box`, `do`, `final`, `macro`, `override`, `priv`, `try`, `typeof`, `unsized`, `virtual`, `yield`), KeywordReserved, nil},\n+\t\t\t{Words(``, `\\b`, `as`, `async`, `await`, `box`, `const`, `crate`, `dyn`, `else`, `extern`, `for`, `if`, `impl`, `in`, `loop`, `match`, `move`, `mut`, `pub`, `ref`, `return`, `static`, `super`, `trait`, `unsafe`, `use`, `where`, `while`), Keyword, nil},\n+\t\t\t{Words(``, `\\b`, `abstract`, `become`, `do`, `final`, `macro`, `override`, `priv`, `typeof`, `try`, `unsized`, `virtual`, `yield`), KeywordReserved, nil},\n \t\t\t{`(true|false)\\b`, KeywordConstant, nil},\n+\t\t\t{`self\\b`, NameBuiltinPseudo, nil},\n \t\t\t{`mod\\b`, Keyword, Push(\"modname\")},\n \t\t\t{`let\\b`, KeywordDeclaration, nil},\n \t\t\t{`fn\\b`, Keyword, Push(\"funcname\")},\n \t\t\t{`(struct|enum|type|union)\\b`, Keyword, Push(\"typename\")},\n \t\t\t{`(default)(\\s+)(type|fn)\\b`, ByGroups(Keyword, Text, Keyword), nil},\n-\t\t\t{Words(``, `\\b`, `u8`, `u16`, `u32`, `u64`, `u128`, `i8`, `i16`, `i32`, `i64`, `i128`, `usize`, `isize`, `f32`, `f64`, `str`, `bool`), KeywordType, nil},\n-\t\t\t{`self\\b`, NameBuiltinPseudo, nil},\n-\t\t\t{Words(``, `\\b`, `Copy`, `Send`, `Sized`, `Sync`, `Drop`, `Fn`, `FnMut`, `FnOnce`, `Box`, `ToOwned`, `Clone`, `PartialEq`, `PartialOrd`, `Eq`, `Ord`, `AsRef`, `AsMut`, `Into`, `From`, `Default`, `Iterator`, `Extend`, `IntoIterator`, `DoubleEndedIterator`, `ExactSizeIterator`, `Option`, `Some`, `None`, `Result`, `Ok`, `Err`, `SliceConcatExt`, `String`, `ToString`, `Vec`), NameBuiltin, nil},\n+\t\t\t{Words(``, `\\b`, `u8`, `u16`, `u32`, `u64`, `u128`, `i8`, `i16`, `i32`, `i64`, `i128`, `usize`, `isize`, `f32`, `f64`, `char`, `str`, `bool`), KeywordType, nil},\n+\t\t\t{`[sS]elf\\b`, NameBuiltinPseudo, nil},\n+\t\t\t{Words(``, `\\b`, `Copy`, `Send`, `Sized`, `Sync`, `Unpin`, `Drop`, `Fn`, `FnMut`, `FnOnce`, `drop`, `Box`, `ToOwned`, `Clone`, `PartialEq`, `PartialOrd`, `Eq`, `Ord`, `AsRef`, `AsMut`, `Into`, `From`, `Default`, `Iterator`, `Extend`, `IntoIterator`, `DoubleEndedIterator`, `ExactSizeIterator`, `Option`, `Some`, `None`, `Result`, `Ok`, `Err`, `String`, `ToString`, `Vec`), NameBuiltin, nil},\n+\t\t\t{Words(``, `!`, `asm`, `assert`, `assert_eq`, `assert_ne`, `cfg`, `column`, `compile_error`, `concat`, `concat_idents`, `dbg`, `debug_assert`, `debug_assert_eq`, `debug_assert_ne`, `env`, `eprint`, `eprintln`, `file`, `format`, `format_args`, `format_args_nl`, `global_asm`, `include`, `include_bytes`, `include_str`, `is_aarch64_feature_detected`, `is_arm_feature_detected`, `is_mips64_feature_detected`, `is_mips_feature_detected`, `is_powerpc64_feature_detected`, `is_powerpc_feature_detected`, `is_x86_feature_detected`, `line`, `llvm_asm`, `log_syntax`, `macro_rules`, `matches`, `module_path`, `option_env`, `panic`, `print`, `println`, `stringify`, `thread_local`, `todo`, `trace_macros`, `unimplemented`, `unreachable`, `vec`, `write`, `writeln`), NameFunctionMagic, nil},\n \t\t\t{`::\\b`, Text, nil},\n \t\t\t{`(?::|->)`, Text, Push(\"typename\")},\n-\t\t\t{`(break|continue)(\\s*)(\\'[A-Za-z_]\\w*)?`, ByGroups(Keyword, TextWhitespace, NameLabel), nil},\n+\t\t\t{`(break|continue)(\\b\\s*)(\\'[A-Za-z_]\\w*)?`, ByGroups(Keyword, TextWhitespace, NameLabel), nil},\n \t\t\t{`'(\\\\['\"\\\\nrt]|\\\\x[0-7][0-9a-fA-F]|\\\\0|\\\\u\\{[0-9a-fA-F]{1,6}\\}|.)'`, LiteralStringChar, nil},\n \t\t\t{`b'(\\\\['\"\\\\nrt]|\\\\x[0-9a-fA-F]{2}|\\\\0|\\\\u\\{[0-9a-fA-F]{1,6}\\}|.)'`, LiteralStringChar, nil},\n \t\t\t{`0b[01_]+`, LiteralNumberBin, Push(\"number_lit\")},\n@@ -57,15 +59,15 @@ func rustRules() Rules {\n \t\t\t{`[0-9][0-9_]*(\\.[0-9_]+[eE][+\\-]?[0-9_]+|\\.[0-9_]*(?!\\.)|[eE][+\\-]?[0-9_]+)`, LiteralNumberFloat, Push(\"number_lit\")},\n \t\t\t{`[0-9][0-9_]*`, LiteralNumberInteger, Push(\"number_lit\")},\n \t\t\t{`b\"`, LiteralString, Push(\"bytestring\")},\n-\t\t\t{`b?r(#*)\".*?\"\\1`, LiteralString, nil},\n-\t\t\t{`'static`, NameBuiltin, nil},\n-\t\t\t{`'[a-zA-Z_]\\w*`, NameAttribute, nil},\n+\t\t\t{`(?s)b?r(#*)\".*?\"\\1`, LiteralString, nil},\n+\t\t\t{`'`, Operator, Push(\"lifetime\")},\n+\t\t\t{`\\.\\.=?`, Operator, nil},\n \t\t\t{`[{}()\\[\\],.;]`, Punctuation, nil},\n \t\t\t{`[+\\-*/%&|<>^!~@=:?]`, Operator, nil},\n \t\t\t{`(r#)?[a-zA-Z_]\\w*`, Name, nil},\n+\t\t\t{`r#[a-zA-Z_]\\w*`, Name, nil},\n \t\t\t{`#!?\\[`, CommentPreproc, Push(\"attribute[\")},\n-\t\t\t{`([A-Za-z_]\\w*)(!)(\\s*)([A-Za-z_]\\w*)?(\\s*)(\\{)`, ByGroups(CommentPreproc, Punctuation, TextWhitespace, Name, TextWhitespace, Punctuation), Push(\"macro{\")},\n-\t\t\t{`([A-Za-z_]\\w*)(!)(\\s*)([A-Za-z_]\\w*)?(\\()`, ByGroups(CommentPreproc, Punctuation, TextWhitespace, Name, Punctuation), Push(\"macro(\")},\n+\t\t\t{`#`, Text, nil},\n \t\t},\n \t\t\"comment\": {\n \t\t\t{`[^*/]+`, CommentMultiline, nil},\n@@ -92,11 +94,17 @@ func rustRules() Rules {\n \t\t\"typename\": {\n \t\t\t{`\\s+`, Text, nil},\n \t\t\t{`&`, KeywordPseudo, nil},\n-\t\t\t{Words(``, `\\b`, `Copy`, `Send`, `Sized`, `Sync`, `Drop`, `Fn`, `FnMut`, `FnOnce`, `Box`, `ToOwned`, `Clone`, `PartialEq`, `PartialOrd`, `Eq`, `Ord`, `AsRef`, `AsMut`, `Into`, `From`, `Default`, `Iterator`, `Extend`, `IntoIterator`, `DoubleEndedIterator`, `ExactSizeIterator`, `Option`, `Some`, `None`, `Result`, `Ok`, `Err`, `SliceConcatExt`, `String`, `ToString`, `Vec`), NameBuiltin, nil},\n-\t\t\t{Words(``, `\\b`, `u8`, `u16`, `u32`, `u64`, `i8`, `i16`, `i32`, `i64`, `usize`, `isize`, `f32`, `f64`, `str`, `bool`), KeywordType, nil},\n+\t\t\t{`'`, Operator, Push(\"lifetime\")},\n+\t\t\t{Words(``, `\\b`, `Copy`, `Send`, `Sized`, `Sync`, `Unpin`, `Drop`, `Fn`, `FnMut`, `FnOnce`, `drop`, `Box`, `ToOwned`, `Clone`, `PartialEq`, `PartialOrd`, `Eq`, `Ord`, `AsRef`, `AsMut`, `Into`, `From`, `Default`, `Iterator`, `Extend`, `IntoIterator`, `DoubleEndedIterator`, `ExactSizeIterator`, `Option`, `Some`, `None`, `Result`, `Ok`, `Err`, `String`, `ToString`, `Vec`), NameBuiltin, nil},\n+\t\t\t{Words(``, `\\b`, `u8`, `u16`, `u32`, `u64`, `u128`, `i8`, `i16`, `i32`, `i64`, `i128`, `usize`, `isize`, `f32`, `f64`, `char`, `str`, `bool`), KeywordType, nil},\n \t\t\t{`[a-zA-Z_]\\w*`, NameClass, Pop(1)},\n \t\t\tDefault(Pop(1)),\n \t\t},\n+\t\t\"lifetime\": {\n+\t\t\t{`(static|_)`, NameBuiltin, nil},\n+\t\t\t{`[a-zA-Z_]+\\w*`, NameAttribute, nil},\n+\t\t\tDefault(Pop(1)),\n+\t\t},\n \t\t\"number_lit\": {\n \t\t\t{`[ui](8|16|32|64|size)`, Keyword, Pop(1)},\n \t\t\t{`f(32|64)`, Keyword, Pop(1)},\n@@ -112,28 +120,14 @@ func rustRules() Rules {\n \t\t\t{`\\\\x[89a-fA-F][0-9a-fA-F]`, LiteralStringEscape, nil},\n \t\t\tInclude(\"string\"),\n \t\t},\n-\t\t\"macro{\": {\n-\t\t\t{`\\{`, Operator, Push()},\n-\t\t\t{`\\}`, Operator, Pop(1)},\n-\t\t},\n-\t\t\"macro(\": {\n-\t\t\t{`\\(`, Operator, Push()},\n-\t\t\t{`\\)`, Operator, Pop(1)},\n-\t\t},\n \t\t\"attribute_common\": {\n \t\t\t{`\"`, LiteralString, Push(\"string\")},\n \t\t\t{`\\[`, CommentPreproc, Push(\"attribute[\")},\n-\t\t\t{`\\(`, CommentPreproc, Push(\"attribute(\")},\n \t\t},\n \t\t\"attribute[\": {\n \t\t\tInclude(\"attribute_common\"),\n-\t\t\t{`\\];?`, CommentPreproc, Pop(1)},\n-\t\t\t{`[^\"\\]]+`, CommentPreproc, nil},\n-\t\t},\n-\t\t\"attribute(\": {\n-\t\t\tInclude(\"attribute_common\"),\n-\t\t\t{`\\);?`, CommentPreproc, Pop(1)},\n-\t\t\t{`[^\")]+`, CommentPreproc, nil},\n+\t\t\t{`\\]`, CommentPreproc, Pop(1)},\n+\t\t\t{`[^\"\\]\\[]+`, CommentPreproc, nil},\n \t\t},\n \t}\n }"
    },
    {
      "sha": "6798c0c6b26065f368e866760b8aca5660b327fa",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/s/scala.go",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/scala.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/scala.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/s/scala.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -22,8 +22,8 @@ var Scala = internal.Register(MustNewLazyLexer(\n func scalaRules() Rules {\n \tvar (\n \t\tscalaOp     = \"[-~\\\\^\\\\*!%&\\\\\\\\<>\\\\|+=:/?@\\xa6-\\xa7\\xa9\\xac\\xae\\xb0-\\xb1\\xb6\\xd7\\xf7\\u03f6\\u0482\\u0606-\\u0608\\u060e-\\u060f\\u06e9\\u06fd-\\u06fe\\u07f6\\u09fa\\u0b70\\u0bf3-\\u0bf8\\u0bfa\\u0c7f\\u0cf1-\\u0cf2\\u0d79\\u0f01-\\u0f03\\u0f13-\\u0f17\\u0f1a-\\u0f1f\\u0f34\\u0f36\\u0f38\\u0fbe-\\u0fc5\\u0fc7-\\u0fcf\\u109e-\\u109f\\u1360\\u1390-\\u1399\\u1940\\u19e0-\\u19ff\\u1b61-\\u1b6a\\u1b74-\\u1b7c\\u2044\\u2052\\u207a-\\u207c\\u208a-\\u208c\\u2100-\\u2101\\u2103-\\u2106\\u2108-\\u2109\\u2114\\u2116-\\u2118\\u211e-\\u2123\\u2125\\u2127\\u2129\\u212e\\u213a-\\u213b\\u2140-\\u2144\\u214a-\\u214d\\u214f\\u2190-\\u2328\\u232b-\\u244a\\u249c-\\u24e9\\u2500-\\u2767\\u2794-\\u27c4\\u27c7-\\u27e5\\u27f0-\\u2982\\u2999-\\u29d7\\u29dc-\\u29fb\\u29fe-\\u2b54\\u2ce5-\\u2cea\\u2e80-\\u2ffb\\u3004\\u3012-\\u3013\\u3020\\u3036-\\u3037\\u303e-\\u303f\\u3190-\\u3191\\u3196-\\u319f\\u31c0-\\u31e3\\u3200-\\u321e\\u322a-\\u3250\\u3260-\\u327f\\u328a-\\u32b0\\u32c0-\\u33ff\\u4dc0-\\u4dff\\ua490-\\ua4c6\\ua828-\\ua82b\\ufb29\\ufdfd\\ufe62\\ufe64-\\ufe66\\uff0b\\uff1c-\\uff1e\\uff5c\\uff5e\\uffe2\\uffe4\\uffe8-\\uffee\\ufffc-\\ufffd]+\"\n-\t\tscalaUpper  = \"[A-Z\\\\$_\\xc0-\\xd6\\xd8-\\xde\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038f\\u0391-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0531-\\u0556\\u10a0-\\u10c5\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59-\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c6f\\u2c72\\u2c75\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\uff21-\\uff3a]\"\n-\t\tscalaLetter = `[a-zA-Z\\\\$_--------------------------------------------------------------------------------------------------------------------------------------------]`\n+\t\tscalaUpper  = `[\\\\$_\\p{Lu}]`\n+\t\tscalaLetter = `[\\\\$_\\p{L}]`\n \t\tscalaIDRest = fmt.Sprintf(`%s(?:%s|[0-9])*(?:(?<=_)%s)?`, scalaLetter, scalaLetter, scalaOp)\n \t)\n "
    },
    {
      "sha": "ff5edf93b20c5db36041d16c13bfdd6a785a8f7c",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/s/sieve.go",
      "status": "added",
      "additions": 37,
      "deletions": 0,
      "changes": 37,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/sieve.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/sieve.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/s/sieve.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,37 @@\n+package s\n+\n+import (\n+\t. \"github.com/alecthomas/chroma\" // nolint\n+\t\"github.com/alecthomas/chroma/lexers/internal\"\n+)\n+\n+// Sieve lexer.\n+var Sieve = internal.Register(MustNewLazyLexer(\n+\t&Config{\n+\t\tName:      \"Sieve\",\n+\t\tAliases:   []string{\"sieve\"},\n+\t\tFilenames: []string{\"*.siv\", \"*.sieve\"},\n+\t\tMimeTypes: []string{},\n+\t},\n+\tfunc() Rules {\n+\t\treturn Rules{\n+\t\t\t\"root\": {\n+\t\t\t\t{`\\s+`, Text, nil},\n+\t\t\t\t{`[();,{}\\[\\]]`, Punctuation, nil},\n+\t\t\t\t{`(?i)require`, KeywordNamespace, nil},\n+\t\t\t\t{`(?i)(:)(addresses|all|contains|content|create|copy|comparator|count|days|detail|domain|fcc|flags|from|handle|importance|is|localpart|length|lowerfirst|lower|matches|message|mime|options|over|percent|quotewildcard|raw|regex|specialuse|subject|text|under|upperfirst|upper|value)`, ByGroups(NameTag, NameTag), nil},\n+\t\t\t\t{`(?i)(address|addflag|allof|anyof|body|discard|elsif|else|envelope|ereject|exists|false|fileinto|if|hasflag|header|keep|notify_method_capability|notify|not|redirect|reject|removeflag|setflag|size|spamtest|stop|string|true|vacation|virustest)`, NameBuiltin, nil},\n+\t\t\t\t{`(?i)set`, KeywordDeclaration, nil},\n+\t\t\t\t{`([0-9.]+)([kmgKMG])?`, ByGroups(LiteralNumber, LiteralNumber), nil},\n+\t\t\t\t{`#.*$`, CommentSingle, nil},\n+\t\t\t\t{`/\\*.*\\*/`, CommentMultiline, nil},\n+\t\t\t\t{`\"[^\"]*?\"`, LiteralString, nil},\n+\t\t\t\t{`text:`, NameTag, Push(\"text\")},\n+\t\t\t},\n+\t\t\t\"text\": {\n+\t\t\t\t{`[^.].*?\\n`, LiteralString, nil},\n+\t\t\t\t{`^\\.`, Punctuation, Pop(1)},\n+\t\t\t},\n+\t\t}\n+\t},\n+))"
    },
    {
      "sha": "3f56f9c03bea8189573a992d11a751edf00b421c",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/s/sparql.go",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/sparql.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/s/sparql.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/s/sparql.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -23,9 +23,9 @@ func sparqlRules() Rules {\n \t\t\t{`((?i)select|construct|describe|ask|where|filter|group\\s+by|minus|distinct|reduced|from\\s+named|from|order\\s+by|desc|asc|limit|offset|bindings|load|clear|drop|create|add|move|copy|insert\\s+data|delete\\s+data|delete\\s+where|delete|insert|using\\s+named|using|graph|default|named|all|optional|service|silent|bind|union|not\\s+in|in|as|having|to|prefix|base)\\b`, Keyword, nil},\n \t\t\t{`(a)\\b`, Keyword, nil},\n \t\t\t{\"(<(?:[^<>\\\"{}|^`\\\\\\\\\\\\x00-\\\\x20])*>)\", NameLabel, nil},\n-\t\t\t{`(_:[0-9a-zA-Z-----------_](?:[a-zA-Z-----------_\\-0-9--.]*[a-zA-Z-----------_\\-0-9--])?)`, NameLabel, nil},\n-\t\t\t{`[?$][0-9a-zA-Z-----------_][a-zA-Z-----------_0-9--]*`, NameVariable, nil},\n-\t\t\t{`([a-zA-Z-----------](?:[a-zA-Z-----------_\\-0-9--.]*[a-zA-Z-----------_\\-0-9--])?)?(\\:)((?:[a-zA-Z-----------_:0-9]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%]))(?:(?:[a-zA-Z-----------_\\-0-9--.:]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%]))*(?:[a-zA-Z-----------_\\-0-9--:]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%])))?)?`, ByGroups(NameNamespace, Punctuation, NameTag), nil},\n+\t\t\t{`(_:[_\\p{L}\\p{N}](?:[-_.\\p{L}\\p{N}]*[-_\\p{L}\\p{N}])?)`, NameLabel, nil},\n+\t\t\t{`[?$][_\\p{L}\\p{N}]+`, NameVariable, nil},\n+\t\t\t{`([\\p{L}][-_.\\p{L}\\p{N}]*)?(\\:)((?:[_:\\p{L}\\p{N}]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%]))(?:(?:[-_:.\\p{L}\\p{N}]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%]))*(?:[-_:\\p{L}\\p{N}]|(?:%[0-9A-Fa-f][0-9A-Fa-f])|(?:\\\\[ _~.\\-!$&\"()*+,;=/?#@%])))?)?`, ByGroups(NameNamespace, Punctuation, NameTag), nil},\n \t\t\t{`((?i)str|lang|langmatches|datatype|bound|iri|uri|bnode|rand|abs|ceil|floor|round|concat|strlen|ucase|lcase|encode_for_uri|contains|strstarts|strends|strbefore|strafter|year|month|day|hours|minutes|seconds|timezone|tz|now|md5|sha1|sha256|sha384|sha512|coalesce|if|strlang|strdt|sameterm|isiri|isuri|isblank|isliteral|isnumeric|regex|substr|replace|exists|not\\s+exists|count|sum|min|max|avg|sample|group_concat|separator)\\b`, NameFunction, nil},\n \t\t\t{`(true|false)`, KeywordConstant, nil},\n \t\t\t{`[+\\-]?(\\d+\\.\\d*[eE][+-]?\\d+|\\.?\\d+[eE][+-]?\\d+)`, LiteralNumberFloat, nil},"
    },
    {
      "sha": "b84b7492a38c46e355ac46d7578a0bc44f6a8ee2",
      "filename": "backend/vendor/github.com/alecthomas/chroma/lexers/v/vue.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/v/vue.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/lexers/v/vue.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/lexers/v/vue.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -55,7 +55,7 @@ func vueRules() Rules {\n \t\t\t{`(abstract|boolean|byte|char|class|const|debugger|double|enum|export|extends|final|float|goto|implements|import|int|interface|long|native|package|private|protected|public|short|static|super|synchronized|throws|transient|volatile)\\b`, KeywordReserved, nil},\n \t\t\t{`(true|false|null|NaN|Infinity|undefined)\\b`, KeywordConstant, nil},\n \t\t\t{`(Array|Boolean|Date|Error|Function|Math|netscape|Number|Object|Packages|RegExp|String|Promise|Proxy|sun|decodeURI|decodeURIComponent|encodeURI|encodeURIComponent|Error|eval|isFinite|isNaN|isSafeInteger|parseFloat|parseInt|document|this|window)\\b`, NameBuiltin, nil},\n-\t\t\t{`(?:[$_A-Z------------------------------------------------------------------------------------------a-z-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]|\\\\u[a-fA-F0-9]{4})(?:(?:[$A-Z------------------------------------------------------------------------------------------a-z---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------0-9--------------------------------------------------------_---]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n+\t\t\t{`(?:[$_\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4})(?:(?:[$\\p{L}\\p{N}]|\\\\u[a-fA-F0-9]{4}))*`, NameOther, nil},\n \t\t\t{`\"(\\\\\\\\|\\\\\"|[^\"])*\"`, LiteralStringDouble, nil},\n \t\t\t{`'(\\\\\\\\|\\\\'|[^'])*'`, LiteralStringSingle, nil},\n \t\t\t{\"`\", LiteralStringBacktick, Push(\"interp\")},"
    },
    {
      "sha": "4096dfc46fdedc2e3f6f2ff65421edcba76439f6",
      "filename": "backend/vendor/github.com/alecthomas/chroma/regexp.go",
      "status": "modified",
      "additions": 7,
      "deletions": 0,
      "changes": 7,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/regexp.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/regexp.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/regexp.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -3,6 +3,7 @@ package chroma\n import (\n \t\"fmt\"\n \t\"os\"\n+\t\"path/filepath\"\n \t\"regexp\"\n \t\"sort\"\n \t\"strings\"\n@@ -238,6 +239,12 @@ func NewLazyLexer(config *Config, rulesFunc func() Rules) (*RegexLexer, error) {\n \tif config == nil {\n \t\tconfig = &Config{}\n \t}\n+\tfor _, glob := range append(config.Filenames, config.AliasFilenames...) {\n+\t\t_, err := filepath.Match(glob, \"\")\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"%s: %q is not a valid glob: %w\", config.Name, glob, err)\n+\t\t}\n+\t}\n \treturn &RegexLexer{\n \t\tconfig:       config,\n \t\tcompilerFunc: rulesFunc,"
    },
    {
      "sha": "9048e38ad1dc18858a5693c130162d132ea52b61",
      "filename": "backend/vendor/github.com/alecthomas/chroma/styles/onesenterprise.go",
      "status": "added",
      "additions": 17,
      "deletions": 0,
      "changes": 17,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/styles/onesenterprise.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/alecthomas/chroma/styles/onesenterprise.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/alecthomas/chroma/styles/onesenterprise.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,17 @@\n+package styles\n+\n+import (\n+\t\"github.com/alecthomas/chroma\"\n+)\n+\n+// 1S:Designer color palette\n+var OnesEnterprise = Register(chroma.MustNewStyle(\"onesenterprise\", chroma.StyleEntries{\n+\tchroma.Text:           \"#000000\",\n+\tchroma.Comment:        \"#008000\",\n+\tchroma.CommentPreproc: \"#963200\",\n+\tchroma.Operator:       \"#FF0000\",\n+\tchroma.Keyword:        \"#FF0000\",\n+\tchroma.Punctuation:    \"#FF0000\",\n+\tchroma.LiteralString:  \"#000000\",\n+\tchroma.Name:           \"#0000FF\",\n+}))"
    },
    {
      "sha": "ee72d3fe0c8d726656b1fc83fa206a8e98dd1e74",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/go.mod",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/go.mod?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,5 +1,5 @@\n module github.com/andybalholm/cascadia\n \n-require golang.org/x/net v0.0.0-20180218175443-cbe0f9307d01\n+go 1.16\n \n-go 1.13\n+require golang.org/x/net v0.0.0-20210916014120-12bc252f5db8"
    },
    {
      "sha": "0f4194c577d5cad37b4e58de9303e66984630c7a",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/go.sum",
      "status": "added",
      "additions": 7,
      "deletions": 0,
      "changes": 7,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,7 @@\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8 h1:/6y1LfuqNuQdHAm0jjtPtgRcxIxjVZgm5OTu8/QhZvk=\n+golang.org/x/net v0.0.0-20210916014120-12bc252f5db8/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\n+golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\n+golang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\n+golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ="
    },
    {
      "sha": "f654c0c7a81dd6e08c41dec98a2b4a0a418906a3",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/parser.go",
      "status": "modified",
      "additions": 54,
      "deletions": 5,
      "changes": 59,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/parser.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/parser.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/parser.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -36,7 +36,7 @@ func (p *parser) parseEscape() (result string, err error) {\n \t\tfor i = start; i < start+6 && i < len(p.s) && hexDigit(p.s[i]); i++ {\n \t\t\t// empty\n \t\t}\n-\t\tv, _ := strconv.ParseUint(p.s[start:i], 16, 21)\n+\t\tv, _ := strconv.ParseUint(p.s[start:i], 16, 64)\n \t\tif len(p.s) > i {\n \t\t\tswitch p.s[i] {\n \t\t\tcase '\\r':\n@@ -409,22 +409,37 @@ func (p *parser) parseAttributeSelector() (attrSelector, error) {\n \tif p.i >= len(p.s) {\n \t\treturn attrSelector{}, errors.New(\"unexpected EOF in attribute selector\")\n \t}\n+\n+\t// check if the attribute contains an ignore case flag\n+\tignoreCase := false\n+\tif p.s[p.i] == 'i' || p.s[p.i] == 'I' {\n+\t\tignoreCase = true\n+\t\tp.i++\n+\t}\n+\n+\tp.skipWhitespace()\n+\tif p.i >= len(p.s) {\n+\t\treturn attrSelector{}, errors.New(\"unexpected EOF in attribute selector\")\n+\t}\n+\n \tif p.s[p.i] != ']' {\n \t\treturn attrSelector{}, fmt.Errorf(\"expected ']', found '%c' instead\", p.s[p.i])\n \t}\n \tp.i++\n \n \tswitch op {\n \tcase \"=\", \"!=\", \"~=\", \"|=\", \"^=\", \"$=\", \"*=\", \"#=\":\n-\t\treturn attrSelector{key: key, val: val, operation: op, regexp: rx}, nil\n+\t\treturn attrSelector{key: key, val: val, operation: op, regexp: rx, insensitive: ignoreCase}, nil\n \tdefault:\n \t\treturn attrSelector{}, fmt.Errorf(\"attribute operator %q is not supported\", op)\n \t}\n }\n \n-var errExpectedParenthesis = errors.New(\"expected '(' but didn't find it\")\n-var errExpectedClosingParenthesis = errors.New(\"expected ')' but didn't find it\")\n-var errUnmatchedParenthesis = errors.New(\"unmatched '('\")\n+var (\n+\terrExpectedParenthesis        = errors.New(\"expected '(' but didn't find it\")\n+\terrExpectedClosingParenthesis = errors.New(\"expected ')' but didn't find it\")\n+\terrUnmatchedParenthesis       = errors.New(\"unmatched '('\")\n+)\n \n // parsePseudoclassSelector parses a pseudoclass selector like :not(p) or a pseudo-element\n // For backwards compatibility, both ':' and '::' prefix are allowed for pseudo-elements.\n@@ -552,6 +567,37 @@ func (p *parser) parsePseudoclassSelector() (out Sel, pseudoElement string, err\n \t\tout = emptyElementPseudoClassSelector{}\n \tcase \"root\":\n \t\tout = rootPseudoClassSelector{}\n+\tcase \"link\":\n+\t\tout = linkPseudoClassSelector{}\n+\tcase \"lang\":\n+\t\tif !p.consumeParenthesis() {\n+\t\t\treturn out, \"\", errExpectedParenthesis\n+\t\t}\n+\t\tif p.i == len(p.s) {\n+\t\t\treturn out, \"\", errUnmatchedParenthesis\n+\t\t}\n+\t\tval, err := p.parseIdentifier()\n+\t\tif err != nil {\n+\t\t\treturn out, \"\", err\n+\t\t}\n+\t\tval = strings.ToLower(val)\n+\t\tp.skipWhitespace()\n+\t\tif p.i >= len(p.s) {\n+\t\t\treturn out, \"\", errors.New(\"unexpected EOF in pseudo selector\")\n+\t\t}\n+\t\tif !p.consumeClosingParenthesis() {\n+\t\t\treturn out, \"\", errExpectedClosingParenthesis\n+\t\t}\n+\t\tout = langPseudoClassSelector{lang: val}\n+\tcase \"enabled\":\n+\t\tout = enabledPseudoClassSelector{}\n+\tcase \"disabled\":\n+\t\tout = disabledPseudoClassSelector{}\n+\tcase \"checked\":\n+\t\tout = checkedPseudoClassSelector{}\n+\tcase \"visited\", \"hover\", \"active\", \"focus\", \"target\":\n+\t\t// Not applicable in a static context: never match.\n+\t\tout = neverMatchSelector{value: \":\" + name}\n \tcase \"after\", \"backdrop\", \"before\", \"cue\", \"first-letter\", \"first-line\", \"grammar-error\", \"marker\", \"placeholder\", \"selection\", \"spelling-error\":\n \t\treturn nil, name, nil\n \tdefault:\n@@ -714,6 +760,9 @@ func (p *parser) parseSimpleSelectorSequence() (Sel, error) {\n \tcase '*':\n \t\t// It's the universal selector. Just skip over it, since it doesn't affect the meaning.\n \t\tp.i++\n+\t\tif p.i+2 < len(p.s) && p.s[p.i:p.i+2] == \"|*\" { // other version of universal selector\n+\t\t\tp.i += 2\n+\t\t}\n \tcase '#', '.', '[', ':':\n \t\t// There's no type selector. Wait to process the other till the main loop.\n \tdefault:"
    },
    {
      "sha": "3986b22cd4e27097da7d7a662f809a8949530346",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/pseudo_classes.go",
      "status": "added",
      "additions": 474,
      "deletions": 0,
      "changes": 474,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/pseudo_classes.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/pseudo_classes.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/pseudo_classes.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,474 @@\n+package cascadia\n+\n+import (\n+\t\"bytes\"\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strings\"\n+\n+\t\"golang.org/x/net/html\"\n+\t\"golang.org/x/net/html/atom\"\n+)\n+\n+// This file implements the pseudo classes selectors,\n+// which share the implementation of PseudoElement() and Specificity()\n+\n+type abstractPseudoClass struct{}\n+\n+func (s abstractPseudoClass) Specificity() Specificity {\n+\treturn Specificity{0, 1, 0}\n+}\n+\n+func (c abstractPseudoClass) PseudoElement() string {\n+\treturn \"\"\n+}\n+\n+type relativePseudoClassSelector struct {\n+\tname  string // one of \"not\", \"has\", \"haschild\"\n+\tmatch SelectorGroup\n+}\n+\n+func (s relativePseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\tswitch s.name {\n+\tcase \"not\":\n+\t\t// matches elements that do not match a.\n+\t\treturn !s.match.Match(n)\n+\tcase \"has\":\n+\t\t//  matches elements with any descendant that matches a.\n+\t\treturn hasDescendantMatch(n, s.match)\n+\tcase \"haschild\":\n+\t\t// matches elements with a child that matches a.\n+\t\treturn hasChildMatch(n, s.match)\n+\tdefault:\n+\t\tpanic(fmt.Sprintf(\"unsupported relative pseudo class selector : %s\", s.name))\n+\t}\n+}\n+\n+// hasChildMatch returns whether n has any child that matches a.\n+func hasChildMatch(n *html.Node, a Matcher) bool {\n+\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif a.Match(c) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// hasDescendantMatch performs a depth-first search of n's descendants,\n+// testing whether any of them match a. It returns true as soon as a match is\n+// found, or false if no match is found.\n+func hasDescendantMatch(n *html.Node, a Matcher) bool {\n+\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif a.Match(c) || (c.Type == html.ElementNode && hasDescendantMatch(c, a)) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// Specificity returns the specificity of the most specific selectors\n+// in the pseudo-class arguments.\n+// See https://www.w3.org/TR/selectors/#specificity-rules\n+func (s relativePseudoClassSelector) Specificity() Specificity {\n+\tvar max Specificity\n+\tfor _, sel := range s.match {\n+\t\tnewSpe := sel.Specificity()\n+\t\tif max.Less(newSpe) {\n+\t\t\tmax = newSpe\n+\t\t}\n+\t}\n+\treturn max\n+}\n+\n+func (c relativePseudoClassSelector) PseudoElement() string {\n+\treturn \"\"\n+}\n+\n+type containsPseudoClassSelector struct {\n+\tabstractPseudoClass\n+\tvalue string\n+\town   bool\n+}\n+\n+func (s containsPseudoClassSelector) Match(n *html.Node) bool {\n+\tvar text string\n+\tif s.own {\n+\t\t// matches nodes that directly contain the given text\n+\t\ttext = strings.ToLower(nodeOwnText(n))\n+\t} else {\n+\t\t// matches nodes that contain the given text.\n+\t\ttext = strings.ToLower(nodeText(n))\n+\t}\n+\treturn strings.Contains(text, s.value)\n+}\n+\n+type regexpPseudoClassSelector struct {\n+\tabstractPseudoClass\n+\tregexp *regexp.Regexp\n+\town    bool\n+}\n+\n+func (s regexpPseudoClassSelector) Match(n *html.Node) bool {\n+\tvar text string\n+\tif s.own {\n+\t\t// matches nodes whose text directly matches the specified regular expression\n+\t\ttext = nodeOwnText(n)\n+\t} else {\n+\t\t// matches nodes whose text matches the specified regular expression\n+\t\ttext = nodeText(n)\n+\t}\n+\treturn s.regexp.MatchString(text)\n+}\n+\n+// writeNodeText writes the text contained in n and its descendants to b.\n+func writeNodeText(n *html.Node, b *bytes.Buffer) {\n+\tswitch n.Type {\n+\tcase html.TextNode:\n+\t\tb.WriteString(n.Data)\n+\tcase html.ElementNode:\n+\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n+\t\t\twriteNodeText(c, b)\n+\t\t}\n+\t}\n+}\n+\n+// nodeText returns the text contained in n and its descendants.\n+func nodeText(n *html.Node) string {\n+\tvar b bytes.Buffer\n+\twriteNodeText(n, &b)\n+\treturn b.String()\n+}\n+\n+// nodeOwnText returns the contents of the text nodes that are direct\n+// children of n.\n+func nodeOwnText(n *html.Node) string {\n+\tvar b bytes.Buffer\n+\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif c.Type == html.TextNode {\n+\t\t\tb.WriteString(c.Data)\n+\t\t}\n+\t}\n+\treturn b.String()\n+}\n+\n+type nthPseudoClassSelector struct {\n+\tabstractPseudoClass\n+\ta, b         int\n+\tlast, ofType bool\n+}\n+\n+func (s nthPseudoClassSelector) Match(n *html.Node) bool {\n+\tif s.a == 0 {\n+\t\tif s.last {\n+\t\t\treturn simpleNthLastChildMatch(s.b, s.ofType, n)\n+\t\t} else {\n+\t\t\treturn simpleNthChildMatch(s.b, s.ofType, n)\n+\t\t}\n+\t}\n+\treturn nthChildMatch(s.a, s.b, s.last, s.ofType, n)\n+}\n+\n+// nthChildMatch implements :nth-child(an+b).\n+// If last is true, implements :nth-last-child instead.\n+// If ofType is true, implements :nth-of-type instead.\n+func nthChildMatch(a, b int, last, ofType bool, n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\n+\tparent := n.Parent\n+\tif parent == nil {\n+\t\treturn false\n+\t}\n+\n+\tif parent.Type == html.DocumentNode {\n+\t\treturn false\n+\t}\n+\n+\ti := -1\n+\tcount := 0\n+\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif (c.Type != html.ElementNode) || (ofType && c.Data != n.Data) {\n+\t\t\tcontinue\n+\t\t}\n+\t\tcount++\n+\t\tif c == n {\n+\t\t\ti = count\n+\t\t\tif !last {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif i == -1 {\n+\t\t// This shouldn't happen, since n should always be one of its parent's children.\n+\t\treturn false\n+\t}\n+\n+\tif last {\n+\t\ti = count - i + 1\n+\t}\n+\n+\ti -= b\n+\tif a == 0 {\n+\t\treturn i == 0\n+\t}\n+\n+\treturn i%a == 0 && i/a >= 0\n+}\n+\n+// simpleNthChildMatch implements :nth-child(b).\n+// If ofType is true, implements :nth-of-type instead.\n+func simpleNthChildMatch(b int, ofType bool, n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\n+\tparent := n.Parent\n+\tif parent == nil {\n+\t\treturn false\n+\t}\n+\n+\tif parent.Type == html.DocumentNode {\n+\t\treturn false\n+\t}\n+\n+\tcount := 0\n+\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif c.Type != html.ElementNode || (ofType && c.Data != n.Data) {\n+\t\t\tcontinue\n+\t\t}\n+\t\tcount++\n+\t\tif c == n {\n+\t\t\treturn count == b\n+\t\t}\n+\t\tif count >= b {\n+\t\t\treturn false\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// simpleNthLastChildMatch implements :nth-last-child(b).\n+// If ofType is true, implements :nth-last-of-type instead.\n+func simpleNthLastChildMatch(b int, ofType bool, n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\n+\tparent := n.Parent\n+\tif parent == nil {\n+\t\treturn false\n+\t}\n+\n+\tif parent.Type == html.DocumentNode {\n+\t\treturn false\n+\t}\n+\n+\tcount := 0\n+\tfor c := parent.LastChild; c != nil; c = c.PrevSibling {\n+\t\tif c.Type != html.ElementNode || (ofType && c.Data != n.Data) {\n+\t\t\tcontinue\n+\t\t}\n+\t\tcount++\n+\t\tif c == n {\n+\t\t\treturn count == b\n+\t\t}\n+\t\tif count >= b {\n+\t\t\treturn false\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+type onlyChildPseudoClassSelector struct {\n+\tabstractPseudoClass\n+\tofType bool\n+}\n+\n+// Match implements :only-child.\n+// If `ofType` is true, it implements :only-of-type instead.\n+func (s onlyChildPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\n+\tparent := n.Parent\n+\tif parent == nil {\n+\t\treturn false\n+\t}\n+\n+\tif parent.Type == html.DocumentNode {\n+\t\treturn false\n+\t}\n+\n+\tcount := 0\n+\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n+\t\tif (c.Type != html.ElementNode) || (s.ofType && c.Data != n.Data) {\n+\t\t\tcontinue\n+\t\t}\n+\t\tcount++\n+\t\tif count > 1 {\n+\t\t\treturn false\n+\t\t}\n+\t}\n+\n+\treturn count == 1\n+}\n+\n+type inputPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+// Matches input, select, textarea and button elements.\n+func (s inputPseudoClassSelector) Match(n *html.Node) bool {\n+\treturn n.Type == html.ElementNode && (n.Data == \"input\" || n.Data == \"select\" || n.Data == \"textarea\" || n.Data == \"button\")\n+}\n+\n+type emptyElementPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+// Matches empty elements.\n+func (s emptyElementPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\n+\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n+\t\tswitch c.Type {\n+\t\tcase html.ElementNode:\n+\t\t\treturn false\n+\t\tcase html.TextNode:\n+\t\t\tif strings.TrimSpace(nodeText(c)) == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t} else {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn true\n+}\n+\n+type rootPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+// Match implements :root\n+func (s rootPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\tif n.Parent == nil {\n+\t\treturn false\n+\t}\n+\treturn n.Parent.Type == html.DocumentNode\n+}\n+\n+func hasAttr(n *html.Node, attr string) bool {\n+\treturn matchAttribute(n, attr, func(string) bool { return true })\n+}\n+\n+type linkPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+// Match implements :link\n+func (s linkPseudoClassSelector) Match(n *html.Node) bool {\n+\treturn (n.DataAtom == atom.A || n.DataAtom == atom.Area || n.DataAtom == atom.Link) && hasAttr(n, \"href\")\n+}\n+\n+type langPseudoClassSelector struct {\n+\tabstractPseudoClass\n+\tlang string\n+}\n+\n+func (s langPseudoClassSelector) Match(n *html.Node) bool {\n+\town := matchAttribute(n, \"lang\", func(val string) bool {\n+\t\treturn val == s.lang || strings.HasPrefix(val, s.lang+\"-\")\n+\t})\n+\tif n.Parent == nil {\n+\t\treturn own\n+\t}\n+\treturn own || s.Match(n.Parent)\n+}\n+\n+type enabledPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+func (s enabledPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\tswitch n.DataAtom {\n+\tcase atom.A, atom.Area, atom.Link:\n+\t\treturn hasAttr(n, \"href\")\n+\tcase atom.Optgroup, atom.Menuitem, atom.Fieldset:\n+\t\treturn !hasAttr(n, \"disabled\")\n+\tcase atom.Button, atom.Input, atom.Select, atom.Textarea, atom.Option:\n+\t\treturn !hasAttr(n, \"disabled\") && !inDisabledFieldset(n)\n+\t}\n+\treturn false\n+}\n+\n+type disabledPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+func (s disabledPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\tswitch n.DataAtom {\n+\tcase atom.Optgroup, atom.Menuitem, atom.Fieldset:\n+\t\treturn hasAttr(n, \"disabled\")\n+\tcase atom.Button, atom.Input, atom.Select, atom.Textarea, atom.Option:\n+\t\treturn hasAttr(n, \"disabled\") || inDisabledFieldset(n)\n+\t}\n+\treturn false\n+}\n+\n+func hasLegendInPreviousSiblings(n *html.Node) bool {\n+\tfor s := n.PrevSibling; s != nil; s = s.PrevSibling {\n+\t\tif s.DataAtom == atom.Legend {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func inDisabledFieldset(n *html.Node) bool {\n+\tif n.Parent == nil {\n+\t\treturn false\n+\t}\n+\tif n.Parent.DataAtom == atom.Fieldset && hasAttr(n.Parent, \"disabled\") &&\n+\t\t(n.DataAtom != atom.Legend || hasLegendInPreviousSiblings(n)) {\n+\t\treturn true\n+\t}\n+\treturn inDisabledFieldset(n.Parent)\n+}\n+\n+type checkedPseudoClassSelector struct {\n+\tabstractPseudoClass\n+}\n+\n+func (s checkedPseudoClassSelector) Match(n *html.Node) bool {\n+\tif n.Type != html.ElementNode {\n+\t\treturn false\n+\t}\n+\tswitch n.DataAtom {\n+\tcase atom.Input, atom.Menuitem:\n+\t\treturn hasAttr(n, \"checked\") && matchAttribute(n, \"type\", func(val string) bool {\n+\t\t\tt := toLowerASCII(val)\n+\t\t\treturn t == \"checkbox\" || t == \"radio\"\n+\t\t})\n+\tcase atom.Option:\n+\t\treturn hasAttr(n, \"selected\")\n+\t}\n+\treturn false\n+}"
    },
    {
      "sha": "87549be23958dfc5948fb4ea20ac998c02ea8d8a",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/selector.go",
      "status": "modified",
      "additions": 47,
      "deletions": 399,
      "changes": 446,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/selector.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/selector.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/selector.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,7 +1,6 @@\n package cascadia\n \n import (\n-\t\"bytes\"\n \t\"fmt\"\n \t\"regexp\"\n \t\"strings\"\n@@ -232,7 +231,7 @@ type classSelector struct {\n // Matches elements by class attribute.\n func (t classSelector) Match(n *html.Node) bool {\n \treturn matchAttribute(n, \"class\", func(s string) bool {\n-\t\treturn matchInclude(t.class, s)\n+\t\treturn matchInclude(t.class, s, false)\n \t})\n }\n \n@@ -266,6 +265,7 @@ func (c idSelector) PseudoElement() string {\n type attrSelector struct {\n \tkey, val, operation string\n \tregexp              *regexp.Regexp\n+\tinsensitive         bool\n }\n \n // Matches elements by attribute value.\n@@ -274,27 +274,38 @@ func (t attrSelector) Match(n *html.Node) bool {\n \tcase \"\":\n \t\treturn matchAttribute(n, t.key, func(string) bool { return true })\n \tcase \"=\":\n-\t\treturn matchAttribute(n, t.key, func(s string) bool { return s == t.val })\n+\t\treturn matchAttribute(n, t.key, func(s string) bool { return matchInsensitiveValue(s, t.val, t.insensitive) })\n \tcase \"!=\":\n-\t\treturn attributeNotEqualMatch(t.key, t.val, n)\n+\t\treturn attributeNotEqualMatch(t.key, t.val, n, t.insensitive)\n \tcase \"~=\":\n \t\t// matches elements where the attribute named key is a whitespace-separated list that includes val.\n-\t\treturn matchAttribute(n, t.key, func(s string) bool { return matchInclude(t.val, s) })\n+\t\treturn matchAttribute(n, t.key, func(s string) bool { return matchInclude(t.val, s, t.insensitive) })\n \tcase \"|=\":\n-\t\treturn attributeDashMatch(t.key, t.val, n)\n+\t\treturn attributeDashMatch(t.key, t.val, n, t.insensitive)\n \tcase \"^=\":\n-\t\treturn attributePrefixMatch(t.key, t.val, n)\n+\t\treturn attributePrefixMatch(t.key, t.val, n, t.insensitive)\n \tcase \"$=\":\n-\t\treturn attributeSuffixMatch(t.key, t.val, n)\n+\t\treturn attributeSuffixMatch(t.key, t.val, n, t.insensitive)\n \tcase \"*=\":\n-\t\treturn attributeSubstringMatch(t.key, t.val, n)\n+\t\treturn attributeSubstringMatch(t.key, t.val, n, t.insensitive)\n \tcase \"#=\":\n \t\treturn attributeRegexMatch(t.key, t.regexp, n)\n \tdefault:\n \t\tpanic(fmt.Sprintf(\"unsuported operation : %s\", t.operation))\n \t}\n }\n \n+// matches elements where we ignore (or not) the case of the attribute value\n+// the user attribute is the value set by the user to match elements\n+// the real attribute is the attribute value found in the code parsed\n+func matchInsensitiveValue(userAttr string, realAttr string, ignoreCase bool) bool {\n+\tif ignoreCase {\n+\t\treturn strings.EqualFold(userAttr, realAttr)\n+\t}\n+\treturn userAttr == realAttr\n+\n+}\n+\n // matches elements where the attribute named key satisifes the function f.\n func matchAttribute(n *html.Node, key string, f func(string) bool) bool {\n \tif n.Type != html.ElementNode {\n@@ -310,26 +321,26 @@ func matchAttribute(n *html.Node, key string, f func(string) bool) bool {\n \n // attributeNotEqualMatch matches elements where\n // the attribute named key does not have the value val.\n-func attributeNotEqualMatch(key, val string, n *html.Node) bool {\n+func attributeNotEqualMatch(key, val string, n *html.Node, ignoreCase bool) bool {\n \tif n.Type != html.ElementNode {\n \t\treturn false\n \t}\n \tfor _, a := range n.Attr {\n-\t\tif a.Key == key && a.Val == val {\n+\t\tif a.Key == key && matchInsensitiveValue(a.Val, val, ignoreCase) {\n \t\t\treturn false\n \t\t}\n \t}\n \treturn true\n }\n \n // returns true if s is a whitespace-separated list that includes val.\n-func matchInclude(val, s string) bool {\n+func matchInclude(val string, s string, ignoreCase bool) bool {\n \tfor s != \"\" {\n \t\ti := strings.IndexAny(s, \" \\t\\r\\n\\f\")\n \t\tif i == -1 {\n-\t\t\treturn s == val\n+\t\t\treturn matchInsensitiveValue(s, val, ignoreCase)\n \t\t}\n-\t\tif s[:i] == val {\n+\t\tif matchInsensitiveValue(s[:i], val, ignoreCase) {\n \t\t\treturn true\n \t\t}\n \t\ts = s[i+1:]\n@@ -338,16 +349,16 @@ func matchInclude(val, s string) bool {\n }\n \n //  matches elements where the attribute named key equals val or starts with val plus a hyphen.\n-func attributeDashMatch(key, val string, n *html.Node) bool {\n+func attributeDashMatch(key, val string, n *html.Node, ignoreCase bool) bool {\n \treturn matchAttribute(n, key,\n \t\tfunc(s string) bool {\n-\t\t\tif s == val {\n+\t\t\tif matchInsensitiveValue(s, val, ignoreCase) {\n \t\t\t\treturn true\n \t\t\t}\n \t\t\tif len(s) <= len(val) {\n \t\t\t\treturn false\n \t\t\t}\n-\t\t\tif s[:len(val)] == val && s[len(val)] == '-' {\n+\t\t\tif matchInsensitiveValue(s[:len(val)], val, ignoreCase) && s[len(val)] == '-' {\n \t\t\t\treturn true\n \t\t\t}\n \t\t\treturn false\n@@ -356,36 +367,45 @@ func attributeDashMatch(key, val string, n *html.Node) bool {\n \n // attributePrefixMatch returns a Selector that matches elements where\n // the attribute named key starts with val.\n-func attributePrefixMatch(key, val string, n *html.Node) bool {\n+func attributePrefixMatch(key, val string, n *html.Node, ignoreCase bool) bool {\n \treturn matchAttribute(n, key,\n \t\tfunc(s string) bool {\n \t\t\tif strings.TrimSpace(s) == \"\" {\n \t\t\t\treturn false\n \t\t\t}\n+\t\t\tif ignoreCase {\n+\t\t\t\treturn strings.HasPrefix(strings.ToLower(s), strings.ToLower(val))\n+\t\t\t}\n \t\t\treturn strings.HasPrefix(s, val)\n \t\t})\n }\n \n // attributeSuffixMatch matches elements where\n // the attribute named key ends with val.\n-func attributeSuffixMatch(key, val string, n *html.Node) bool {\n+func attributeSuffixMatch(key, val string, n *html.Node, ignoreCase bool) bool {\n \treturn matchAttribute(n, key,\n \t\tfunc(s string) bool {\n \t\t\tif strings.TrimSpace(s) == \"\" {\n \t\t\t\treturn false\n \t\t\t}\n+\t\t\tif ignoreCase {\n+\t\t\t\treturn strings.HasSuffix(strings.ToLower(s), strings.ToLower(val))\n+\t\t\t}\n \t\t\treturn strings.HasSuffix(s, val)\n \t\t})\n }\n \n // attributeSubstringMatch matches nodes where\n // the attribute named key contains val.\n-func attributeSubstringMatch(key, val string, n *html.Node) bool {\n+func attributeSubstringMatch(key, val string, n *html.Node, ignoreCase bool) bool {\n \treturn matchAttribute(n, key,\n \t\tfunc(s string) bool {\n \t\t\tif strings.TrimSpace(s) == \"\" {\n \t\t\t\treturn false\n \t\t\t}\n+\t\t\tif ignoreCase {\n+\t\t\t\treturn strings.Contains(strings.ToLower(s), strings.ToLower(val))\n+\t\t\t}\n \t\t\treturn strings.Contains(s, val)\n \t\t})\n }\n@@ -407,394 +427,22 @@ func (c attrSelector) PseudoElement() string {\n \treturn \"\"\n }\n \n-// ---------------- Pseudo class selectors ----------------\n-// we use severals concrete types of pseudo-class selectors\n-\n-type relativePseudoClassSelector struct {\n-\tname  string // one of \"not\", \"has\", \"haschild\"\n-\tmatch SelectorGroup\n-}\n-\n-func (s relativePseudoClassSelector) Match(n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\tswitch s.name {\n-\tcase \"not\":\n-\t\t// matches elements that do not match a.\n-\t\treturn !s.match.Match(n)\n-\tcase \"has\":\n-\t\t//  matches elements with any descendant that matches a.\n-\t\treturn hasDescendantMatch(n, s.match)\n-\tcase \"haschild\":\n-\t\t// matches elements with a child that matches a.\n-\t\treturn hasChildMatch(n, s.match)\n-\tdefault:\n-\t\tpanic(fmt.Sprintf(\"unsupported relative pseudo class selector : %s\", s.name))\n-\t}\n-}\n-\n-// hasChildMatch returns whether n has any child that matches a.\n-func hasChildMatch(n *html.Node, a Matcher) bool {\n-\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif a.Match(c) {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// hasDescendantMatch performs a depth-first search of n's descendants,\n-// testing whether any of them match a. It returns true as soon as a match is\n-// found, or false if no match is found.\n-func hasDescendantMatch(n *html.Node, a Matcher) bool {\n-\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif a.Match(c) || (c.Type == html.ElementNode && hasDescendantMatch(c, a)) {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// Specificity returns the specificity of the most specific selectors\n-// in the pseudo-class arguments.\n-// See https://www.w3.org/TR/selectors/#specificity-rules\n-func (s relativePseudoClassSelector) Specificity() Specificity {\n-\tvar max Specificity\n-\tfor _, sel := range s.match {\n-\t\tnewSpe := sel.Specificity()\n-\t\tif max.Less(newSpe) {\n-\t\t\tmax = newSpe\n-\t\t}\n-\t}\n-\treturn max\n-}\n-\n-func (c relativePseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n+// see pseudo_classes.go for pseudo classes selectors\n \n-type containsPseudoClassSelector struct {\n-\town   bool\n+// on a static context, some selectors can't match anything\n+type neverMatchSelector struct {\n \tvalue string\n }\n \n-func (s containsPseudoClassSelector) Match(n *html.Node) bool {\n-\tvar text string\n-\tif s.own {\n-\t\t// matches nodes that directly contain the given text\n-\t\ttext = strings.ToLower(nodeOwnText(n))\n-\t} else {\n-\t\t// matches nodes that contain the given text.\n-\t\ttext = strings.ToLower(nodeText(n))\n-\t}\n-\treturn strings.Contains(text, s.value)\n-}\n-\n-func (s containsPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c containsPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type regexpPseudoClassSelector struct {\n-\town    bool\n-\tregexp *regexp.Regexp\n-}\n-\n-func (s regexpPseudoClassSelector) Match(n *html.Node) bool {\n-\tvar text string\n-\tif s.own {\n-\t\t// matches nodes whose text directly matches the specified regular expression\n-\t\ttext = nodeOwnText(n)\n-\t} else {\n-\t\t// matches nodes whose text matches the specified regular expression\n-\t\ttext = nodeText(n)\n-\t}\n-\treturn s.regexp.MatchString(text)\n-}\n-\n-// writeNodeText writes the text contained in n and its descendants to b.\n-func writeNodeText(n *html.Node, b *bytes.Buffer) {\n-\tswitch n.Type {\n-\tcase html.TextNode:\n-\t\tb.WriteString(n.Data)\n-\tcase html.ElementNode:\n-\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n-\t\t\twriteNodeText(c, b)\n-\t\t}\n-\t}\n-}\n-\n-// nodeText returns the text contained in n and its descendants.\n-func nodeText(n *html.Node) string {\n-\tvar b bytes.Buffer\n-\twriteNodeText(n, &b)\n-\treturn b.String()\n-}\n-\n-// nodeOwnText returns the contents of the text nodes that are direct\n-// children of n.\n-func nodeOwnText(n *html.Node) string {\n-\tvar b bytes.Buffer\n-\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif c.Type == html.TextNode {\n-\t\t\tb.WriteString(c.Data)\n-\t\t}\n-\t}\n-\treturn b.String()\n-}\n-\n-func (s regexpPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c regexpPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type nthPseudoClassSelector struct {\n-\ta, b         int\n-\tlast, ofType bool\n-}\n-\n-func (s nthPseudoClassSelector) Match(n *html.Node) bool {\n-\tif s.a == 0 {\n-\t\tif s.last {\n-\t\t\treturn simpleNthLastChildMatch(s.b, s.ofType, n)\n-\t\t} else {\n-\t\t\treturn simpleNthChildMatch(s.b, s.ofType, n)\n-\t\t}\n-\t}\n-\treturn nthChildMatch(s.a, s.b, s.last, s.ofType, n)\n-}\n-\n-// nthChildMatch implements :nth-child(an+b).\n-// If last is true, implements :nth-last-child instead.\n-// If ofType is true, implements :nth-of-type instead.\n-func nthChildMatch(a, b int, last, ofType bool, n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\n-\tparent := n.Parent\n-\tif parent == nil {\n-\t\treturn false\n-\t}\n-\n-\tif parent.Type == html.DocumentNode {\n-\t\treturn false\n-\t}\n-\n-\ti := -1\n-\tcount := 0\n-\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif (c.Type != html.ElementNode) || (ofType && c.Data != n.Data) {\n-\t\t\tcontinue\n-\t\t}\n-\t\tcount++\n-\t\tif c == n {\n-\t\t\ti = count\n-\t\t\tif !last {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tif i == -1 {\n-\t\t// This shouldn't happen, since n should always be one of its parent's children.\n-\t\treturn false\n-\t}\n-\n-\tif last {\n-\t\ti = count - i + 1\n-\t}\n-\n-\ti -= b\n-\tif a == 0 {\n-\t\treturn i == 0\n-\t}\n-\n-\treturn i%a == 0 && i/a >= 0\n-}\n-\n-// simpleNthChildMatch implements :nth-child(b).\n-// If ofType is true, implements :nth-of-type instead.\n-func simpleNthChildMatch(b int, ofType bool, n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\n-\tparent := n.Parent\n-\tif parent == nil {\n-\t\treturn false\n-\t}\n-\n-\tif parent.Type == html.DocumentNode {\n-\t\treturn false\n-\t}\n-\n-\tcount := 0\n-\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif c.Type != html.ElementNode || (ofType && c.Data != n.Data) {\n-\t\t\tcontinue\n-\t\t}\n-\t\tcount++\n-\t\tif c == n {\n-\t\t\treturn count == b\n-\t\t}\n-\t\tif count >= b {\n-\t\t\treturn false\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// simpleNthLastChildMatch implements :nth-last-child(b).\n-// If ofType is true, implements :nth-last-of-type instead.\n-func simpleNthLastChildMatch(b int, ofType bool, n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\n-\tparent := n.Parent\n-\tif parent == nil {\n-\t\treturn false\n-\t}\n-\n-\tif parent.Type == html.DocumentNode {\n-\t\treturn false\n-\t}\n-\n-\tcount := 0\n-\tfor c := parent.LastChild; c != nil; c = c.PrevSibling {\n-\t\tif c.Type != html.ElementNode || (ofType && c.Data != n.Data) {\n-\t\t\tcontinue\n-\t\t}\n-\t\tcount++\n-\t\tif c == n {\n-\t\t\treturn count == b\n-\t\t}\n-\t\tif count >= b {\n-\t\t\treturn false\n-\t\t}\n-\t}\n+func (s neverMatchSelector) Match(n *html.Node) bool {\n \treturn false\n }\n \n-// Specificity for nth-child pseudo-class.\n-// Does not support a list of selectors\n-func (s nthPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c nthPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type onlyChildPseudoClassSelector struct {\n-\tofType bool\n-}\n-\n-// Match implements :only-child.\n-// If `ofType` is true, it implements :only-of-type instead.\n-func (s onlyChildPseudoClassSelector) Match(n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\n-\tparent := n.Parent\n-\tif parent == nil {\n-\t\treturn false\n-\t}\n-\n-\tif parent.Type == html.DocumentNode {\n-\t\treturn false\n-\t}\n-\n-\tcount := 0\n-\tfor c := parent.FirstChild; c != nil; c = c.NextSibling {\n-\t\tif (c.Type != html.ElementNode) || (s.ofType && c.Data != n.Data) {\n-\t\t\tcontinue\n-\t\t}\n-\t\tcount++\n-\t\tif count > 1 {\n-\t\t\treturn false\n-\t\t}\n-\t}\n-\n-\treturn count == 1\n-}\n-\n-func (s onlyChildPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c onlyChildPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type inputPseudoClassSelector struct{}\n-\n-// Matches input, select, textarea and button elements.\n-func (s inputPseudoClassSelector) Match(n *html.Node) bool {\n-\treturn n.Type == html.ElementNode && (n.Data == \"input\" || n.Data == \"select\" || n.Data == \"textarea\" || n.Data == \"button\")\n-}\n-\n-func (s inputPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c inputPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type emptyElementPseudoClassSelector struct{}\n-\n-// Matches empty elements.\n-func (s emptyElementPseudoClassSelector) Match(n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\n-\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n-\t\tswitch c.Type {\n-\t\tcase html.ElementNode, html.TextNode:\n-\t\t\treturn false\n-\t\t}\n-\t}\n-\n-\treturn true\n-}\n-\n-func (s emptyElementPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n-}\n-\n-func (c emptyElementPseudoClassSelector) PseudoElement() string {\n-\treturn \"\"\n-}\n-\n-type rootPseudoClassSelector struct{}\n-\n-// Match implements :root\n-func (s rootPseudoClassSelector) Match(n *html.Node) bool {\n-\tif n.Type != html.ElementNode {\n-\t\treturn false\n-\t}\n-\tif n.Parent == nil {\n-\t\treturn false\n-\t}\n-\treturn n.Parent.Type == html.DocumentNode\n-}\n-\n-func (s rootPseudoClassSelector) Specificity() Specificity {\n-\treturn Specificity{0, 1, 0}\n+func (s neverMatchSelector) Specificity() Specificity {\n+\treturn Specificity{0, 0, 0}\n }\n \n-func (c rootPseudoClassSelector) PseudoElement() string {\n+func (c neverMatchSelector) PseudoElement() string {\n \treturn \"\"\n }\n "
    },
    {
      "sha": "61acf04e1c69470888485381ea95c1195d908f18",
      "filename": "backend/vendor/github.com/andybalholm/cascadia/serialize.go",
      "status": "modified",
      "additions": 60,
      "deletions": 4,
      "changes": 64,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/serialize.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/andybalholm/cascadia/serialize.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/andybalholm/cascadia/serialize.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -2,21 +2,35 @@ package cascadia\n \n import (\n \t\"fmt\"\n+\t\"strconv\"\n \t\"strings\"\n )\n \n // implements the reverse operation Sel -> string\n \n+var specialCharReplacer *strings.Replacer\n+\n+func init() {\n+\tvar pairs []string\n+\tfor _, s := range \",!\\\"#$%&'()*+ -./:;<=>?@[\\\\]^`{|}~\" {\n+\t\tpairs = append(pairs, string(s), \"\\\\\"+string(s))\n+\t}\n+\tspecialCharReplacer = strings.NewReplacer(pairs...)\n+}\n+\n+// espace special CSS char\n+func escape(s string) string { return specialCharReplacer.Replace(s) }\n+\n func (c tagSelector) String() string {\n \treturn c.tag\n }\n \n func (c idSelector) String() string {\n-\treturn \"#\" + c.id\n+\treturn \"#\" + escape(c.id)\n }\n \n func (c classSelector) String() string {\n-\treturn \".\" + c.class\n+\treturn \".\" + escape(c.class)\n }\n \n func (c attrSelector) String() string {\n@@ -26,26 +40,36 @@ func (c attrSelector) String() string {\n \t} else if c.operation != \"\" {\n \t\tval = fmt.Sprintf(`\"%s\"`, val)\n \t}\n-\treturn fmt.Sprintf(`[%s%s%s]`, c.key, c.operation, val)\n+\n+\tignoreCase := \"\"\n+\n+\tif c.insensitive {\n+\t\tignoreCase = \" i\"\n+\t}\n+\n+\treturn fmt.Sprintf(`[%s%s%s%s]`, c.key, c.operation, val, ignoreCase)\n }\n \n func (c relativePseudoClassSelector) String() string {\n \treturn fmt.Sprintf(\":%s(%s)\", c.name, c.match.String())\n }\n+\n func (c containsPseudoClassSelector) String() string {\n \ts := \"contains\"\n \tif c.own {\n \t\ts += \"Own\"\n \t}\n \treturn fmt.Sprintf(`:%s(\"%s\")`, s, c.value)\n }\n+\n func (c regexpPseudoClassSelector) String() string {\n \ts := \"matches\"\n \tif c.own {\n \t\ts += \"Own\"\n \t}\n \treturn fmt.Sprintf(\":%s(%s)\", s, c.regexp.String())\n }\n+\n func (c nthPseudoClassSelector) String() string {\n \tif c.a == 0 && c.b == 1 { // special cases\n \t\ts := \":first-\"\n@@ -70,24 +94,56 @@ func (c nthPseudoClassSelector) String() string {\n \tcase [2]bool{false, false}:\n \t\tname = \"nth-child\"\n \t}\n-\treturn fmt.Sprintf(\":%s(%dn+%d)\", name, c.a, c.b)\n+\ts := fmt.Sprintf(\"+%d\", c.b)\n+\tif c.b < 0 { // avoid +-8 invalid syntax\n+\t\ts = strconv.Itoa(c.b)\n+\t}\n+\treturn fmt.Sprintf(\":%s(%dn%s)\", name, c.a, s)\n }\n+\n func (c onlyChildPseudoClassSelector) String() string {\n \tif c.ofType {\n \t\treturn \":only-of-type\"\n \t}\n \treturn \":only-child\"\n }\n+\n func (c inputPseudoClassSelector) String() string {\n \treturn \":input\"\n }\n+\n func (c emptyElementPseudoClassSelector) String() string {\n \treturn \":empty\"\n }\n+\n func (c rootPseudoClassSelector) String() string {\n \treturn \":root\"\n }\n \n+func (c linkPseudoClassSelector) String() string {\n+\treturn \":link\"\n+}\n+\n+func (c langPseudoClassSelector) String() string {\n+\treturn fmt.Sprintf(\":lang(%s)\", c.lang)\n+}\n+\n+func (c neverMatchSelector) String() string {\n+\treturn c.value\n+}\n+\n+func (c enabledPseudoClassSelector) String() string {\n+\treturn \":enabled\"\n+}\n+\n+func (c disabledPseudoClassSelector) String() string {\n+\treturn \":disabled\"\n+}\n+\n+func (c checkedPseudoClassSelector) String() string {\n+\treturn \":checked\"\n+}\n+\n func (c compoundSelector) String() string {\n \tif len(c.selectors) == 0 && c.pseudoElement == \"\" {\n \t\treturn \"*\""
    },
    {
      "sha": "daf913b1b347aae6de6f48d599bc89ef8c8693d6",
      "filename": "backend/vendor/github.com/danwakefield/fnmatch/.gitignore",
      "status": "removed",
      "additions": 0,
      "deletions": 24,
      "changes": 24,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/.gitignore",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/.gitignore",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/danwakefield/fnmatch/.gitignore?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,24 +0,0 @@\n-# Compiled Object files, Static and Dynamic libs (Shared Objects)\n-*.o\n-*.a\n-*.so\n-\n-# Folders\n-_obj\n-_test\n-\n-# Architecture specific extensions/prefixes\n-*.[568vq]\n-[568vq].out\n-\n-*.cgo1.go\n-*.cgo2.c\n-_cgo_defun.c\n-_cgo_gotypes.go\n-_cgo_export.*\n-\n-_testmain.go\n-\n-*.exe\n-*.test\n-*.prof"
    },
    {
      "sha": "0dc9851a343895b0075cc43e392b25e6e0826730",
      "filename": "backend/vendor/github.com/danwakefield/fnmatch/LICENSE",
      "status": "removed",
      "additions": 0,
      "deletions": 23,
      "changes": 23,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/LICENSE",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/LICENSE",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/danwakefield/fnmatch/LICENSE?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,23 +0,0 @@\n-Copyright (c) 2016, Daniel Wakefield\n-All rights reserved.\n-\n-Redistribution and use in source and binary forms, with or without\n-modification, are permitted provided that the following conditions are met:\n-\n-* Redistributions of source code must retain the above copyright notice, this\n-  list of conditions and the following disclaimer.\n-\n-* Redistributions in binary form must reproduce the above copyright notice,\n-  this list of conditions and the following disclaimer in the documentation\n-  and/or other materials provided with the distribution.\n-\n-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n-AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n-IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n-DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n-SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n-CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n-OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
    },
    {
      "sha": "b8d715662c223fbb0cefc83a59dc88f5834623d6",
      "filename": "backend/vendor/github.com/danwakefield/fnmatch/README.md",
      "status": "removed",
      "additions": 0,
      "deletions": 4,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/danwakefield/fnmatch/README.md?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,4 +0,0 @@\n-# fnmatch\n-Updated clone of kballards golang fnmatch gist (https://gist.github.com/kballard/272720)\n-\n-"
    },
    {
      "sha": "07ac7b37ca0f6dfc72b828c419877e6bfe431eb2",
      "filename": "backend/vendor/github.com/danwakefield/fnmatch/fnmatch.go",
      "status": "removed",
      "additions": 0,
      "deletions": 219,
      "changes": 219,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/fnmatch.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/github.com/danwakefield/fnmatch/fnmatch.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/danwakefield/fnmatch/fnmatch.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,219 +0,0 @@\n-// Provide string-matching based on fnmatch.3\n-package fnmatch\n-\n-// There are a few issues that I believe to be bugs, but this implementation is\n-// based as closely as possible on BSD fnmatch. These bugs are present in the\n-// source of BSD fnmatch, and so are replicated here. The issues are as follows:\n-//\n-// * FNM_PERIOD is no longer observed after the first * in a pattern\n-//   This only applies to matches done with FNM_PATHNAME as well\n-// * FNM_PERIOD doesn't apply to ranges. According to the documentation,\n-//   a period must be matched explicitly, but a range will match it too\n-\n-import (\n-\t\"unicode\"\n-\t\"unicode/utf8\"\n-)\n-\n-const (\n-\tFNM_NOESCAPE = (1 << iota)\n-\tFNM_PATHNAME\n-\tFNM_PERIOD\n-\n-\tFNM_LEADING_DIR\n-\tFNM_CASEFOLD\n-\n-\tFNM_IGNORECASE = FNM_CASEFOLD\n-\tFNM_FILE_NAME  = FNM_PATHNAME\n-)\n-\n-func unpackRune(str *string) rune {\n-\trune, size := utf8.DecodeRuneInString(*str)\n-\t*str = (*str)[size:]\n-\treturn rune\n-}\n-\n-// Matches the pattern against the string, with the given flags,\n-// and returns true if the match is successful.\n-// This function should match fnmatch.3 as closely as possible.\n-func Match(pattern, s string, flags int) bool {\n-\t// The implementation for this function was patterned after the BSD fnmatch.c\n-\t// source found at http://src.gnu-darwin.org/src/contrib/csup/fnmatch.c.html\n-\tnoescape := (flags&FNM_NOESCAPE != 0)\n-\tpathname := (flags&FNM_PATHNAME != 0)\n-\tperiod := (flags&FNM_PERIOD != 0)\n-\tleadingdir := (flags&FNM_LEADING_DIR != 0)\n-\tcasefold := (flags&FNM_CASEFOLD != 0)\n-\t// the following is some bookkeeping that the original fnmatch.c implementation did not do\n-\t// We are forced to do this because we're not keeping indexes into C strings but rather\n-\t// processing utf8-encoded strings. Use a custom unpacker to maintain our state for us\n-\tsAtStart := true\n-\tsLastAtStart := true\n-\tsLastSlash := false\n-\tsLastUnpacked := rune(0)\n-\tunpackS := func() rune {\n-\t\tsLastSlash = (sLastUnpacked == '/')\n-\t\tsLastUnpacked = unpackRune(&s)\n-\t\tsLastAtStart = sAtStart\n-\t\tsAtStart = false\n-\t\treturn sLastUnpacked\n-\t}\n-\tfor len(pattern) > 0 {\n-\t\tc := unpackRune(&pattern)\n-\t\tswitch c {\n-\t\tcase '?':\n-\t\t\tif len(s) == 0 {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\tsc := unpackS()\n-\t\t\tif pathname && sc == '/' {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\tif period && sc == '.' && (sLastAtStart || (pathname && sLastSlash)) {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\tcase '*':\n-\t\t\t// collapse multiple *'s\n-\t\t\t// don't use unpackRune here, the only char we care to detect is ASCII\n-\t\t\tfor len(pattern) > 0 && pattern[0] == '*' {\n-\t\t\t\tpattern = pattern[1:]\n-\t\t\t}\n-\t\t\tif period && s[0] == '.' && (sAtStart || (pathname && sLastUnpacked == '/')) {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\t// optimize for patterns with * at end or before /\n-\t\t\tif len(pattern) == 0 {\n-\t\t\t\tif pathname {\n-\t\t\t\t\treturn leadingdir || (strchr(s, '/') == -1)\n-\t\t\t\t} else {\n-\t\t\t\t\treturn true\n-\t\t\t\t}\n-\t\t\t\treturn !(pathname && strchr(s, '/') >= 0)\n-\t\t\t} else if pathname && pattern[0] == '/' {\n-\t\t\t\toffset := strchr(s, '/')\n-\t\t\t\tif offset == -1 {\n-\t\t\t\t\treturn false\n-\t\t\t\t} else {\n-\t\t\t\t\t// we already know our pattern and string have a /, skip past it\n-\t\t\t\t\ts = s[offset:] // use unpackS here to maintain our bookkeeping state\n-\t\t\t\t\tunpackS()\n-\t\t\t\t\tpattern = pattern[1:] // we know / is one byte long\n-\t\t\t\t\tbreak\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\t// general case, recurse\n-\t\t\tfor test := s; len(test) > 0; unpackRune(&test) {\n-\t\t\t\t// I believe the (flags &^ FNM_PERIOD) is a bug when FNM_PATHNAME is specified\n-\t\t\t\t// but this follows exactly from how fnmatch.c implements it\n-\t\t\t\tif Match(pattern, test, (flags &^ FNM_PERIOD)) {\n-\t\t\t\t\treturn true\n-\t\t\t\t} else if pathname && test[0] == '/' {\n-\t\t\t\t\tbreak\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\treturn false\n-\t\tcase '[':\n-\t\t\tif len(s) == 0 {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\tif pathname && s[0] == '/' {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\tsc := unpackS()\n-\t\t\tif !rangematch(&pattern, sc, flags) {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\tcase '\\\\':\n-\t\t\tif !noescape {\n-\t\t\t\tif len(pattern) > 0 {\n-\t\t\t\t\tc = unpackRune(&pattern)\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tfallthrough\n-\t\tdefault:\n-\t\t\tif len(s) == 0 {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\tsc := unpackS()\n-\t\t\tswitch {\n-\t\t\tcase sc == c:\n-\t\t\tcase casefold && unicode.ToLower(sc) == unicode.ToLower(c):\n-\t\t\tdefault:\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn len(s) == 0 || (leadingdir && s[0] == '/')\n-}\n-\n-func rangematch(pattern *string, test rune, flags int) bool {\n-\tif len(*pattern) == 0 {\n-\t\treturn false\n-\t}\n-\tcasefold := (flags&FNM_CASEFOLD != 0)\n-\tnoescape := (flags&FNM_NOESCAPE != 0)\n-\tif casefold {\n-\t\ttest = unicode.ToLower(test)\n-\t}\n-\tvar negate, matched bool\n-\tif (*pattern)[0] == '^' || (*pattern)[0] == '!' {\n-\t\tnegate = true\n-\t\t(*pattern) = (*pattern)[1:]\n-\t}\n-\tfor !matched && len(*pattern) > 1 && (*pattern)[0] != ']' {\n-\t\tc := unpackRune(pattern)\n-\t\tif !noescape && c == '\\\\' {\n-\t\t\tif len(*pattern) > 1 {\n-\t\t\t\tc = unpackRune(pattern)\n-\t\t\t} else {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t}\n-\t\tif casefold {\n-\t\t\tc = unicode.ToLower(c)\n-\t\t}\n-\t\tif (*pattern)[0] == '-' && len(*pattern) > 1 && (*pattern)[1] != ']' {\n-\t\t\tunpackRune(pattern) // skip the -\n-\t\t\tc2 := unpackRune(pattern)\n-\t\t\tif !noescape && c2 == '\\\\' {\n-\t\t\t\tif len(*pattern) > 0 {\n-\t\t\t\t\tc2 = unpackRune(pattern)\n-\t\t\t\t} else {\n-\t\t\t\t\treturn false\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif casefold {\n-\t\t\t\tc2 = unicode.ToLower(c2)\n-\t\t\t}\n-\t\t\t// this really should be more intelligent, but it looks like\n-\t\t\t// fnmatch.c does simple int comparisons, therefore we will as well\n-\t\t\tif c <= test && test <= c2 {\n-\t\t\t\tmatched = true\n-\t\t\t}\n-\t\t} else if c == test {\n-\t\t\tmatched = true\n-\t\t}\n-\t}\n-\t// skip past the rest of the pattern\n-\tok := false\n-\tfor !ok && len(*pattern) > 0 {\n-\t\tc := unpackRune(pattern)\n-\t\tif c == '\\\\' && len(*pattern) > 0 {\n-\t\t\tunpackRune(pattern)\n-\t\t} else if c == ']' {\n-\t\t\tok = true\n-\t\t}\n-\t}\n-\treturn ok && matched != negate\n-}\n-\n-// define strchr because strings.Index() seems a bit overkill\n-// returns the index of c in s, or -1 if there is no match\n-func strchr(s string, c rune) int {\n-\tfor i, sc := range s {\n-\t\tif sc == c {\n-\t\t\treturn i\n-\t\t}\n-\t}\n-\treturn -1\n-}"
    },
    {
      "sha": "f7dcaeb80c99a21aec1ac60486cbad8066d2a600",
      "filename": "backend/vendor/github.com/go-chi/chi/v5/CHANGELOG.md",
      "status": "modified",
      "additions": 5,
      "deletions": 0,
      "changes": 5,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/CHANGELOG.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/CHANGELOG.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/go-chi/chi/v5/CHANGELOG.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,5 +1,10 @@\n # Changelog\n \n+## v5.0.5 (2021-10-27)\n+\n+- History of changes: see https://github.com/go-chi/chi/compare/v5.0.4...v5.0.5\n+\n+\n ## v5.0.4 (2021-08-29)\n \n - History of changes: see https://github.com/go-chi/chi/compare/v5.0.3...v5.0.4"
    },
    {
      "sha": "f36e8ccf24bab3d560e678239f966265bf71b241",
      "filename": "backend/vendor/github.com/go-chi/chi/v5/middleware/heartbeat.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/middleware/heartbeat.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/middleware/heartbeat.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/go-chi/chi/v5/middleware/heartbeat.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -12,7 +12,7 @@ import (\n func Heartbeat(endpoint string) func(http.Handler) http.Handler {\n \tf := func(h http.Handler) http.Handler {\n \t\tfn := func(w http.ResponseWriter, r *http.Request) {\n-\t\t\tif r.Method == \"GET\" && strings.EqualFold(r.URL.Path, endpoint) {\n+\t\t\tif (r.Method == \"GET\" || r.Method == \"HEAD\") && strings.EqualFold(r.URL.Path, endpoint) {\n \t\t\t\tw.Header().Set(\"Content-Type\", \"text/plain\")\n \t\t\t\tw.WriteHeader(http.StatusOK)\n \t\t\t\tw.Write([]byte(\".\"))"
    },
    {
      "sha": "c9eafff4524ed13ffb0e226eda95698db9ba3b34",
      "filename": "backend/vendor/github.com/go-chi/chi/v5/middleware/recoverer.go",
      "status": "modified",
      "additions": 6,
      "deletions": 2,
      "changes": 8,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/middleware/recoverer.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/go-chi/chi/v5/middleware/recoverer.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/go-chi/chi/v5/middleware/recoverer.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -7,6 +7,7 @@ import (\n \t\"bytes\"\n \t\"errors\"\n \t\"fmt\"\n+\t\"io\"\n \t\"net/http\"\n \t\"os\"\n \t\"runtime/debug\"\n@@ -40,12 +41,15 @@ func Recoverer(next http.Handler) http.Handler {\n \treturn http.HandlerFunc(fn)\n }\n \n+// for ability to test the PrintPrettyStack function\n+var recovererErrorWriter io.Writer = os.Stderr\n+\n func PrintPrettyStack(rvr interface{}) {\n \tdebugStack := debug.Stack()\n \ts := prettyStack{}\n \tout, err := s.parse(debugStack, rvr)\n \tif err == nil {\n-\t\tos.Stderr.Write(out)\n+\t\trecovererErrorWriter.Write(out)\n \t} else {\n \t\t// print stdlib output as a fallback\n \t\tos.Stderr.Write(debugStack)\n@@ -72,7 +76,7 @@ func (s prettyStack) parse(debugStack []byte, rvr interface{}) ([]byte, error) {\n \t// locate panic line, as we may have nested panics\n \tfor i := len(stack) - 1; i > 0; i-- {\n \t\tlines = append(lines, stack[i])\n-\t\tif strings.HasPrefix(stack[i], \"panic(0x\") {\n+\t\tif strings.HasPrefix(stack[i], \"panic(\") {\n \t\t\tlines = lines[0 : len(lines)-2] // remove boilerplate\n \t\t\tbreak\n \t\t}"
    },
    {
      "sha": "dbf73d4eda65960821d6f17579b68a640c42465e",
      "filename": "backend/vendor/github.com/slack-go/slack/README.md",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/slack-go/slack/README.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -39,7 +39,7 @@ func main() {\n \t// If you set debugging, it will log all requests to the console\n \t// Useful when encountering issues\n \t// slack.New(\"YOUR_TOKEN_HERE\", slack.OptionDebug(true))\n-\tgroups, err := api.GetGroups(false)\n+\tgroups, err := api.GetUserGroups(false)\n \tif err != nil {\n \t\tfmt.Printf(\"%s\\n\", err)\n \t\treturn"
    },
    {
      "sha": "384fee22b6c77886679d4f1e171574cc62d3180e",
      "filename": "backend/vendor/github.com/slack-go/slack/block_context.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/block_context.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/block_context.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/slack-go/slack/block_context.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -3,7 +3,7 @@ package slack\n // ContextBlock defines data that is used to display message context, which can\n // include both images and text.\n //\n-// More Information: https://api.slack.com/reference/messaging/blocks#actions\n+// More Information: https://api.slack.com/reference/messaging/blocks#context\n type ContextBlock struct {\n \tType            MessageBlockType `json:\"type\"`\n \tBlockID         string           `json:\"block_id,omitempty\"`"
    },
    {
      "sha": "9a519e27587d2ac34521fab5cae2f3bf064615ef",
      "filename": "backend/vendor/github.com/slack-go/slack/interactions.go",
      "status": "modified",
      "additions": 6,
      "deletions": 0,
      "changes": 6,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/interactions.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/github.com/slack-go/slack/interactions.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/github.com/slack-go/slack/interactions.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -53,6 +53,7 @@ type InteractionCallback struct {\n \tAPIAppID        string          `json:\"api_app_id\"`\n \tBlockID         string          `json:\"block_id\"`\n \tContainer       Container       `json:\"container\"`\n+\tEnterprise      Enterprise      `json:\"enterprise\"`\n \tDialogSubmissionCallback\n \tViewSubmissionCallback\n \tViewClosedCallback\n@@ -128,6 +129,11 @@ type Container struct {\n \tIsAppUnfurl  bool        `json:\"is_app_unfurl\"`\n }\n \n+type Enterprise struct {\n+\tID   string `json:\"id\"`\n+\tName string `json:\"name\"`\n+}\n+\n // ActionCallback is a convenience struct defined to allow dynamic unmarshalling of\n // the \"actions\" value in Slack's JSON response, which varies depending on block type\n type ActionCallbacks struct {"
    },
    {
      "sha": "dfdb5b6d94aa30ee9c13973738eee1a9d7bc003f",
      "filename": "backend/vendor/go.uber.org/goleak/.travis.yml",
      "status": "removed",
      "additions": 0,
      "deletions": 25,
      "changes": 25,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/go.uber.org/goleak/.travis.yml",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/go.uber.org/goleak/.travis.yml",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/.travis.yml?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,25 +0,0 @@\n-sudo: false\n-language: go\n-go_import_path: go.uber.org/goleak\n-\n-env:\n-  global:\n-    - GO111MODULE=on\n-\n-matrix:\n-  include:\n-  - go: 1.12.x\n-  - go: 1.13.x\n-  - go: 1.14.x\n-    env: LINT=1\n-\n-install:\n-  - make install\n-\n-script:\n-  - test -z \"$LINT\" || make lint\n-  - make test\n-\n-after_success:\n-  - make cover\n-  - bash <(curl -s https://codecov.io/bash)"
    },
    {
      "sha": "a6275e27d3b2974f8e15ae5670e854e3c528c9c7",
      "filename": "backend/vendor/go.uber.org/goleak/CHANGELOG.md",
      "status": "modified",
      "additions": 11,
      "deletions": 1,
      "changes": 12,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/CHANGELOG.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/CHANGELOG.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/CHANGELOG.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -4,7 +4,17 @@ All notable changes to this project will be documented in this file.\n The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/)\n and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html).\n \n-## [1.1.0]\n+## [1.1.12]\n+### Fixed\n+- Fixed logic for ignoring trace related goroutines on Go versions 1.16 and above.\n+\n+## [1.1.11]\n+### Fixed\n+- Documentation fix on how to test.\n+- Update dependency on stretchr/testify to v1.7.0. (#59)\n+- Update dependency on golang.org/x/tools to address CVE-2020-14040. (#62)\n+\n+## [1.1.10]\n ### Added\n - [#49]: Add option to ignore current goroutines, which checks for any additional leaks and allows for incremental adoption of goleak in larger projects.\n "
    },
    {
      "sha": "fb92dabc56d8391a146bc930fc4135a98c18801c",
      "filename": "backend/vendor/go.uber.org/goleak/README.md",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/README.md?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -46,7 +46,7 @@ $ go test -c -o tests\n \n # Run each test individually, printing \".\" for successful tests, or the test name\n # for failing tests.\n-$ for test in $(go test -list . | grep -E \"^(Test|Example)\"); do ./tests -test.run \"^$test\\$\" &>/dev/null && echo -n \".\" || echo \"\\n$test failed\"; done\n+$ for test in $(go test -list . | grep -E \"^(Test|Example)\"); do ./tests -test.run \"^$test\\$\" &>/dev/null && echo -n \".\" || echo -e \"\\n$test failed\"; done\n ```\n \n This will only print names of failing tests which can be investigated individually. E.g.,\n@@ -65,7 +65,7 @@ No breaking changes will be made to exported APIs before 2.0.\n \n [doc-img]: https://godoc.org/go.uber.org/goleak?status.svg\n [doc]: https://godoc.org/go.uber.org/goleak\n-[ci-img]: https://travis-ci.com/uber-go/goleak.svg?branch=master\n-[ci]: https://travis-ci.com/uber-go/goleak\n+[ci-img]: https://github.com/uber-go/goleak/actions/workflows/go.yml/badge.svg\n+[ci]: https://github.com/uber-go/goleak/actions/workflows/go.yml\n [cov-img]: https://codecov.io/gh/uber-go/goleak/branch/master/graph/badge.svg\n [cov]: https://codecov.io/gh/uber-go/goleak"
    },
    {
      "sha": "c596abeb93980aaeb9c688335abb9b79bcfc0298",
      "filename": "backend/vendor/go.uber.org/goleak/go.mod",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/go.mod?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -4,8 +4,8 @@ go 1.13\n \n require (\n \tgithub.com/kr/pretty v0.1.0 // indirect\n-\tgithub.com/stretchr/testify v1.4.0\n+\tgithub.com/stretchr/testify v1.7.0\n \tgolang.org/x/lint v0.0.0-20190930215403-16217165b5de\n-\tgolang.org/x/tools v0.0.0-20191108193012-7d206e10da11 // indirect\n+\tgolang.org/x/tools v0.1.5 // indirect\n \tgopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 // indirect\n )"
    },
    {
      "sha": "31bb5d7fc8e4be84ea0f9684f99ad109e6c1f380",
      "filename": "backend/vendor/go.uber.org/goleak/go.sum",
      "status": "modified",
      "additions": 25,
      "deletions": 7,
      "changes": 32,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/go.sum?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -8,23 +8,41 @@ github.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\n github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\n github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\n github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\n-github.com/stretchr/testify v1.4.0 h1:2E4SXV/wtOkTonXsotYi4li6zVWxYlZuYNCXe9XRJyk=\n-github.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\n+github.com/stretchr/testify v1.7.0 h1:nwc3DEeHmmLAfoZucVR881uASk0Mfjw8xYJ99tb5CcY=\n+github.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\n+github.com/yuin/goldmark v1.3.5/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\n golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\n+golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\n golang.org/x/lint v0.0.0-20190930215403-16217165b5de h1:5hukYrvBGR8/eNkX5mdUezrA6JiaEZDtJb9Ei+1LlBs=\n golang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\n+golang.org/x/mod v0.4.2 h1:Gz96sIWK3OalVv/I/qNygP42zyoKp3xptRVCWRFEBvo=\n+golang.org/x/mod v0.4.2/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\n golang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\n+golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\n golang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\n+golang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\n golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n+golang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n+golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n+golang.org/x/sys v0.0.0-20210510120138-977fb7262007 h1:gG67DSER+11cZvqIMb8S8bt0vZtiN6xWYARwirrOSfE=\n+golang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n+golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\n golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\n+golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\n+golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\n golang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\n-golang.org/x/tools v0.0.0-20191108193012-7d206e10da11 h1:Yq9t9jnGoR+dBuitxdo9l6Q7xh/zOyNnYUtDKaQ3x0E=\n-golang.org/x/tools v0.0.0-20191108193012-7d206e10da11/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n+golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\n+golang.org/x/tools v0.1.5 h1:ouewzE6p+/VEB31YYnTbEJdi8pFqKp4P4n85vwo3DHA=\n+golang.org/x/tools v0.1.5/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\n golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n-gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\n+golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n+golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 h1:go1bK/D/BFZV2I8cIQd1NKEZ+0owSTG1fDTci4IqFcE=\n+golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\n gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 h1:qIbj1fsPNlZgppZ+VLlY7N33q108Sa+fhmuc+sWQYwY=\n gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\n-gopkg.in/yaml.v2 v2.2.2 h1:ZCJp+EgiOT7lHqUV2J862kp8Qj64Jo6az82+3Td9dZw=\n-gopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\n+gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c h1:dUUwHk2QECo/6vqA44rthZ8ie2QXMNeKRTHCNY2nXvo=\n+gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM="
    },
    {
      "sha": "33266f6170085965e60c5af66759722a93ef4372",
      "filename": "backend/vendor/go.uber.org/goleak/options.go",
      "status": "modified",
      "additions": 0,
      "deletions": 8,
      "changes": 8,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/options.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/options.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/options.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -154,11 +154,3 @@ func isStdLibStack(s stack.Stack) bool {\n \t// Using signal.Notify will start a runtime goroutine.\n \treturn strings.Contains(s.Full(), \"runtime.ensureSigM\")\n }\n-\n-func isTraceStack(s stack.Stack) bool {\n-\tif f := s.FirstFunction(); f != \"runtime.goparkunlock\" {\n-\t\treturn false\n-\t}\n-\n-\treturn strings.Contains(s.Full(), \"runtime.ReadTrace\")\n-}"
    },
    {
      "sha": "d12ffd840435dccbea5b6dccd6b2d6c169ffc338",
      "filename": "backend/vendor/go.uber.org/goleak/tracestack_new.go",
      "status": "renamed",
      "additions": 10,
      "deletions": 4,
      "changes": 14,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/tracestack_new.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/tracestack_new.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/tracestack_new.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -1,4 +1,4 @@\n-// Copyright (c) 2019 Uber Technologies, Inc.\n+// Copyright (c) 2021 Uber Technologies, Inc.\n //\n // Permission is hereby granted, free of charge, to any person obtaining a copy\n // of this software and associated documentation files (the \"Software\"), to deal\n@@ -18,11 +18,17 @@\n // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n // THE SOFTWARE.\n \n-// +build tools\n+//go:build go1.16\n+// +build go1.16\n \n package goleak\n \n import (\n-\t// Tools we use during development.\n-\t_ \"golang.org/x/lint/golint\"\n+\t\"strings\"\n+\n+\t\"go.uber.org/goleak/internal/stack\"\n )\n+\n+func isTraceStack(s stack.Stack) bool {\n+\treturn strings.Contains(s.Full(), \"runtime.ReadTrace\")\n+}",
      "previous_filename": "backend/vendor/go.uber.org/goleak/tools.go"
    },
    {
      "sha": "1874384ceb664f7c5d43aba82f22c5bea4181665",
      "filename": "backend/vendor/go.uber.org/goleak/tracestack_old.go",
      "status": "added",
      "additions": 38,
      "deletions": 0,
      "changes": 38,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/tracestack_old.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/go.uber.org/goleak/tracestack_old.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/go.uber.org/goleak/tracestack_old.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -0,0 +1,38 @@\n+// Copyright (c) 2021 Uber Technologies, Inc.\n+//\n+// Permission is hereby granted, free of charge, to any person obtaining a copy\n+// of this software and associated documentation files (the \"Software\"), to deal\n+// in the Software without restriction, including without limitation the rights\n+// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+// copies of the Software, and to permit persons to whom the Software is\n+// furnished to do so, subject to the following conditions:\n+//\n+// The above copyright notice and this permission notice shall be included in\n+// all copies or substantial portions of the Software.\n+//\n+// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n+// THE SOFTWARE.\n+\n+//go:build !go1.16\n+// +build !go1.16\n+\n+package goleak\n+\n+import (\n+\t\"strings\"\n+\n+\t\"go.uber.org/goleak/internal/stack\"\n+)\n+\n+func isTraceStack(s stack.Stack) bool {\n+\tif f := s.FirstFunction(); f != \"runtime.goparkunlock\" {\n+\t\treturn false\n+\t}\n+\n+\treturn strings.Contains(s.Full(), \"runtime.ReadTrace\")\n+}"
    },
    {
      "sha": "73b19ef35a2c1f19764500ecdaa395f91ab45e8f",
      "filename": "backend/vendor/golang.org/x/crypto/acme/acme.go",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/golang.org/x/crypto/acme/acme.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/golang.org/x/crypto/acme/acme.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/crypto/acme/acme.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -4,7 +4,7 @@\n \n // Package acme provides an implementation of the\n // Automatic Certificate Management Environment (ACME) spec.\n-// The intial implementation was based on ACME draft-02 and\n+// The initial implementation was based on ACME draft-02 and\n // is now being extended to comply with RFC 8555.\n // See https://tools.ietf.org/html/draft-ietf-acme-acme-02\n // and https://tools.ietf.org/html/rfc8555 for details."
    },
    {
      "sha": "f9d3011ffc11696adee170abe74c6e34a61c20dc",
      "filename": "backend/vendor/golang.org/x/crypto/acme/rfc8555.go",
      "status": "modified",
      "additions": 26,
      "deletions": 0,
      "changes": 26,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/golang.org/x/crypto/acme/rfc8555.go",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/golang.org/x/crypto/acme/rfc8555.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/crypto/acme/rfc8555.go?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -410,3 +410,29 @@ func isAlreadyRevoked(err error) bool {\n \te, ok := err.(*Error)\n \treturn ok && e.ProblemType == \"urn:ietf:params:acme:error:alreadyRevoked\"\n }\n+\n+// ListCertAlternates retrieves any alternate certificate chain URLs for the\n+// given certificate chain URL. These alternate URLs can be passed to FetchCert\n+// in order to retrieve the alternate certificate chains.\n+//\n+// If there are no alternate issuer certificate chains, a nil slice will be\n+// returned.\n+func (c *Client) ListCertAlternates(ctx context.Context, url string) ([]string, error) {\n+\tif _, err := c.Discover(ctx); err != nil { // required by c.accountKID\n+\t\treturn nil, err\n+\t}\n+\n+\tres, err := c.postAsGet(ctx, url, wantStatus(http.StatusOK))\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tdefer res.Body.Close()\n+\n+\t// We don't need the body but we need to discard it so we don't end up\n+\t// preventing keep-alive\n+\tif _, err := io.Copy(ioutil.Discard, res.Body); err != nil {\n+\t\treturn nil, fmt.Errorf(\"acme: cert alternates response stream: %v\", err)\n+\t}\n+\talts := linkHeader(res.Header, \"alternate\")\n+\treturn alts, nil\n+}"
    },
    {
      "sha": "50553ebd004a3da11af03520d704a97d494b28f5",
      "filename": "backend/vendor/golang.org/x/lint/.travis.yml",
      "status": "removed",
      "additions": 0,
      "deletions": 19,
      "changes": 19,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/.travis.yml",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/.travis.yml",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/.travis.yml?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,19 +0,0 @@\n-sudo: false\n-language: go\n-go:\n-  - 1.10.x\n-  - 1.11.x\n-  - master\n-\n-go_import_path: golang.org/x/lint\n-\n-install:\n-  - go get -t -v ./...\n-\n-script:\n-  - go test -v -race ./...\n-\n-matrix:\n-  allow_failures:\n-    - go: master\n-  fast_finish: true"
    },
    {
      "sha": "1fadda62d2fc8b451a866b645d2286615d621693",
      "filename": "backend/vendor/golang.org/x/lint/CONTRIBUTING.md",
      "status": "removed",
      "additions": 0,
      "deletions": 15,
      "changes": 15,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/CONTRIBUTING.md",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/CONTRIBUTING.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/CONTRIBUTING.md?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,15 +0,0 @@\n-# Contributing to Golint\n-\n-## Before filing an issue:\n-\n-### Are you having trouble building golint?\n-\n-Check you have the latest version of its dependencies. Run\n-```\n-go get -u golang.org/x/lint/golint\n-```\n-If you still have problems, consider searching for existing issues before filing a new issue.\n-\n-## Before sending a pull request:\n-\n-Have you understood the purpose of golint? Make sure to carefully read `README`."
    },
    {
      "sha": "65d761bc9f28c7de26b4f39c495d5ebd365b114d",
      "filename": "backend/vendor/golang.org/x/lint/LICENSE",
      "status": "removed",
      "additions": 0,
      "deletions": 27,
      "changes": 27,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/LICENSE",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/LICENSE",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/LICENSE?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,27 +0,0 @@\n-Copyright (c) 2013 The Go Authors. All rights reserved.\n-\n-Redistribution and use in source and binary forms, with or without\n-modification, are permitted provided that the following conditions are\n-met:\n-\n-   * Redistributions of source code must retain the above copyright\n-notice, this list of conditions and the following disclaimer.\n-   * Redistributions in binary form must reproduce the above\n-copyright notice, this list of conditions and the following disclaimer\n-in the documentation and/or other materials provided with the\n-distribution.\n-   * Neither the name of Google Inc. nor the names of its\n-contributors may be used to endorse or promote products derived from\n-this software without specific prior written permission.\n-\n-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n-\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
    },
    {
      "sha": "4968b13aef7e853c7b12e0c7803d7ef8ec97843d",
      "filename": "backend/vendor/golang.org/x/lint/README.md",
      "status": "removed",
      "additions": 0,
      "deletions": 88,
      "changes": 88,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/README.md",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/README.md",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/README.md?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,88 +0,0 @@\n-Golint is a linter for Go source code.\n-\n-[![Build Status](https://travis-ci.org/golang/lint.svg?branch=master)](https://travis-ci.org/golang/lint)\n-\n-## Installation\n-\n-Golint requires a\n-[supported release of Go](https://golang.org/doc/devel/release.html#policy).\n-\n-    go get -u golang.org/x/lint/golint\n-\n-To find out where `golint` was installed you can run `go list -f {{.Target}} golang.org/x/lint/golint`. For `golint` to be used globally add that directory to the `$PATH` environment setting.\n-\n-## Usage\n-\n-Invoke `golint` with one or more filenames, directories, or packages named\n-by its import path. Golint uses the same\n-[import path syntax](https://golang.org/cmd/go/#hdr-Import_path_syntax) as\n-the `go` command and therefore\n-also supports relative import paths like `./...`. Additionally the `...`\n-wildcard can be used as suffix on relative and absolute file paths to recurse\n-into them.\n-\n-The output of this tool is a list of suggestions in Vim quickfix format,\n-which is accepted by lots of different editors.\n-\n-## Purpose\n-\n-Golint differs from gofmt. Gofmt reformats Go source code, whereas\n-golint prints out style mistakes.\n-\n-Golint differs from govet. Govet is concerned with correctness, whereas\n-golint is concerned with coding style. Golint is in use at Google, and it\n-seeks to match the accepted style of the open source Go project.\n-\n-The suggestions made by golint are exactly that: suggestions.\n-Golint is not perfect, and has both false positives and false negatives.\n-Do not treat its output as a gold standard. We will not be adding pragmas\n-or other knobs to suppress specific warnings, so do not expect or require\n-code to be completely \"lint-free\".\n-In short, this tool is not, and will never be, trustworthy enough for its\n-suggestions to be enforced automatically, for example as part of a build process.\n-Golint makes suggestions for many of the mechanically checkable items listed in\n-[Effective Go](https://golang.org/doc/effective_go.html) and the\n-[CodeReviewComments wiki page](https://golang.org/wiki/CodeReviewComments).\n-\n-## Scope\n-\n-Golint is meant to carry out the stylistic conventions put forth in\n-[Effective Go](https://golang.org/doc/effective_go.html) and\n-[CodeReviewComments](https://golang.org/wiki/CodeReviewComments).\n-Changes that are not aligned with those documents will not be considered.\n-\n-## Contributions\n-\n-Contributions to this project are welcome provided they are [in scope](#scope),\n-though please send mail before starting work on anything major.\n-Contributors retain their copyright, so we need you to fill out\n-[a short form](https://developers.google.com/open-source/cla/individual)\n-before we can accept your contribution.\n-\n-## Vim\n-\n-Add this to your ~/.vimrc:\n-\n-    set rtp+=$GOPATH/src/golang.org/x/lint/misc/vim\n-\n-If you have multiple entries in your GOPATH, replace `$GOPATH` with the right value.\n-\n-Running `:Lint` will run golint on the current file and populate the quickfix list.\n-\n-Optionally, add this to your `~/.vimrc` to automatically run `golint` on `:w`\n-\n-    autocmd BufWritePost,FileWritePost *.go execute 'Lint' | cwindow\n-\n-\n-## Emacs\n-\n-Add this to your `.emacs` file:\n-\n-    (add-to-list 'load-path (concat (getenv \"GOPATH\")  \"/src/golang.org/x/lint/misc/emacs/\"))\n-    (require 'golint)\n-\n-If you have multiple entries in your GOPATH, replace `$GOPATH` with the right value.\n-\n-Running M-x golint will run golint on the current file.\n-\n-For more usage, see [Compilation-Mode](http://www.gnu.org/software/emacs/manual/html_node/emacs/Compilation-Mode.html)."
    },
    {
      "sha": "b32309c45fd6460f80be32c781f94df54a02f213",
      "filename": "backend/vendor/golang.org/x/lint/go.mod",
      "status": "removed",
      "additions": 0,
      "deletions": 5,
      "changes": 5,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/go.mod",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/go.mod",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/go.mod?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,5 +0,0 @@\n-module golang.org/x/lint\n-\n-go 1.11\n-\n-require golang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7"
    },
    {
      "sha": "2ad45cae24645e5ac21ed7d735c704ba126f582c",
      "filename": "backend/vendor/golang.org/x/lint/go.sum",
      "status": "removed",
      "additions": 0,
      "deletions": 12,
      "changes": 12,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/go.sum",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/go.sum",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/go.sum?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,12 +0,0 @@\n-golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\n-golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\n-golang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\n-golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\n-golang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\n-golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\n-golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n-golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\n-golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\n-golang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7 h1:EBZoQjiKKPaLbPrbpssUfuHtwM6KV/vb4U85g/cigFY=\n-golang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\n-golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0="
    },
    {
      "sha": "ac024b6d26f188d5880ddff524dbcb3940d4d6e7",
      "filename": "backend/vendor/golang.org/x/lint/golint/golint.go",
      "status": "removed",
      "additions": 0,
      "deletions": 159,
      "changes": 159,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/golint.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/golint.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/golint/golint.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,159 +0,0 @@\n-// Copyright (c) 2013 The Go Authors. All rights reserved.\n-//\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file or at\n-// https://developers.google.com/open-source/licenses/bsd.\n-\n-// golint lints the Go source files named on its command line.\n-package main\n-\n-import (\n-\t\"flag\"\n-\t\"fmt\"\n-\t\"go/build\"\n-\t\"io/ioutil\"\n-\t\"os\"\n-\t\"path/filepath\"\n-\t\"strings\"\n-\n-\t\"golang.org/x/lint\"\n-)\n-\n-var (\n-\tminConfidence = flag.Float64(\"min_confidence\", 0.8, \"minimum confidence of a problem to print it\")\n-\tsetExitStatus = flag.Bool(\"set_exit_status\", false, \"set exit status to 1 if any issues are found\")\n-\tsuggestions   int\n-)\n-\n-func usage() {\n-\tfmt.Fprintf(os.Stderr, \"Usage of %s:\\n\", os.Args[0])\n-\tfmt.Fprintf(os.Stderr, \"\\tgolint [flags] # runs on package in current directory\\n\")\n-\tfmt.Fprintf(os.Stderr, \"\\tgolint [flags] [packages]\\n\")\n-\tfmt.Fprintf(os.Stderr, \"\\tgolint [flags] [directories] # where a '/...' suffix includes all sub-directories\\n\")\n-\tfmt.Fprintf(os.Stderr, \"\\tgolint [flags] [files] # all must belong to a single package\\n\")\n-\tfmt.Fprintf(os.Stderr, \"Flags:\\n\")\n-\tflag.PrintDefaults()\n-}\n-\n-func main() {\n-\tflag.Usage = usage\n-\tflag.Parse()\n-\n-\tif flag.NArg() == 0 {\n-\t\tlintDir(\".\")\n-\t} else {\n-\t\t// dirsRun, filesRun, and pkgsRun indicate whether golint is applied to\n-\t\t// directory, file or package targets. The distinction affects which\n-\t\t// checks are run. It is no valid to mix target types.\n-\t\tvar dirsRun, filesRun, pkgsRun int\n-\t\tvar args []string\n-\t\tfor _, arg := range flag.Args() {\n-\t\t\tif strings.HasSuffix(arg, \"/...\") && isDir(arg[:len(arg)-len(\"/...\")]) {\n-\t\t\t\tdirsRun = 1\n-\t\t\t\tfor _, dirname := range allPackagesInFS(arg) {\n-\t\t\t\t\targs = append(args, dirname)\n-\t\t\t\t}\n-\t\t\t} else if isDir(arg) {\n-\t\t\t\tdirsRun = 1\n-\t\t\t\targs = append(args, arg)\n-\t\t\t} else if exists(arg) {\n-\t\t\t\tfilesRun = 1\n-\t\t\t\targs = append(args, arg)\n-\t\t\t} else {\n-\t\t\t\tpkgsRun = 1\n-\t\t\t\targs = append(args, arg)\n-\t\t\t}\n-\t\t}\n-\n-\t\tif dirsRun+filesRun+pkgsRun != 1 {\n-\t\t\tusage()\n-\t\t\tos.Exit(2)\n-\t\t}\n-\t\tswitch {\n-\t\tcase dirsRun == 1:\n-\t\t\tfor _, dir := range args {\n-\t\t\t\tlintDir(dir)\n-\t\t\t}\n-\t\tcase filesRun == 1:\n-\t\t\tlintFiles(args...)\n-\t\tcase pkgsRun == 1:\n-\t\t\tfor _, pkg := range importPaths(args) {\n-\t\t\t\tlintPackage(pkg)\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tif *setExitStatus && suggestions > 0 {\n-\t\tfmt.Fprintf(os.Stderr, \"Found %d lint suggestions; failing.\\n\", suggestions)\n-\t\tos.Exit(1)\n-\t}\n-}\n-\n-func isDir(filename string) bool {\n-\tfi, err := os.Stat(filename)\n-\treturn err == nil && fi.IsDir()\n-}\n-\n-func exists(filename string) bool {\n-\t_, err := os.Stat(filename)\n-\treturn err == nil\n-}\n-\n-func lintFiles(filenames ...string) {\n-\tfiles := make(map[string][]byte)\n-\tfor _, filename := range filenames {\n-\t\tsrc, err := ioutil.ReadFile(filename)\n-\t\tif err != nil {\n-\t\t\tfmt.Fprintln(os.Stderr, err)\n-\t\t\tcontinue\n-\t\t}\n-\t\tfiles[filename] = src\n-\t}\n-\n-\tl := new(lint.Linter)\n-\tps, err := l.LintFiles(files)\n-\tif err != nil {\n-\t\tfmt.Fprintf(os.Stderr, \"%v\\n\", err)\n-\t\treturn\n-\t}\n-\tfor _, p := range ps {\n-\t\tif p.Confidence >= *minConfidence {\n-\t\t\tfmt.Printf(\"%v: %s\\n\", p.Position, p.Text)\n-\t\t\tsuggestions++\n-\t\t}\n-\t}\n-}\n-\n-func lintDir(dirname string) {\n-\tpkg, err := build.ImportDir(dirname, 0)\n-\tlintImportedPackage(pkg, err)\n-}\n-\n-func lintPackage(pkgname string) {\n-\tpkg, err := build.Import(pkgname, \".\", 0)\n-\tlintImportedPackage(pkg, err)\n-}\n-\n-func lintImportedPackage(pkg *build.Package, err error) {\n-\tif err != nil {\n-\t\tif _, nogo := err.(*build.NoGoError); nogo {\n-\t\t\t// Don't complain if the failure is due to no Go source files.\n-\t\t\treturn\n-\t\t}\n-\t\tfmt.Fprintln(os.Stderr, err)\n-\t\treturn\n-\t}\n-\n-\tvar files []string\n-\tfiles = append(files, pkg.GoFiles...)\n-\tfiles = append(files, pkg.CgoFiles...)\n-\tfiles = append(files, pkg.TestGoFiles...)\n-\tif pkg.Dir != \".\" {\n-\t\tfor i, f := range files {\n-\t\t\tfiles[i] = filepath.Join(pkg.Dir, f)\n-\t\t}\n-\t}\n-\t// TODO(dsymonds): Do foo_test too (pkg.XTestGoFiles)\n-\n-\tlintFiles(files...)\n-}"
    },
    {
      "sha": "2ba9dea779273cfaafc5d506eb564e1ac8ac6025",
      "filename": "backend/vendor/golang.org/x/lint/golint/import.go",
      "status": "removed",
      "additions": 0,
      "deletions": 309,
      "changes": 309,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/import.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/import.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/golint/import.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,309 +0,0 @@\n-package main\n-\n-/*\n-\n-This file holds a direct copy of the import path matching code of\n-https://github.com/golang/go/blob/master/src/cmd/go/main.go. It can be\n-replaced when https://golang.org/issue/8768 is resolved.\n-\n-It has been updated to follow upstream changes in a few ways.\n-\n-*/\n-\n-import (\n-\t\"fmt\"\n-\t\"go/build\"\n-\t\"log\"\n-\t\"os\"\n-\t\"path\"\n-\t\"path/filepath\"\n-\t\"regexp\"\n-\t\"runtime\"\n-\t\"strings\"\n-)\n-\n-var (\n-\tbuildContext = build.Default\n-\tgoroot       = filepath.Clean(runtime.GOROOT())\n-\tgorootSrc    = filepath.Join(goroot, \"src\")\n-)\n-\n-// importPathsNoDotExpansion returns the import paths to use for the given\n-// command line, but it does no ... expansion.\n-func importPathsNoDotExpansion(args []string) []string {\n-\tif len(args) == 0 {\n-\t\treturn []string{\".\"}\n-\t}\n-\tvar out []string\n-\tfor _, a := range args {\n-\t\t// Arguments are supposed to be import paths, but\n-\t\t// as a courtesy to Windows developers, rewrite \\ to /\n-\t\t// in command-line arguments.  Handles .\\... and so on.\n-\t\tif filepath.Separator == '\\\\' {\n-\t\t\ta = strings.Replace(a, `\\`, `/`, -1)\n-\t\t}\n-\n-\t\t// Put argument in canonical form, but preserve leading ./.\n-\t\tif strings.HasPrefix(a, \"./\") {\n-\t\t\ta = \"./\" + path.Clean(a)\n-\t\t\tif a == \"./.\" {\n-\t\t\t\ta = \".\"\n-\t\t\t}\n-\t\t} else {\n-\t\t\ta = path.Clean(a)\n-\t\t}\n-\t\tif a == \"all\" || a == \"std\" {\n-\t\t\tout = append(out, allPackages(a)...)\n-\t\t\tcontinue\n-\t\t}\n-\t\tout = append(out, a)\n-\t}\n-\treturn out\n-}\n-\n-// importPaths returns the import paths to use for the given command line.\n-func importPaths(args []string) []string {\n-\targs = importPathsNoDotExpansion(args)\n-\tvar out []string\n-\tfor _, a := range args {\n-\t\tif strings.Contains(a, \"...\") {\n-\t\t\tif build.IsLocalImport(a) {\n-\t\t\t\tout = append(out, allPackagesInFS(a)...)\n-\t\t\t} else {\n-\t\t\t\tout = append(out, allPackages(a)...)\n-\t\t\t}\n-\t\t\tcontinue\n-\t\t}\n-\t\tout = append(out, a)\n-\t}\n-\treturn out\n-}\n-\n-// matchPattern(pattern)(name) reports whether\n-// name matches pattern.  Pattern is a limited glob\n-// pattern in which '...' means 'any string' and there\n-// is no other special syntax.\n-func matchPattern(pattern string) func(name string) bool {\n-\tre := regexp.QuoteMeta(pattern)\n-\tre = strings.Replace(re, `\\.\\.\\.`, `.*`, -1)\n-\t// Special case: foo/... matches foo too.\n-\tif strings.HasSuffix(re, `/.*`) {\n-\t\tre = re[:len(re)-len(`/.*`)] + `(/.*)?`\n-\t}\n-\treg := regexp.MustCompile(`^` + re + `$`)\n-\treturn func(name string) bool {\n-\t\treturn reg.MatchString(name)\n-\t}\n-}\n-\n-// hasPathPrefix reports whether the path s begins with the\n-// elements in prefix.\n-func hasPathPrefix(s, prefix string) bool {\n-\tswitch {\n-\tdefault:\n-\t\treturn false\n-\tcase len(s) == len(prefix):\n-\t\treturn s == prefix\n-\tcase len(s) > len(prefix):\n-\t\tif prefix != \"\" && prefix[len(prefix)-1] == '/' {\n-\t\t\treturn strings.HasPrefix(s, prefix)\n-\t\t}\n-\t\treturn s[len(prefix)] == '/' && s[:len(prefix)] == prefix\n-\t}\n-}\n-\n-// treeCanMatchPattern(pattern)(name) reports whether\n-// name or children of name can possibly match pattern.\n-// Pattern is the same limited glob accepted by matchPattern.\n-func treeCanMatchPattern(pattern string) func(name string) bool {\n-\twildCard := false\n-\tif i := strings.Index(pattern, \"...\"); i >= 0 {\n-\t\twildCard = true\n-\t\tpattern = pattern[:i]\n-\t}\n-\treturn func(name string) bool {\n-\t\treturn len(name) <= len(pattern) && hasPathPrefix(pattern, name) ||\n-\t\t\twildCard && strings.HasPrefix(name, pattern)\n-\t}\n-}\n-\n-// allPackages returns all the packages that can be found\n-// under the $GOPATH directories and $GOROOT matching pattern.\n-// The pattern is either \"all\" (all packages), \"std\" (standard packages)\n-// or a path including \"...\".\n-func allPackages(pattern string) []string {\n-\tpkgs := matchPackages(pattern)\n-\tif len(pkgs) == 0 {\n-\t\tfmt.Fprintf(os.Stderr, \"warning: %q matched no packages\\n\", pattern)\n-\t}\n-\treturn pkgs\n-}\n-\n-func matchPackages(pattern string) []string {\n-\tmatch := func(string) bool { return true }\n-\ttreeCanMatch := func(string) bool { return true }\n-\tif pattern != \"all\" && pattern != \"std\" {\n-\t\tmatch = matchPattern(pattern)\n-\t\ttreeCanMatch = treeCanMatchPattern(pattern)\n-\t}\n-\n-\thave := map[string]bool{\n-\t\t\"builtin\": true, // ignore pseudo-package that exists only for documentation\n-\t}\n-\tif !buildContext.CgoEnabled {\n-\t\thave[\"runtime/cgo\"] = true // ignore during walk\n-\t}\n-\tvar pkgs []string\n-\n-\t// Commands\n-\tcmd := filepath.Join(goroot, \"src/cmd\") + string(filepath.Separator)\n-\tfilepath.Walk(cmd, func(path string, fi os.FileInfo, err error) error {\n-\t\tif err != nil || !fi.IsDir() || path == cmd {\n-\t\t\treturn nil\n-\t\t}\n-\t\tname := path[len(cmd):]\n-\t\tif !treeCanMatch(name) {\n-\t\t\treturn filepath.SkipDir\n-\t\t}\n-\t\t// Commands are all in cmd/, not in subdirectories.\n-\t\tif strings.Contains(name, string(filepath.Separator)) {\n-\t\t\treturn filepath.SkipDir\n-\t\t}\n-\n-\t\t// We use, e.g., cmd/gofmt as the pseudo import path for gofmt.\n-\t\tname = \"cmd/\" + name\n-\t\tif have[name] {\n-\t\t\treturn nil\n-\t\t}\n-\t\thave[name] = true\n-\t\tif !match(name) {\n-\t\t\treturn nil\n-\t\t}\n-\t\t_, err = buildContext.ImportDir(path, 0)\n-\t\tif err != nil {\n-\t\t\tif _, noGo := err.(*build.NoGoError); !noGo {\n-\t\t\t\tlog.Print(err)\n-\t\t\t}\n-\t\t\treturn nil\n-\t\t}\n-\t\tpkgs = append(pkgs, name)\n-\t\treturn nil\n-\t})\n-\n-\tfor _, src := range buildContext.SrcDirs() {\n-\t\tif (pattern == \"std\" || pattern == \"cmd\") && src != gorootSrc {\n-\t\t\tcontinue\n-\t\t}\n-\t\tsrc = filepath.Clean(src) + string(filepath.Separator)\n-\t\troot := src\n-\t\tif pattern == \"cmd\" {\n-\t\t\troot += \"cmd\" + string(filepath.Separator)\n-\t\t}\n-\t\tfilepath.Walk(root, func(path string, fi os.FileInfo, err error) error {\n-\t\t\tif err != nil || !fi.IsDir() || path == src {\n-\t\t\t\treturn nil\n-\t\t\t}\n-\n-\t\t\t// Avoid .foo, _foo, and testdata directory trees.\n-\t\t\t_, elem := filepath.Split(path)\n-\t\t\tif strings.HasPrefix(elem, \".\") || strings.HasPrefix(elem, \"_\") || elem == \"testdata\" {\n-\t\t\t\treturn filepath.SkipDir\n-\t\t\t}\n-\n-\t\t\tname := filepath.ToSlash(path[len(src):])\n-\t\t\tif pattern == \"std\" && (strings.Contains(name, \".\") || name == \"cmd\") {\n-\t\t\t\t// The name \"std\" is only the standard library.\n-\t\t\t\t// If the name is cmd, it's the root of the command tree.\n-\t\t\t\treturn filepath.SkipDir\n-\t\t\t}\n-\t\t\tif !treeCanMatch(name) {\n-\t\t\t\treturn filepath.SkipDir\n-\t\t\t}\n-\t\t\tif have[name] {\n-\t\t\t\treturn nil\n-\t\t\t}\n-\t\t\thave[name] = true\n-\t\t\tif !match(name) {\n-\t\t\t\treturn nil\n-\t\t\t}\n-\t\t\t_, err = buildContext.ImportDir(path, 0)\n-\t\t\tif err != nil {\n-\t\t\t\tif _, noGo := err.(*build.NoGoError); noGo {\n-\t\t\t\t\treturn nil\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tpkgs = append(pkgs, name)\n-\t\t\treturn nil\n-\t\t})\n-\t}\n-\treturn pkgs\n-}\n-\n-// allPackagesInFS is like allPackages but is passed a pattern\n-// beginning ./ or ../, meaning it should scan the tree rooted\n-// at the given directory.  There are ... in the pattern too.\n-func allPackagesInFS(pattern string) []string {\n-\tpkgs := matchPackagesInFS(pattern)\n-\tif len(pkgs) == 0 {\n-\t\tfmt.Fprintf(os.Stderr, \"warning: %q matched no packages\\n\", pattern)\n-\t}\n-\treturn pkgs\n-}\n-\n-func matchPackagesInFS(pattern string) []string {\n-\t// Find directory to begin the scan.\n-\t// Could be smarter but this one optimization\n-\t// is enough for now, since ... is usually at the\n-\t// end of a path.\n-\ti := strings.Index(pattern, \"...\")\n-\tdir, _ := path.Split(pattern[:i])\n-\n-\t// pattern begins with ./ or ../.\n-\t// path.Clean will discard the ./ but not the ../.\n-\t// We need to preserve the ./ for pattern matching\n-\t// and in the returned import paths.\n-\tprefix := \"\"\n-\tif strings.HasPrefix(pattern, \"./\") {\n-\t\tprefix = \"./\"\n-\t}\n-\tmatch := matchPattern(pattern)\n-\n-\tvar pkgs []string\n-\tfilepath.Walk(dir, func(path string, fi os.FileInfo, err error) error {\n-\t\tif err != nil || !fi.IsDir() {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif path == dir {\n-\t\t\t// filepath.Walk starts at dir and recurses. For the recursive case,\n-\t\t\t// the path is the result of filepath.Join, which calls filepath.Clean.\n-\t\t\t// The initial case is not Cleaned, though, so we do this explicitly.\n-\t\t\t//\n-\t\t\t// This converts a path like \"./io/\" to \"io\". Without this step, running\n-\t\t\t// \"cd $GOROOT/src/pkg; go list ./io/...\" would incorrectly skip the io\n-\t\t\t// package, because prepending the prefix \"./\" to the unclean path would\n-\t\t\t// result in \"././io\", and match(\"././io\") returns false.\n-\t\t\tpath = filepath.Clean(path)\n-\t\t}\n-\n-\t\t// Avoid .foo, _foo, and testdata directory trees, but do not avoid \".\" or \"..\".\n-\t\t_, elem := filepath.Split(path)\n-\t\tdot := strings.HasPrefix(elem, \".\") && elem != \".\" && elem != \"..\"\n-\t\tif dot || strings.HasPrefix(elem, \"_\") || elem == \"testdata\" {\n-\t\t\treturn filepath.SkipDir\n-\t\t}\n-\n-\t\tname := prefix + filepath.ToSlash(path)\n-\t\tif !match(name) {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif _, err = build.ImportDir(path, 0); err != nil {\n-\t\t\tif _, noGo := err.(*build.NoGoError); !noGo {\n-\t\t\t\tlog.Print(err)\n-\t\t\t}\n-\t\t\treturn nil\n-\t\t}\n-\t\tpkgs = append(pkgs, name)\n-\t\treturn nil\n-\t})\n-\treturn pkgs\n-}"
    },
    {
      "sha": "d5b32f7346494262099012b582235cd1082c1977",
      "filename": "backend/vendor/golang.org/x/lint/golint/importcomment.go",
      "status": "removed",
      "additions": 0,
      "deletions": 13,
      "changes": 13,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/importcomment.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/golint/importcomment.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/golint/importcomment.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,13 +0,0 @@\n-// Copyright (c) 2018 The Go Authors. All rights reserved.\n-//\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file or at\n-// https://developers.google.com/open-source/licenses/bsd.\n-\n-// +build go1.12\n-\n-// Require use of the correct import path only for Go 1.12+ users, so\n-// any breakages coincide with people updating their CI configs or\n-// whatnot.\n-\n-package main // import \"golang.org/x/lint/golint\""
    },
    {
      "sha": "7d813e061ad9c0a232c7ff9d2c2664e263d407cc",
      "filename": "backend/vendor/golang.org/x/lint/lint.go",
      "status": "removed",
      "additions": 0,
      "deletions": 1615,
      "changes": 1615,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/lint.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/lint/lint.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/lint/lint.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,1615 +0,0 @@\n-// Copyright (c) 2013 The Go Authors. All rights reserved.\n-//\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file or at\n-// https://developers.google.com/open-source/licenses/bsd.\n-\n-// Package lint contains a linter for Go source code.\n-package lint // import \"golang.org/x/lint\"\n-\n-import (\n-\t\"bufio\"\n-\t\"bytes\"\n-\t\"fmt\"\n-\t\"go/ast\"\n-\t\"go/parser\"\n-\t\"go/printer\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"regexp\"\n-\t\"sort\"\n-\t\"strconv\"\n-\t\"strings\"\n-\t\"unicode\"\n-\t\"unicode/utf8\"\n-\n-\t\"golang.org/x/tools/go/ast/astutil\"\n-\t\"golang.org/x/tools/go/gcexportdata\"\n-)\n-\n-const styleGuideBase = \"https://golang.org/wiki/CodeReviewComments\"\n-\n-// A Linter lints Go source code.\n-type Linter struct {\n-}\n-\n-// Problem represents a problem in some source code.\n-type Problem struct {\n-\tPosition   token.Position // position in source file\n-\tText       string         // the prose that describes the problem\n-\tLink       string         // (optional) the link to the style guide for the problem\n-\tConfidence float64        // a value in (0,1] estimating the confidence in this problem's correctness\n-\tLineText   string         // the source line\n-\tCategory   string         // a short name for the general category of the problem\n-\n-\t// If the problem has a suggested fix (the minority case),\n-\t// ReplacementLine is a full replacement for the relevant line of the source file.\n-\tReplacementLine string\n-}\n-\n-func (p *Problem) String() string {\n-\tif p.Link != \"\" {\n-\t\treturn p.Text + \"\\n\\n\" + p.Link\n-\t}\n-\treturn p.Text\n-}\n-\n-type byPosition []Problem\n-\n-func (p byPosition) Len() int      { return len(p) }\n-func (p byPosition) Swap(i, j int) { p[i], p[j] = p[j], p[i] }\n-\n-func (p byPosition) Less(i, j int) bool {\n-\tpi, pj := p[i].Position, p[j].Position\n-\n-\tif pi.Filename != pj.Filename {\n-\t\treturn pi.Filename < pj.Filename\n-\t}\n-\tif pi.Line != pj.Line {\n-\t\treturn pi.Line < pj.Line\n-\t}\n-\tif pi.Column != pj.Column {\n-\t\treturn pi.Column < pj.Column\n-\t}\n-\n-\treturn p[i].Text < p[j].Text\n-}\n-\n-// Lint lints src.\n-func (l *Linter) Lint(filename string, src []byte) ([]Problem, error) {\n-\treturn l.LintFiles(map[string][]byte{filename: src})\n-}\n-\n-// LintFiles lints a set of files of a single package.\n-// The argument is a map of filename to source.\n-func (l *Linter) LintFiles(files map[string][]byte) ([]Problem, error) {\n-\tpkg := &pkg{\n-\t\tfset:  token.NewFileSet(),\n-\t\tfiles: make(map[string]*file),\n-\t}\n-\tvar pkgName string\n-\tfor filename, src := range files {\n-\t\tif isGenerated(src) {\n-\t\t\tcontinue // See issue #239\n-\t\t}\n-\t\tf, err := parser.ParseFile(pkg.fset, filename, src, parser.ParseComments)\n-\t\tif err != nil {\n-\t\t\treturn nil, err\n-\t\t}\n-\t\tif pkgName == \"\" {\n-\t\t\tpkgName = f.Name.Name\n-\t\t} else if f.Name.Name != pkgName {\n-\t\t\treturn nil, fmt.Errorf(\"%s is in package %s, not %s\", filename, f.Name.Name, pkgName)\n-\t\t}\n-\t\tpkg.files[filename] = &file{\n-\t\t\tpkg:      pkg,\n-\t\t\tf:        f,\n-\t\t\tfset:     pkg.fset,\n-\t\t\tsrc:      src,\n-\t\t\tfilename: filename,\n-\t\t}\n-\t}\n-\tif len(pkg.files) == 0 {\n-\t\treturn nil, nil\n-\t}\n-\treturn pkg.lint(), nil\n-}\n-\n-var (\n-\tgenHdr = []byte(\"// Code generated \")\n-\tgenFtr = []byte(\" DO NOT EDIT.\")\n-)\n-\n-// isGenerated reports whether the source file is generated code\n-// according the rules from https://golang.org/s/generatedcode.\n-func isGenerated(src []byte) bool {\n-\tsc := bufio.NewScanner(bytes.NewReader(src))\n-\tfor sc.Scan() {\n-\t\tb := sc.Bytes()\n-\t\tif bytes.HasPrefix(b, genHdr) && bytes.HasSuffix(b, genFtr) && len(b) >= len(genHdr)+len(genFtr) {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// pkg represents a package being linted.\n-type pkg struct {\n-\tfset  *token.FileSet\n-\tfiles map[string]*file\n-\n-\ttypesPkg  *types.Package\n-\ttypesInfo *types.Info\n-\n-\t// sortable is the set of types in the package that implement sort.Interface.\n-\tsortable map[string]bool\n-\t// main is whether this is a \"main\" package.\n-\tmain bool\n-\n-\tproblems []Problem\n-}\n-\n-func (p *pkg) lint() []Problem {\n-\tif err := p.typeCheck(); err != nil {\n-\t\t/* TODO(dsymonds): Consider reporting these errors when golint operates on entire packages.\n-\t\tif e, ok := err.(types.Error); ok {\n-\t\t\tpos := p.fset.Position(e.Pos)\n-\t\t\tconf := 1.0\n-\t\t\tif strings.Contains(e.Msg, \"can't find import: \") {\n-\t\t\t\t// Golint is probably being run in a context that doesn't support\n-\t\t\t\t// typechecking (e.g. package files aren't found), so don't warn about it.\n-\t\t\t\tconf = 0\n-\t\t\t}\n-\t\t\tif conf > 0 {\n-\t\t\t\tp.errorfAt(pos, conf, category(\"typechecking\"), e.Msg)\n-\t\t\t}\n-\n-\t\t\t// TODO(dsymonds): Abort if !e.Soft?\n-\t\t}\n-\t\t*/\n-\t}\n-\n-\tp.scanSortable()\n-\tp.main = p.isMain()\n-\n-\tfor _, f := range p.files {\n-\t\tf.lint()\n-\t}\n-\n-\tsort.Sort(byPosition(p.problems))\n-\n-\treturn p.problems\n-}\n-\n-// file represents a file being linted.\n-type file struct {\n-\tpkg      *pkg\n-\tf        *ast.File\n-\tfset     *token.FileSet\n-\tsrc      []byte\n-\tfilename string\n-}\n-\n-func (f *file) isTest() bool { return strings.HasSuffix(f.filename, \"_test.go\") }\n-\n-func (f *file) lint() {\n-\tf.lintPackageComment()\n-\tf.lintImports()\n-\tf.lintBlankImports()\n-\tf.lintExported()\n-\tf.lintNames()\n-\tf.lintElses()\n-\tf.lintRanges()\n-\tf.lintErrorf()\n-\tf.lintErrors()\n-\tf.lintErrorStrings()\n-\tf.lintReceiverNames()\n-\tf.lintIncDec()\n-\tf.lintErrorReturn()\n-\tf.lintUnexportedReturn()\n-\tf.lintTimeNames()\n-\tf.lintContextKeyTypes()\n-\tf.lintContextArgs()\n-}\n-\n-type link string\n-type category string\n-\n-// The variadic arguments may start with link and category types,\n-// and must end with a format string and any arguments.\n-// It returns the new Problem.\n-func (f *file) errorf(n ast.Node, confidence float64, args ...interface{}) *Problem {\n-\tpos := f.fset.Position(n.Pos())\n-\tif pos.Filename == \"\" {\n-\t\tpos.Filename = f.filename\n-\t}\n-\treturn f.pkg.errorfAt(pos, confidence, args...)\n-}\n-\n-func (p *pkg) errorfAt(pos token.Position, confidence float64, args ...interface{}) *Problem {\n-\tproblem := Problem{\n-\t\tPosition:   pos,\n-\t\tConfidence: confidence,\n-\t}\n-\tif pos.Filename != \"\" {\n-\t\t// The file might not exist in our mapping if a //line directive was encountered.\n-\t\tif f, ok := p.files[pos.Filename]; ok {\n-\t\t\tproblem.LineText = srcLine(f.src, pos)\n-\t\t}\n-\t}\n-\n-argLoop:\n-\tfor len(args) > 1 { // always leave at least the format string in args\n-\t\tswitch v := args[0].(type) {\n-\t\tcase link:\n-\t\t\tproblem.Link = string(v)\n-\t\tcase category:\n-\t\t\tproblem.Category = string(v)\n-\t\tdefault:\n-\t\t\tbreak argLoop\n-\t\t}\n-\t\targs = args[1:]\n-\t}\n-\n-\tproblem.Text = fmt.Sprintf(args[0].(string), args[1:]...)\n-\n-\tp.problems = append(p.problems, problem)\n-\treturn &p.problems[len(p.problems)-1]\n-}\n-\n-var newImporter = func(fset *token.FileSet) types.ImporterFrom {\n-\treturn gcexportdata.NewImporter(fset, make(map[string]*types.Package))\n-}\n-\n-func (p *pkg) typeCheck() error {\n-\tconfig := &types.Config{\n-\t\t// By setting a no-op error reporter, the type checker does as much work as possible.\n-\t\tError:    func(error) {},\n-\t\tImporter: newImporter(p.fset),\n-\t}\n-\tinfo := &types.Info{\n-\t\tTypes:  make(map[ast.Expr]types.TypeAndValue),\n-\t\tDefs:   make(map[*ast.Ident]types.Object),\n-\t\tUses:   make(map[*ast.Ident]types.Object),\n-\t\tScopes: make(map[ast.Node]*types.Scope),\n-\t}\n-\tvar anyFile *file\n-\tvar astFiles []*ast.File\n-\tfor _, f := range p.files {\n-\t\tanyFile = f\n-\t\tastFiles = append(astFiles, f.f)\n-\t}\n-\tpkg, err := config.Check(anyFile.f.Name.Name, p.fset, astFiles, info)\n-\t// Remember the typechecking info, even if config.Check failed,\n-\t// since we will get partial information.\n-\tp.typesPkg = pkg\n-\tp.typesInfo = info\n-\treturn err\n-}\n-\n-func (p *pkg) typeOf(expr ast.Expr) types.Type {\n-\tif p.typesInfo == nil {\n-\t\treturn nil\n-\t}\n-\treturn p.typesInfo.TypeOf(expr)\n-}\n-\n-func (p *pkg) isNamedType(typ types.Type, importPath, name string) bool {\n-\tn, ok := typ.(*types.Named)\n-\tif !ok {\n-\t\treturn false\n-\t}\n-\ttn := n.Obj()\n-\treturn tn != nil && tn.Pkg() != nil && tn.Pkg().Path() == importPath && tn.Name() == name\n-}\n-\n-// scopeOf returns the tightest scope encompassing id.\n-func (p *pkg) scopeOf(id *ast.Ident) *types.Scope {\n-\tvar scope *types.Scope\n-\tif obj := p.typesInfo.ObjectOf(id); obj != nil {\n-\t\tscope = obj.Parent()\n-\t}\n-\tif scope == p.typesPkg.Scope() {\n-\t\t// We were given a top-level identifier.\n-\t\t// Use the file-level scope instead of the package-level scope.\n-\t\tpos := id.Pos()\n-\t\tfor _, f := range p.files {\n-\t\t\tif f.f.Pos() <= pos && pos < f.f.End() {\n-\t\t\t\tscope = p.typesInfo.Scopes[f.f]\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn scope\n-}\n-\n-func (p *pkg) scanSortable() {\n-\tp.sortable = make(map[string]bool)\n-\n-\t// bitfield for which methods exist on each type.\n-\tconst (\n-\t\tLen = 1 << iota\n-\t\tLess\n-\t\tSwap\n-\t)\n-\tnmap := map[string]int{\"Len\": Len, \"Less\": Less, \"Swap\": Swap}\n-\thas := make(map[string]int)\n-\tfor _, f := range p.files {\n-\t\tf.walk(func(n ast.Node) bool {\n-\t\t\tfn, ok := n.(*ast.FuncDecl)\n-\t\t\tif !ok || fn.Recv == nil || len(fn.Recv.List) == 0 {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t\t// TODO(dsymonds): We could check the signature to be more precise.\n-\t\t\trecv := receiverType(fn)\n-\t\t\tif i, ok := nmap[fn.Name.Name]; ok {\n-\t\t\t\thas[recv] |= i\n-\t\t\t}\n-\t\t\treturn false\n-\t\t})\n-\t}\n-\tfor typ, ms := range has {\n-\t\tif ms == Len|Less|Swap {\n-\t\t\tp.sortable[typ] = true\n-\t\t}\n-\t}\n-}\n-\n-func (p *pkg) isMain() bool {\n-\tfor _, f := range p.files {\n-\t\tif f.isMain() {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-func (f *file) isMain() bool {\n-\tif f.f.Name.Name == \"main\" {\n-\t\treturn true\n-\t}\n-\treturn false\n-}\n-\n-// lintPackageComment checks package comments. It complains if\n-// there is no package comment, or if it is not of the right form.\n-// This has a notable false positive in that a package comment\n-// could rightfully appear in a different file of the same package,\n-// but that's not easy to fix since this linter is file-oriented.\n-func (f *file) lintPackageComment() {\n-\tif f.isTest() {\n-\t\treturn\n-\t}\n-\n-\tconst ref = styleGuideBase + \"#package-comments\"\n-\tprefix := \"Package \" + f.f.Name.Name + \" \"\n-\n-\t// Look for a detached package comment.\n-\t// First, scan for the last comment that occurs before the \"package\" keyword.\n-\tvar lastCG *ast.CommentGroup\n-\tfor _, cg := range f.f.Comments {\n-\t\tif cg.Pos() > f.f.Package {\n-\t\t\t// Gone past \"package\" keyword.\n-\t\t\tbreak\n-\t\t}\n-\t\tlastCG = cg\n-\t}\n-\tif lastCG != nil && strings.HasPrefix(lastCG.Text(), prefix) {\n-\t\tendPos := f.fset.Position(lastCG.End())\n-\t\tpkgPos := f.fset.Position(f.f.Package)\n-\t\tif endPos.Line+1 < pkgPos.Line {\n-\t\t\t// There isn't a great place to anchor this error;\n-\t\t\t// the start of the blank lines between the doc and the package statement\n-\t\t\t// is at least pointing at the location of the problem.\n-\t\t\tpos := token.Position{\n-\t\t\t\tFilename: endPos.Filename,\n-\t\t\t\t// Offset not set; it is non-trivial, and doesn't appear to be needed.\n-\t\t\t\tLine:   endPos.Line + 1,\n-\t\t\t\tColumn: 1,\n-\t\t\t}\n-\t\t\tf.pkg.errorfAt(pos, 0.9, link(ref), category(\"comments\"), \"package comment is detached; there should be no blank lines between it and the package statement\")\n-\t\t\treturn\n-\t\t}\n-\t}\n-\n-\tif f.f.Doc == nil {\n-\t\tf.errorf(f.f, 0.2, link(ref), category(\"comments\"), \"should have a package comment, unless it's in another file for this package\")\n-\t\treturn\n-\t}\n-\ts := f.f.Doc.Text()\n-\tif ts := strings.TrimLeft(s, \" \\t\"); ts != s {\n-\t\tf.errorf(f.f.Doc, 1, link(ref), category(\"comments\"), \"package comment should not have leading space\")\n-\t\ts = ts\n-\t}\n-\t// Only non-main packages need to keep to this form.\n-\tif !f.pkg.main && !strings.HasPrefix(s, prefix) {\n-\t\tf.errorf(f.f.Doc, 1, link(ref), category(\"comments\"), `package comment should be of the form \"%s...\"`, prefix)\n-\t}\n-}\n-\n-// lintBlankImports complains if a non-main package has blank imports that are\n-// not documented.\n-func (f *file) lintBlankImports() {\n-\t// In package main and in tests, we don't complain about blank imports.\n-\tif f.pkg.main || f.isTest() {\n-\t\treturn\n-\t}\n-\n-\t// The first element of each contiguous group of blank imports should have\n-\t// an explanatory comment of some kind.\n-\tfor i, imp := range f.f.Imports {\n-\t\tpos := f.fset.Position(imp.Pos())\n-\n-\t\tif !isBlank(imp.Name) {\n-\t\t\tcontinue // Ignore non-blank imports.\n-\t\t}\n-\t\tif i > 0 {\n-\t\t\tprev := f.f.Imports[i-1]\n-\t\t\tprevPos := f.fset.Position(prev.Pos())\n-\t\t\tif isBlank(prev.Name) && prevPos.Line+1 == pos.Line {\n-\t\t\t\tcontinue // A subsequent blank in a group.\n-\t\t\t}\n-\t\t}\n-\n-\t\t// This is the first blank import of a group.\n-\t\tif imp.Doc == nil && imp.Comment == nil {\n-\t\t\tref := \"\"\n-\t\t\tf.errorf(imp, 1, link(ref), category(\"imports\"), \"a blank import should be only in a main or test package, or have a comment justifying it\")\n-\t\t}\n-\t}\n-}\n-\n-// lintImports examines import blocks.\n-func (f *file) lintImports() {\n-\tfor i, is := range f.f.Imports {\n-\t\t_ = i\n-\t\tif is.Name != nil && is.Name.Name == \".\" && !f.isTest() {\n-\t\t\tf.errorf(is, 1, link(styleGuideBase+\"#import-dot\"), category(\"imports\"), \"should not use dot imports\")\n-\t\t}\n-\n-\t}\n-}\n-\n-const docCommentsLink = styleGuideBase + \"#doc-comments\"\n-\n-// lintExported examines the exported names.\n-// It complains if any required doc comments are missing,\n-// or if they are not of the right form. The exact rules are in\n-// lintFuncDoc, lintTypeDoc and lintValueSpecDoc; this function\n-// also tracks the GenDecl structure being traversed to permit\n-// doc comments for constants to be on top of the const block.\n-// It also complains if the names stutter when combined with\n-// the package name.\n-func (f *file) lintExported() {\n-\tif f.isTest() {\n-\t\treturn\n-\t}\n-\n-\tvar lastGen *ast.GenDecl // last GenDecl entered.\n-\n-\t// Set of GenDecls that have already had missing comments flagged.\n-\tgenDeclMissingComments := make(map[*ast.GenDecl]bool)\n-\n-\tf.walk(func(node ast.Node) bool {\n-\t\tswitch v := node.(type) {\n-\t\tcase *ast.GenDecl:\n-\t\t\tif v.Tok == token.IMPORT {\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t\t// token.CONST, token.TYPE or token.VAR\n-\t\t\tlastGen = v\n-\t\t\treturn true\n-\t\tcase *ast.FuncDecl:\n-\t\t\tf.lintFuncDoc(v)\n-\t\t\tif v.Recv == nil {\n-\t\t\t\t// Only check for stutter on functions, not methods.\n-\t\t\t\t// Method names are not used package-qualified.\n-\t\t\t\tf.checkStutter(v.Name, \"func\")\n-\t\t\t}\n-\t\t\t// Don't proceed inside funcs.\n-\t\t\treturn false\n-\t\tcase *ast.TypeSpec:\n-\t\t\t// inside a GenDecl, which usually has the doc\n-\t\t\tdoc := v.Doc\n-\t\t\tif doc == nil {\n-\t\t\t\tdoc = lastGen.Doc\n-\t\t\t}\n-\t\t\tf.lintTypeDoc(v, doc)\n-\t\t\tf.checkStutter(v.Name, \"type\")\n-\t\t\t// Don't proceed inside types.\n-\t\t\treturn false\n-\t\tcase *ast.ValueSpec:\n-\t\t\tf.lintValueSpecDoc(v, lastGen, genDeclMissingComments)\n-\t\t\treturn false\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-var (\n-\tallCapsRE = regexp.MustCompile(`^[A-Z0-9_]+$`)\n-\tanyCapsRE = regexp.MustCompile(`[A-Z]`)\n-)\n-\n-// knownNameExceptions is a set of names that are known to be exempt from naming checks.\n-// This is usually because they are constrained by having to match names in the\n-// standard library.\n-var knownNameExceptions = map[string]bool{\n-\t\"LastInsertId\": true, // must match database/sql\n-\t\"kWh\":          true,\n-}\n-\n-func isInTopLevel(f *ast.File, ident *ast.Ident) bool {\n-\tpath, _ := astutil.PathEnclosingInterval(f, ident.Pos(), ident.End())\n-\tfor _, f := range path {\n-\t\tswitch f.(type) {\n-\t\tcase *ast.File, *ast.GenDecl, *ast.ValueSpec, *ast.Ident:\n-\t\t\tcontinue\n-\t\t}\n-\t\treturn false\n-\t}\n-\treturn true\n-}\n-\n-// lintNames examines all names in the file.\n-// It complains if any use underscores or incorrect known initialisms.\n-func (f *file) lintNames() {\n-\t// Package names need slightly different handling than other names.\n-\tif strings.Contains(f.f.Name.Name, \"_\") && !strings.HasSuffix(f.f.Name.Name, \"_test\") {\n-\t\tf.errorf(f.f, 1, link(\"http://golang.org/doc/effective_go.html#package-names\"), category(\"naming\"), \"don't use an underscore in package name\")\n-\t}\n-\tif anyCapsRE.MatchString(f.f.Name.Name) {\n-\t\tf.errorf(f.f, 1, link(\"http://golang.org/doc/effective_go.html#package-names\"), category(\"mixed-caps\"), \"don't use MixedCaps in package name; %s should be %s\", f.f.Name.Name, strings.ToLower(f.f.Name.Name))\n-\t}\n-\n-\tcheck := func(id *ast.Ident, thing string) {\n-\t\tif id.Name == \"_\" {\n-\t\t\treturn\n-\t\t}\n-\t\tif knownNameExceptions[id.Name] {\n-\t\t\treturn\n-\t\t}\n-\n-\t\t// Handle two common styles from other languages that don't belong in Go.\n-\t\tif len(id.Name) >= 5 && allCapsRE.MatchString(id.Name) && strings.Contains(id.Name, \"_\") {\n-\t\t\tcapCount := 0\n-\t\t\tfor _, c := range id.Name {\n-\t\t\t\tif 'A' <= c && c <= 'Z' {\n-\t\t\t\t\tcapCount++\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif capCount >= 2 {\n-\t\t\t\tf.errorf(id, 0.8, link(styleGuideBase+\"#mixed-caps\"), category(\"naming\"), \"don't use ALL_CAPS in Go names; use CamelCase\")\n-\t\t\t\treturn\n-\t\t\t}\n-\t\t}\n-\t\tif thing == \"const\" || (thing == \"var\" && isInTopLevel(f.f, id)) {\n-\t\t\tif len(id.Name) > 2 && id.Name[0] == 'k' && id.Name[1] >= 'A' && id.Name[1] <= 'Z' {\n-\t\t\t\tshould := string(id.Name[1]+'a'-'A') + id.Name[2:]\n-\t\t\t\tf.errorf(id, 0.8, link(styleGuideBase+\"#mixed-caps\"), category(\"naming\"), \"don't use leading k in Go names; %s %s should be %s\", thing, id.Name, should)\n-\t\t\t}\n-\t\t}\n-\n-\t\tshould := lintName(id.Name)\n-\t\tif id.Name == should {\n-\t\t\treturn\n-\t\t}\n-\n-\t\tif len(id.Name) > 2 && strings.Contains(id.Name[1:], \"_\") {\n-\t\t\tf.errorf(id, 0.9, link(\"http://golang.org/doc/effective_go.html#mixed-caps\"), category(\"naming\"), \"don't use underscores in Go names; %s %s should be %s\", thing, id.Name, should)\n-\t\t\treturn\n-\t\t}\n-\t\tf.errorf(id, 0.8, link(styleGuideBase+\"#initialisms\"), category(\"naming\"), \"%s %s should be %s\", thing, id.Name, should)\n-\t}\n-\tcheckList := func(fl *ast.FieldList, thing string) {\n-\t\tif fl == nil {\n-\t\t\treturn\n-\t\t}\n-\t\tfor _, f := range fl.List {\n-\t\t\tfor _, id := range f.Names {\n-\t\t\t\tcheck(id, thing)\n-\t\t\t}\n-\t\t}\n-\t}\n-\tf.walk(func(node ast.Node) bool {\n-\t\tswitch v := node.(type) {\n-\t\tcase *ast.AssignStmt:\n-\t\t\tif v.Tok == token.ASSIGN {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t\tfor _, exp := range v.Lhs {\n-\t\t\t\tif id, ok := exp.(*ast.Ident); ok {\n-\t\t\t\t\tcheck(id, \"var\")\n-\t\t\t\t}\n-\t\t\t}\n-\t\tcase *ast.FuncDecl:\n-\t\t\tif f.isTest() && (strings.HasPrefix(v.Name.Name, \"Example\") || strings.HasPrefix(v.Name.Name, \"Test\") || strings.HasPrefix(v.Name.Name, \"Benchmark\")) {\n-\t\t\t\treturn true\n-\t\t\t}\n-\n-\t\t\tthing := \"func\"\n-\t\t\tif v.Recv != nil {\n-\t\t\t\tthing = \"method\"\n-\t\t\t}\n-\n-\t\t\t// Exclude naming warnings for functions that are exported to C but\n-\t\t\t// not exported in the Go API.\n-\t\t\t// See https://github.com/golang/lint/issues/144.\n-\t\t\tif ast.IsExported(v.Name.Name) || !isCgoExported(v) {\n-\t\t\t\tcheck(v.Name, thing)\n-\t\t\t}\n-\n-\t\t\tcheckList(v.Type.Params, thing+\" parameter\")\n-\t\t\tcheckList(v.Type.Results, thing+\" result\")\n-\t\tcase *ast.GenDecl:\n-\t\t\tif v.Tok == token.IMPORT {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t\tvar thing string\n-\t\t\tswitch v.Tok {\n-\t\t\tcase token.CONST:\n-\t\t\t\tthing = \"const\"\n-\t\t\tcase token.TYPE:\n-\t\t\t\tthing = \"type\"\n-\t\t\tcase token.VAR:\n-\t\t\t\tthing = \"var\"\n-\t\t\t}\n-\t\t\tfor _, spec := range v.Specs {\n-\t\t\t\tswitch s := spec.(type) {\n-\t\t\t\tcase *ast.TypeSpec:\n-\t\t\t\t\tcheck(s.Name, thing)\n-\t\t\t\tcase *ast.ValueSpec:\n-\t\t\t\t\tfor _, id := range s.Names {\n-\t\t\t\t\t\tcheck(id, thing)\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\tcase *ast.InterfaceType:\n-\t\t\t// Do not check interface method names.\n-\t\t\t// They are often constrainted by the method names of concrete types.\n-\t\t\tfor _, x := range v.Methods.List {\n-\t\t\t\tft, ok := x.Type.(*ast.FuncType)\n-\t\t\t\tif !ok { // might be an embedded interface name\n-\t\t\t\t\tcontinue\n-\t\t\t\t}\n-\t\t\t\tcheckList(ft.Params, \"interface method parameter\")\n-\t\t\t\tcheckList(ft.Results, \"interface method result\")\n-\t\t\t}\n-\t\tcase *ast.RangeStmt:\n-\t\t\tif v.Tok == token.ASSIGN {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t\tif id, ok := v.Key.(*ast.Ident); ok {\n-\t\t\t\tcheck(id, \"range var\")\n-\t\t\t}\n-\t\t\tif id, ok := v.Value.(*ast.Ident); ok {\n-\t\t\t\tcheck(id, \"range var\")\n-\t\t\t}\n-\t\tcase *ast.StructType:\n-\t\t\tfor _, f := range v.Fields.List {\n-\t\t\t\tfor _, id := range f.Names {\n-\t\t\t\t\tcheck(id, \"struct field\")\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-// lintName returns a different name if it should be different.\n-func lintName(name string) (should string) {\n-\t// Fast path for simple cases: \"_\" and all lowercase.\n-\tif name == \"_\" {\n-\t\treturn name\n-\t}\n-\tallLower := true\n-\tfor _, r := range name {\n-\t\tif !unicode.IsLower(r) {\n-\t\t\tallLower = false\n-\t\t\tbreak\n-\t\t}\n-\t}\n-\tif allLower {\n-\t\treturn name\n-\t}\n-\n-\t// Split camelCase at any lower->upper transition, and split on underscores.\n-\t// Check each word for common initialisms.\n-\trunes := []rune(name)\n-\tw, i := 0, 0 // index of start of word, scan\n-\tfor i+1 <= len(runes) {\n-\t\teow := false // whether we hit the end of a word\n-\t\tif i+1 == len(runes) {\n-\t\t\teow = true\n-\t\t} else if runes[i+1] == '_' {\n-\t\t\t// underscore; shift the remainder forward over any run of underscores\n-\t\t\teow = true\n-\t\t\tn := 1\n-\t\t\tfor i+n+1 < len(runes) && runes[i+n+1] == '_' {\n-\t\t\t\tn++\n-\t\t\t}\n-\n-\t\t\t// Leave at most one underscore if the underscore is between two digits\n-\t\t\tif i+n+1 < len(runes) && unicode.IsDigit(runes[i]) && unicode.IsDigit(runes[i+n+1]) {\n-\t\t\t\tn--\n-\t\t\t}\n-\n-\t\t\tcopy(runes[i+1:], runes[i+n+1:])\n-\t\t\trunes = runes[:len(runes)-n]\n-\t\t} else if unicode.IsLower(runes[i]) && !unicode.IsLower(runes[i+1]) {\n-\t\t\t// lower->non-lower\n-\t\t\teow = true\n-\t\t}\n-\t\ti++\n-\t\tif !eow {\n-\t\t\tcontinue\n-\t\t}\n-\n-\t\t// [w,i) is a word.\n-\t\tword := string(runes[w:i])\n-\t\tif u := strings.ToUpper(word); commonInitialisms[u] {\n-\t\t\t// Keep consistent case, which is lowercase only at the start.\n-\t\t\tif w == 0 && unicode.IsLower(runes[w]) {\n-\t\t\t\tu = strings.ToLower(u)\n-\t\t\t}\n-\t\t\t// All the common initialisms are ASCII,\n-\t\t\t// so we can replace the bytes exactly.\n-\t\t\tcopy(runes[w:], []rune(u))\n-\t\t} else if w > 0 && strings.ToLower(word) == word {\n-\t\t\t// already all lowercase, and not the first word, so uppercase the first character.\n-\t\t\trunes[w] = unicode.ToUpper(runes[w])\n-\t\t}\n-\t\tw = i\n-\t}\n-\treturn string(runes)\n-}\n-\n-// commonInitialisms is a set of common initialisms.\n-// Only add entries that are highly unlikely to be non-initialisms.\n-// For instance, \"ID\" is fine (Freudian code is rare), but \"AND\" is not.\n-var commonInitialisms = map[string]bool{\n-\t\"ACL\":   true,\n-\t\"API\":   true,\n-\t\"ASCII\": true,\n-\t\"CPU\":   true,\n-\t\"CSS\":   true,\n-\t\"DNS\":   true,\n-\t\"EOF\":   true,\n-\t\"GUID\":  true,\n-\t\"HTML\":  true,\n-\t\"HTTP\":  true,\n-\t\"HTTPS\": true,\n-\t\"ID\":    true,\n-\t\"IP\":    true,\n-\t\"JSON\":  true,\n-\t\"LHS\":   true,\n-\t\"QPS\":   true,\n-\t\"RAM\":   true,\n-\t\"RHS\":   true,\n-\t\"RPC\":   true,\n-\t\"SLA\":   true,\n-\t\"SMTP\":  true,\n-\t\"SQL\":   true,\n-\t\"SSH\":   true,\n-\t\"TCP\":   true,\n-\t\"TLS\":   true,\n-\t\"TTL\":   true,\n-\t\"UDP\":   true,\n-\t\"UI\":    true,\n-\t\"UID\":   true,\n-\t\"UUID\":  true,\n-\t\"URI\":   true,\n-\t\"URL\":   true,\n-\t\"UTF8\":  true,\n-\t\"VM\":    true,\n-\t\"XML\":   true,\n-\t\"XMPP\":  true,\n-\t\"XSRF\":  true,\n-\t\"XSS\":   true,\n-}\n-\n-// lintTypeDoc examines the doc comment on a type.\n-// It complains if they are missing from an exported type,\n-// or if they are not of the standard form.\n-func (f *file) lintTypeDoc(t *ast.TypeSpec, doc *ast.CommentGroup) {\n-\tif !ast.IsExported(t.Name.Name) {\n-\t\treturn\n-\t}\n-\tif doc == nil {\n-\t\tf.errorf(t, 1, link(docCommentsLink), category(\"comments\"), \"exported type %v should have comment or be unexported\", t.Name)\n-\t\treturn\n-\t}\n-\n-\ts := doc.Text()\n-\tarticles := [...]string{\"A\", \"An\", \"The\"}\n-\tfor _, a := range articles {\n-\t\tif strings.HasPrefix(s, a+\" \") {\n-\t\t\ts = s[len(a)+1:]\n-\t\t\tbreak\n-\t\t}\n-\t}\n-\tif !strings.HasPrefix(s, t.Name.Name+\" \") {\n-\t\tf.errorf(doc, 1, link(docCommentsLink), category(\"comments\"), `comment on exported type %v should be of the form \"%v ...\" (with optional leading article)`, t.Name, t.Name)\n-\t}\n-}\n-\n-var commonMethods = map[string]bool{\n-\t\"Error\":     true,\n-\t\"Read\":      true,\n-\t\"ServeHTTP\": true,\n-\t\"String\":    true,\n-\t\"Write\":     true,\n-\t\"Unwrap\":    true,\n-}\n-\n-// lintFuncDoc examines doc comments on functions and methods.\n-// It complains if they are missing, or not of the right form.\n-// It has specific exclusions for well-known methods (see commonMethods above).\n-func (f *file) lintFuncDoc(fn *ast.FuncDecl) {\n-\tif !ast.IsExported(fn.Name.Name) {\n-\t\t// func is unexported\n-\t\treturn\n-\t}\n-\tkind := \"function\"\n-\tname := fn.Name.Name\n-\tif fn.Recv != nil && len(fn.Recv.List) > 0 {\n-\t\t// method\n-\t\tkind = \"method\"\n-\t\trecv := receiverType(fn)\n-\t\tif !ast.IsExported(recv) {\n-\t\t\t// receiver is unexported\n-\t\t\treturn\n-\t\t}\n-\t\tif commonMethods[name] {\n-\t\t\treturn\n-\t\t}\n-\t\tswitch name {\n-\t\tcase \"Len\", \"Less\", \"Swap\":\n-\t\t\tif f.pkg.sortable[recv] {\n-\t\t\t\treturn\n-\t\t\t}\n-\t\t}\n-\t\tname = recv + \".\" + name\n-\t}\n-\tif fn.Doc == nil {\n-\t\tf.errorf(fn, 1, link(docCommentsLink), category(\"comments\"), \"exported %s %s should have comment or be unexported\", kind, name)\n-\t\treturn\n-\t}\n-\ts := fn.Doc.Text()\n-\tprefix := fn.Name.Name + \" \"\n-\tif !strings.HasPrefix(s, prefix) {\n-\t\tf.errorf(fn.Doc, 1, link(docCommentsLink), category(\"comments\"), `comment on exported %s %s should be of the form \"%s...\"`, kind, name, prefix)\n-\t}\n-}\n-\n-// lintValueSpecDoc examines package-global variables and constants.\n-// It complains if they are not individually declared,\n-// or if they are not suitably documented in the right form (unless they are in a block that is commented).\n-func (f *file) lintValueSpecDoc(vs *ast.ValueSpec, gd *ast.GenDecl, genDeclMissingComments map[*ast.GenDecl]bool) {\n-\tkind := \"var\"\n-\tif gd.Tok == token.CONST {\n-\t\tkind = \"const\"\n-\t}\n-\n-\tif len(vs.Names) > 1 {\n-\t\t// Check that none are exported except for the first.\n-\t\tfor _, n := range vs.Names[1:] {\n-\t\t\tif ast.IsExported(n.Name) {\n-\t\t\t\tf.errorf(vs, 1, category(\"comments\"), \"exported %s %s should have its own declaration\", kind, n.Name)\n-\t\t\t\treturn\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t// Only one name.\n-\tname := vs.Names[0].Name\n-\tif !ast.IsExported(name) {\n-\t\treturn\n-\t}\n-\n-\tif vs.Doc == nil && gd.Doc == nil {\n-\t\tif genDeclMissingComments[gd] {\n-\t\t\treturn\n-\t\t}\n-\t\tblock := \"\"\n-\t\tif kind == \"const\" && gd.Lparen.IsValid() {\n-\t\t\tblock = \" (or a comment on this block)\"\n-\t\t}\n-\t\tf.errorf(vs, 1, link(docCommentsLink), category(\"comments\"), \"exported %s %s should have comment%s or be unexported\", kind, name, block)\n-\t\tgenDeclMissingComments[gd] = true\n-\t\treturn\n-\t}\n-\t// If this GenDecl has parens and a comment, we don't check its comment form.\n-\tif gd.Lparen.IsValid() && gd.Doc != nil {\n-\t\treturn\n-\t}\n-\t// The relevant text to check will be on either vs.Doc or gd.Doc.\n-\t// Use vs.Doc preferentially.\n-\tdoc := vs.Doc\n-\tif doc == nil {\n-\t\tdoc = gd.Doc\n-\t}\n-\tprefix := name + \" \"\n-\tif !strings.HasPrefix(doc.Text(), prefix) {\n-\t\tf.errorf(doc, 1, link(docCommentsLink), category(\"comments\"), `comment on exported %s %s should be of the form \"%s...\"`, kind, name, prefix)\n-\t}\n-}\n-\n-func (f *file) checkStutter(id *ast.Ident, thing string) {\n-\tpkg, name := f.f.Name.Name, id.Name\n-\tif !ast.IsExported(name) {\n-\t\t// unexported name\n-\t\treturn\n-\t}\n-\t// A name stutters if the package name is a strict prefix\n-\t// and the next character of the name starts a new word.\n-\tif len(name) <= len(pkg) {\n-\t\t// name is too short to stutter.\n-\t\t// This permits the name to be the same as the package name.\n-\t\treturn\n-\t}\n-\tif !strings.EqualFold(pkg, name[:len(pkg)]) {\n-\t\treturn\n-\t}\n-\t// We can assume the name is well-formed UTF-8.\n-\t// If the next rune after the package name is uppercase or an underscore\n-\t// the it's starting a new word and thus this name stutters.\n-\trem := name[len(pkg):]\n-\tif next, _ := utf8.DecodeRuneInString(rem); next == '_' || unicode.IsUpper(next) {\n-\t\tf.errorf(id, 0.8, link(styleGuideBase+\"#package-names\"), category(\"naming\"), \"%s name will be used as %s.%s by other packages, and that stutters; consider calling this %s\", thing, pkg, name, rem)\n-\t}\n-}\n-\n-// zeroLiteral is a set of ast.BasicLit values that are zero values.\n-// It is not exhaustive.\n-var zeroLiteral = map[string]bool{\n-\t\"false\": true, // bool\n-\t// runes\n-\t`'\\x00'`: true,\n-\t`'\\000'`: true,\n-\t// strings\n-\t`\"\"`: true,\n-\t\"``\": true,\n-\t// numerics\n-\t\"0\":   true,\n-\t\"0.\":  true,\n-\t\"0.0\": true,\n-\t\"0i\":  true,\n-}\n-\n-// lintElses examines else blocks. It complains about any else block whose if block ends in a return.\n-func (f *file) lintElses() {\n-\t// We don't want to flag if { } else if { } else { } constructions.\n-\t// They will appear as an IfStmt whose Else field is also an IfStmt.\n-\t// Record such a node so we ignore it when we visit it.\n-\tignore := make(map[*ast.IfStmt]bool)\n-\n-\tf.walk(func(node ast.Node) bool {\n-\t\tifStmt, ok := node.(*ast.IfStmt)\n-\t\tif !ok || ifStmt.Else == nil {\n-\t\t\treturn true\n-\t\t}\n-\t\tif elseif, ok := ifStmt.Else.(*ast.IfStmt); ok {\n-\t\t\tignore[elseif] = true\n-\t\t\treturn true\n-\t\t}\n-\t\tif ignore[ifStmt] {\n-\t\t\treturn true\n-\t\t}\n-\t\tif _, ok := ifStmt.Else.(*ast.BlockStmt); !ok {\n-\t\t\t// only care about elses without conditions\n-\t\t\treturn true\n-\t\t}\n-\t\tif len(ifStmt.Body.List) == 0 {\n-\t\t\treturn true\n-\t\t}\n-\t\tshortDecl := false // does the if statement have a \":=\" initialization statement?\n-\t\tif ifStmt.Init != nil {\n-\t\t\tif as, ok := ifStmt.Init.(*ast.AssignStmt); ok && as.Tok == token.DEFINE {\n-\t\t\t\tshortDecl = true\n-\t\t\t}\n-\t\t}\n-\t\tlastStmt := ifStmt.Body.List[len(ifStmt.Body.List)-1]\n-\t\tif _, ok := lastStmt.(*ast.ReturnStmt); ok {\n-\t\t\textra := \"\"\n-\t\t\tif shortDecl {\n-\t\t\t\textra = \" (move short variable declaration to its own line if necessary)\"\n-\t\t\t}\n-\t\t\tf.errorf(ifStmt.Else, 1, link(styleGuideBase+\"#indent-error-flow\"), category(\"indent\"), \"if block ends with a return statement, so drop this else and outdent its block\"+extra)\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-// lintRanges examines range clauses. It complains about redundant constructions.\n-func (f *file) lintRanges() {\n-\tf.walk(func(node ast.Node) bool {\n-\t\trs, ok := node.(*ast.RangeStmt)\n-\t\tif !ok {\n-\t\t\treturn true\n-\t\t}\n-\n-\t\tif isIdent(rs.Key, \"_\") && (rs.Value == nil || isIdent(rs.Value, \"_\")) {\n-\t\t\tp := f.errorf(rs.Key, 1, category(\"range-loop\"), \"should omit values from range; this loop is equivalent to `for range ...`\")\n-\n-\t\t\tnewRS := *rs // shallow copy\n-\t\t\tnewRS.Value = nil\n-\t\t\tnewRS.Key = nil\n-\t\t\tp.ReplacementLine = f.firstLineOf(&newRS, rs)\n-\n-\t\t\treturn true\n-\t\t}\n-\n-\t\tif isIdent(rs.Value, \"_\") {\n-\t\t\tp := f.errorf(rs.Value, 1, category(\"range-loop\"), \"should omit 2nd value from range; this loop is equivalent to `for %s %s range ...`\", f.render(rs.Key), rs.Tok)\n-\n-\t\t\tnewRS := *rs // shallow copy\n-\t\t\tnewRS.Value = nil\n-\t\t\tp.ReplacementLine = f.firstLineOf(&newRS, rs)\n-\t\t}\n-\n-\t\treturn true\n-\t})\n-}\n-\n-// lintErrorf examines errors.New and testing.Error calls. It complains if its only argument is an fmt.Sprintf invocation.\n-func (f *file) lintErrorf() {\n-\tf.walk(func(node ast.Node) bool {\n-\t\tce, ok := node.(*ast.CallExpr)\n-\t\tif !ok || len(ce.Args) != 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\tisErrorsNew := isPkgDot(ce.Fun, \"errors\", \"New\")\n-\t\tvar isTestingError bool\n-\t\tse, ok := ce.Fun.(*ast.SelectorExpr)\n-\t\tif ok && se.Sel.Name == \"Error\" {\n-\t\t\tif typ := f.pkg.typeOf(se.X); typ != nil {\n-\t\t\t\tisTestingError = typ.String() == \"*testing.T\"\n-\t\t\t}\n-\t\t}\n-\t\tif !isErrorsNew && !isTestingError {\n-\t\t\treturn true\n-\t\t}\n-\t\tif !f.imports(\"errors\") {\n-\t\t\treturn true\n-\t\t}\n-\t\targ := ce.Args[0]\n-\t\tce, ok = arg.(*ast.CallExpr)\n-\t\tif !ok || !isPkgDot(ce.Fun, \"fmt\", \"Sprintf\") {\n-\t\t\treturn true\n-\t\t}\n-\t\terrorfPrefix := \"fmt\"\n-\t\tif isTestingError {\n-\t\t\terrorfPrefix = f.render(se.X)\n-\t\t}\n-\t\tp := f.errorf(node, 1, category(\"errors\"), \"should replace %s(fmt.Sprintf(...)) with %s.Errorf(...)\", f.render(se), errorfPrefix)\n-\n-\t\tm := f.srcLineWithMatch(ce, `^(.*)`+f.render(se)+`\\(fmt\\.Sprintf\\((.*)\\)\\)(.*)$`)\n-\t\tif m != nil {\n-\t\t\tp.ReplacementLine = m[1] + errorfPrefix + \".Errorf(\" + m[2] + \")\" + m[3]\n-\t\t}\n-\n-\t\treturn true\n-\t})\n-}\n-\n-// lintErrors examines global error vars. It complains if they aren't named in the standard way.\n-func (f *file) lintErrors() {\n-\tfor _, decl := range f.f.Decls {\n-\t\tgd, ok := decl.(*ast.GenDecl)\n-\t\tif !ok || gd.Tok != token.VAR {\n-\t\t\tcontinue\n-\t\t}\n-\t\tfor _, spec := range gd.Specs {\n-\t\t\tspec := spec.(*ast.ValueSpec)\n-\t\t\tif len(spec.Names) != 1 || len(spec.Values) != 1 {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tce, ok := spec.Values[0].(*ast.CallExpr)\n-\t\t\tif !ok {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tif !isPkgDot(ce.Fun, \"errors\", \"New\") && !isPkgDot(ce.Fun, \"fmt\", \"Errorf\") {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\n-\t\t\tid := spec.Names[0]\n-\t\t\tprefix := \"err\"\n-\t\t\tif id.IsExported() {\n-\t\t\t\tprefix = \"Err\"\n-\t\t\t}\n-\t\t\tif !strings.HasPrefix(id.Name, prefix) {\n-\t\t\t\tf.errorf(id, 0.9, category(\"naming\"), \"error var %s should have name of the form %sFoo\", id.Name, prefix)\n-\t\t\t}\n-\t\t}\n-\t}\n-}\n-\n-func lintErrorString(s string) (isClean bool, conf float64) {\n-\tconst basicConfidence = 0.8\n-\tconst capConfidence = basicConfidence - 0.2\n-\tfirst, firstN := utf8.DecodeRuneInString(s)\n-\tlast, _ := utf8.DecodeLastRuneInString(s)\n-\tif last == '.' || last == ':' || last == '!' || last == '\\n' {\n-\t\treturn false, basicConfidence\n-\t}\n-\tif unicode.IsUpper(first) {\n-\t\t// People use proper nouns and exported Go identifiers in error strings,\n-\t\t// so decrease the confidence of warnings for capitalization.\n-\t\tif len(s) <= firstN {\n-\t\t\treturn false, capConfidence\n-\t\t}\n-\t\t// Flag strings starting with something that doesn't look like an initialism.\n-\t\tif second, _ := utf8.DecodeRuneInString(s[firstN:]); !unicode.IsUpper(second) {\n-\t\t\treturn false, capConfidence\n-\t\t}\n-\t}\n-\treturn true, 0\n-}\n-\n-// lintErrorStrings examines error strings.\n-// It complains if they are capitalized or end in punctuation or a newline.\n-func (f *file) lintErrorStrings() {\n-\tf.walk(func(node ast.Node) bool {\n-\t\tce, ok := node.(*ast.CallExpr)\n-\t\tif !ok {\n-\t\t\treturn true\n-\t\t}\n-\t\tif !isPkgDot(ce.Fun, \"errors\", \"New\") && !isPkgDot(ce.Fun, \"fmt\", \"Errorf\") {\n-\t\t\treturn true\n-\t\t}\n-\t\tif len(ce.Args) < 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\tstr, ok := ce.Args[0].(*ast.BasicLit)\n-\t\tif !ok || str.Kind != token.STRING {\n-\t\t\treturn true\n-\t\t}\n-\t\ts, _ := strconv.Unquote(str.Value) // can assume well-formed Go\n-\t\tif s == \"\" {\n-\t\t\treturn true\n-\t\t}\n-\t\tclean, conf := lintErrorString(s)\n-\t\tif clean {\n-\t\t\treturn true\n-\t\t}\n-\n-\t\tf.errorf(str, conf, link(styleGuideBase+\"#error-strings\"), category(\"errors\"),\n-\t\t\t\"error strings should not be capitalized or end with punctuation or a newline\")\n-\t\treturn true\n-\t})\n-}\n-\n-// lintReceiverNames examines receiver names. It complains about inconsistent\n-// names used for the same type and names such as \"this\".\n-func (f *file) lintReceiverNames() {\n-\ttypeReceiver := map[string]string{}\n-\tf.walk(func(n ast.Node) bool {\n-\t\tfn, ok := n.(*ast.FuncDecl)\n-\t\tif !ok || fn.Recv == nil || len(fn.Recv.List) == 0 {\n-\t\t\treturn true\n-\t\t}\n-\t\tnames := fn.Recv.List[0].Names\n-\t\tif len(names) < 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\tname := names[0].Name\n-\t\tconst ref = styleGuideBase + \"#receiver-names\"\n-\t\tif name == \"_\" {\n-\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), `receiver name should not be an underscore, omit the name if it is unused`)\n-\t\t\treturn true\n-\t\t}\n-\t\tif name == \"this\" || name == \"self\" {\n-\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), `receiver name should be a reflection of its identity; don't use generic names such as \"this\" or \"self\"`)\n-\t\t\treturn true\n-\t\t}\n-\t\trecv := receiverType(fn)\n-\t\tif prev, ok := typeReceiver[recv]; ok && prev != name {\n-\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), \"receiver name %s should be consistent with previous receiver name %s for %s\", name, prev, recv)\n-\t\t\treturn true\n-\t\t}\n-\t\ttypeReceiver[recv] = name\n-\t\treturn true\n-\t})\n-}\n-\n-// lintIncDec examines statements that increment or decrement a variable.\n-// It complains if they don't use x++ or x--.\n-func (f *file) lintIncDec() {\n-\tf.walk(func(n ast.Node) bool {\n-\t\tas, ok := n.(*ast.AssignStmt)\n-\t\tif !ok {\n-\t\t\treturn true\n-\t\t}\n-\t\tif len(as.Lhs) != 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\tif !isOne(as.Rhs[0]) {\n-\t\t\treturn true\n-\t\t}\n-\t\tvar suffix string\n-\t\tswitch as.Tok {\n-\t\tcase token.ADD_ASSIGN:\n-\t\t\tsuffix = \"++\"\n-\t\tcase token.SUB_ASSIGN:\n-\t\t\tsuffix = \"--\"\n-\t\tdefault:\n-\t\t\treturn true\n-\t\t}\n-\t\tf.errorf(as, 0.8, category(\"unary-op\"), \"should replace %s with %s%s\", f.render(as), f.render(as.Lhs[0]), suffix)\n-\t\treturn true\n-\t})\n-}\n-\n-// lintErrorReturn examines function declarations that return an error.\n-// It complains if the error isn't the last parameter.\n-func (f *file) lintErrorReturn() {\n-\tf.walk(func(n ast.Node) bool {\n-\t\tfn, ok := n.(*ast.FuncDecl)\n-\t\tif !ok || fn.Type.Results == nil {\n-\t\t\treturn true\n-\t\t}\n-\t\tret := fn.Type.Results.List\n-\t\tif len(ret) <= 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\tif isIdent(ret[len(ret)-1].Type, \"error\") {\n-\t\t\treturn true\n-\t\t}\n-\t\t// An error return parameter should be the last parameter.\n-\t\t// Flag any error parameters found before the last.\n-\t\tfor _, r := range ret[:len(ret)-1] {\n-\t\t\tif isIdent(r.Type, \"error\") {\n-\t\t\t\tf.errorf(fn, 0.9, category(\"arg-order\"), \"error should be the last type when returning multiple items\")\n-\t\t\t\tbreak // only flag one\n-\t\t\t}\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-// lintUnexportedReturn examines exported function declarations.\n-// It complains if any return an unexported type.\n-func (f *file) lintUnexportedReturn() {\n-\tf.walk(func(n ast.Node) bool {\n-\t\tfn, ok := n.(*ast.FuncDecl)\n-\t\tif !ok {\n-\t\t\treturn true\n-\t\t}\n-\t\tif fn.Type.Results == nil {\n-\t\t\treturn false\n-\t\t}\n-\t\tif !fn.Name.IsExported() {\n-\t\t\treturn false\n-\t\t}\n-\t\tthing := \"func\"\n-\t\tif fn.Recv != nil && len(fn.Recv.List) > 0 {\n-\t\t\tthing = \"method\"\n-\t\t\tif !ast.IsExported(receiverType(fn)) {\n-\t\t\t\t// Don't report exported methods of unexported types,\n-\t\t\t\t// such as private implementations of sort.Interface.\n-\t\t\t\treturn false\n-\t\t\t}\n-\t\t}\n-\t\tfor _, ret := range fn.Type.Results.List {\n-\t\t\ttyp := f.pkg.typeOf(ret.Type)\n-\t\t\tif exportedType(typ) {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tf.errorf(ret.Type, 0.8, category(\"unexported-type-in-api\"),\n-\t\t\t\t\"exported %s %s returns unexported type %s, which can be annoying to use\",\n-\t\t\t\tthing, fn.Name.Name, typ)\n-\t\t\tbreak // only flag one\n-\t\t}\n-\t\treturn false\n-\t})\n-}\n-\n-// exportedType reports whether typ is an exported type.\n-// It is imprecise, and will err on the side of returning true,\n-// such as for composite types.\n-func exportedType(typ types.Type) bool {\n-\tswitch T := typ.(type) {\n-\tcase *types.Named:\n-\t\t// Builtin types have no package.\n-\t\treturn T.Obj().Pkg() == nil || T.Obj().Exported()\n-\tcase *types.Map:\n-\t\treturn exportedType(T.Key()) && exportedType(T.Elem())\n-\tcase interface {\n-\t\tElem() types.Type\n-\t}: // array, slice, pointer, chan\n-\t\treturn exportedType(T.Elem())\n-\t}\n-\t// Be conservative about other types, such as struct, interface, etc.\n-\treturn true\n-}\n-\n-// timeSuffixes is a list of name suffixes that imply a time unit.\n-// This is not an exhaustive list.\n-var timeSuffixes = []string{\n-\t\"Sec\", \"Secs\", \"Seconds\",\n-\t\"Msec\", \"Msecs\",\n-\t\"Milli\", \"Millis\", \"Milliseconds\",\n-\t\"Usec\", \"Usecs\", \"Microseconds\",\n-\t\"MS\", \"Ms\",\n-}\n-\n-func (f *file) lintTimeNames() {\n-\tf.walk(func(node ast.Node) bool {\n-\t\tv, ok := node.(*ast.ValueSpec)\n-\t\tif !ok {\n-\t\t\treturn true\n-\t\t}\n-\t\tfor _, name := range v.Names {\n-\t\t\torigTyp := f.pkg.typeOf(name)\n-\t\t\t// Look for time.Duration or *time.Duration;\n-\t\t\t// the latter is common when using flag.Duration.\n-\t\t\ttyp := origTyp\n-\t\t\tif pt, ok := typ.(*types.Pointer); ok {\n-\t\t\t\ttyp = pt.Elem()\n-\t\t\t}\n-\t\t\tif !f.pkg.isNamedType(typ, \"time\", \"Duration\") {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tsuffix := \"\"\n-\t\t\tfor _, suf := range timeSuffixes {\n-\t\t\t\tif strings.HasSuffix(name.Name, suf) {\n-\t\t\t\t\tsuffix = suf\n-\t\t\t\t\tbreak\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif suffix == \"\" {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tf.errorf(v, 0.9, category(\"time\"), \"var %s is of type %v; don't use unit-specific suffix %q\", name.Name, origTyp, suffix)\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-// lintContextKeyTypes checks for call expressions to context.WithValue with\n-// basic types used for the key argument.\n-// See: https://golang.org/issue/17293\n-func (f *file) lintContextKeyTypes() {\n-\tf.walk(func(node ast.Node) bool {\n-\t\tswitch node := node.(type) {\n-\t\tcase *ast.CallExpr:\n-\t\t\tf.checkContextKeyType(node)\n-\t\t}\n-\n-\t\treturn true\n-\t})\n-}\n-\n-// checkContextKeyType reports an error if the call expression calls\n-// context.WithValue with a key argument of basic type.\n-func (f *file) checkContextKeyType(x *ast.CallExpr) {\n-\tsel, ok := x.Fun.(*ast.SelectorExpr)\n-\tif !ok {\n-\t\treturn\n-\t}\n-\tpkg, ok := sel.X.(*ast.Ident)\n-\tif !ok || pkg.Name != \"context\" {\n-\t\treturn\n-\t}\n-\tif sel.Sel.Name != \"WithValue\" {\n-\t\treturn\n-\t}\n-\n-\t// key is second argument to context.WithValue\n-\tif len(x.Args) != 3 {\n-\t\treturn\n-\t}\n-\tkey := f.pkg.typesInfo.Types[x.Args[1]]\n-\n-\tif ktyp, ok := key.Type.(*types.Basic); ok && ktyp.Kind() != types.Invalid {\n-\t\tf.errorf(x, 1.0, category(\"context\"), fmt.Sprintf(\"should not use basic type %s as key in context.WithValue\", key.Type))\n-\t}\n-}\n-\n-// lintContextArgs examines function declarations that contain an\n-// argument with a type of context.Context\n-// It complains if that argument isn't the first parameter.\n-func (f *file) lintContextArgs() {\n-\tf.walk(func(n ast.Node) bool {\n-\t\tfn, ok := n.(*ast.FuncDecl)\n-\t\tif !ok || len(fn.Type.Params.List) <= 1 {\n-\t\t\treturn true\n-\t\t}\n-\t\t// A context.Context should be the first parameter of a function.\n-\t\t// Flag any that show up after the first.\n-\t\tfor _, arg := range fn.Type.Params.List[1:] {\n-\t\t\tif isPkgDot(arg.Type, \"context\", \"Context\") {\n-\t\t\t\tf.errorf(fn, 0.9, link(\"https://golang.org/pkg/context/\"), category(\"arg-order\"), \"context.Context should be the first parameter of a function\")\n-\t\t\t\tbreak // only flag one\n-\t\t\t}\n-\t\t}\n-\t\treturn true\n-\t})\n-}\n-\n-// containsComments returns whether the interval [start, end) contains any\n-// comments without \"// MATCH \" prefix.\n-func (f *file) containsComments(start, end token.Pos) bool {\n-\tfor _, cgroup := range f.f.Comments {\n-\t\tcomments := cgroup.List\n-\t\tif comments[0].Slash >= end {\n-\t\t\t// All comments starting with this group are after end pos.\n-\t\t\treturn false\n-\t\t}\n-\t\tif comments[len(comments)-1].Slash < start {\n-\t\t\t// Comments group ends before start pos.\n-\t\t\tcontinue\n-\t\t}\n-\t\tfor _, c := range comments {\n-\t\t\tif start <= c.Slash && c.Slash < end && !strings.HasPrefix(c.Text, \"// MATCH \") {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// receiverType returns the named type of the method receiver, sans \"*\",\n-// or \"invalid-type\" if fn.Recv is ill formed.\n-func receiverType(fn *ast.FuncDecl) string {\n-\tswitch e := fn.Recv.List[0].Type.(type) {\n-\tcase *ast.Ident:\n-\t\treturn e.Name\n-\tcase *ast.StarExpr:\n-\t\tif id, ok := e.X.(*ast.Ident); ok {\n-\t\t\treturn id.Name\n-\t\t}\n-\t}\n-\t// The parser accepts much more than just the legal forms.\n-\treturn \"invalid-type\"\n-}\n-\n-func (f *file) walk(fn func(ast.Node) bool) {\n-\tast.Walk(walker(fn), f.f)\n-}\n-\n-func (f *file) render(x interface{}) string {\n-\tvar buf bytes.Buffer\n-\tif err := printer.Fprint(&buf, f.fset, x); err != nil {\n-\t\tpanic(err)\n-\t}\n-\treturn buf.String()\n-}\n-\n-func (f *file) debugRender(x interface{}) string {\n-\tvar buf bytes.Buffer\n-\tif err := ast.Fprint(&buf, f.fset, x, nil); err != nil {\n-\t\tpanic(err)\n-\t}\n-\treturn buf.String()\n-}\n-\n-// walker adapts a function to satisfy the ast.Visitor interface.\n-// The function return whether the walk should proceed into the node's children.\n-type walker func(ast.Node) bool\n-\n-func (w walker) Visit(node ast.Node) ast.Visitor {\n-\tif w(node) {\n-\t\treturn w\n-\t}\n-\treturn nil\n-}\n-\n-func isIdent(expr ast.Expr, ident string) bool {\n-\tid, ok := expr.(*ast.Ident)\n-\treturn ok && id.Name == ident\n-}\n-\n-// isBlank returns whether id is the blank identifier \"_\".\n-// If id == nil, the answer is false.\n-func isBlank(id *ast.Ident) bool { return id != nil && id.Name == \"_\" }\n-\n-func isPkgDot(expr ast.Expr, pkg, name string) bool {\n-\tsel, ok := expr.(*ast.SelectorExpr)\n-\treturn ok && isIdent(sel.X, pkg) && isIdent(sel.Sel, name)\n-}\n-\n-func isOne(expr ast.Expr) bool {\n-\tlit, ok := expr.(*ast.BasicLit)\n-\treturn ok && lit.Kind == token.INT && lit.Value == \"1\"\n-}\n-\n-func isCgoExported(f *ast.FuncDecl) bool {\n-\tif f.Recv != nil || f.Doc == nil {\n-\t\treturn false\n-\t}\n-\n-\tcgoExport := regexp.MustCompile(fmt.Sprintf(\"(?m)^//export %s$\", regexp.QuoteMeta(f.Name.Name)))\n-\tfor _, c := range f.Doc.List {\n-\t\tif cgoExport.MatchString(c.Text) {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-var basicTypeKinds = map[types.BasicKind]string{\n-\ttypes.UntypedBool:    \"bool\",\n-\ttypes.UntypedInt:     \"int\",\n-\ttypes.UntypedRune:    \"rune\",\n-\ttypes.UntypedFloat:   \"float64\",\n-\ttypes.UntypedComplex: \"complex128\",\n-\ttypes.UntypedString:  \"string\",\n-}\n-\n-// isUntypedConst reports whether expr is an untyped constant,\n-// and indicates what its default type is.\n-// scope may be nil.\n-func (f *file) isUntypedConst(expr ast.Expr) (defType string, ok bool) {\n-\t// Re-evaluate expr outside of its context to see if it's untyped.\n-\t// (An expr evaluated within, for example, an assignment context will get the type of the LHS.)\n-\texprStr := f.render(expr)\n-\ttv, err := types.Eval(f.fset, f.pkg.typesPkg, expr.Pos(), exprStr)\n-\tif err != nil {\n-\t\treturn \"\", false\n-\t}\n-\tif b, ok := tv.Type.(*types.Basic); ok {\n-\t\tif dt, ok := basicTypeKinds[b.Kind()]; ok {\n-\t\t\treturn dt, true\n-\t\t}\n-\t}\n-\n-\treturn \"\", false\n-}\n-\n-// firstLineOf renders the given node and returns its first line.\n-// It will also match the indentation of another node.\n-func (f *file) firstLineOf(node, match ast.Node) string {\n-\tline := f.render(node)\n-\tif i := strings.Index(line, \"\\n\"); i >= 0 {\n-\t\tline = line[:i]\n-\t}\n-\treturn f.indentOf(match) + line\n-}\n-\n-func (f *file) indentOf(node ast.Node) string {\n-\tline := srcLine(f.src, f.fset.Position(node.Pos()))\n-\tfor i, r := range line {\n-\t\tswitch r {\n-\t\tcase ' ', '\\t':\n-\t\tdefault:\n-\t\t\treturn line[:i]\n-\t\t}\n-\t}\n-\treturn line // unusual or empty line\n-}\n-\n-func (f *file) srcLineWithMatch(node ast.Node, pattern string) (m []string) {\n-\tline := srcLine(f.src, f.fset.Position(node.Pos()))\n-\tline = strings.TrimSuffix(line, \"\\n\")\n-\trx := regexp.MustCompile(pattern)\n-\treturn rx.FindStringSubmatch(line)\n-}\n-\n-// imports returns true if the current file imports the specified package path.\n-func (f *file) imports(importPath string) bool {\n-\tall := astutil.Imports(f.fset, f.f)\n-\tfor _, p := range all {\n-\t\tfor _, i := range p {\n-\t\t\tuq, err := strconv.Unquote(i.Path.Value)\n-\t\t\tif err == nil && importPath == uq {\n-\t\t\t\treturn true\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// srcLine returns the complete line at p, including the terminating newline.\n-func srcLine(src []byte, p token.Position) string {\n-\t// Run to end of line in both directions if not at line start/end.\n-\tlo, hi := p.Offset, p.Offset+1\n-\tfor lo > 0 && src[lo-1] != '\\n' {\n-\t\tlo--\n-\t}\n-\tfor hi < len(src) && src[hi-1] != '\\n' {\n-\t\thi++\n-\t}\n-\treturn string(src[lo:hi])\n-}"
    },
    {
      "sha": "15167cd746c560e5b3d3b233a169aa64d3e9101e",
      "filename": "backend/vendor/golang.org/x/tools/AUTHORS",
      "status": "removed",
      "additions": 0,
      "deletions": 3,
      "changes": 3,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/AUTHORS",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/AUTHORS",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/AUTHORS?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,3 +0,0 @@\n-# This source code refers to The Go Authors for copyright purposes.\n-# The master list of authors is in the main Go distribution,\n-# visible at http://tip.golang.org/AUTHORS."
    },
    {
      "sha": "1c4577e9680611383f46044d17fa343a96997c3c",
      "filename": "backend/vendor/golang.org/x/tools/CONTRIBUTORS",
      "status": "removed",
      "additions": 0,
      "deletions": 3,
      "changes": 3,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/CONTRIBUTORS",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/CONTRIBUTORS",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/CONTRIBUTORS?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,3 +0,0 @@\n-# This source code was written by the Go contributors.\n-# The master list of contributors is in the main Go distribution,\n-# visible at http://tip.golang.org/CONTRIBUTORS."
    },
    {
      "sha": "6a66aea5eafe0ca6a688840c47219556c552488e",
      "filename": "backend/vendor/golang.org/x/tools/LICENSE",
      "status": "removed",
      "additions": 0,
      "deletions": 27,
      "changes": 27,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/LICENSE",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/LICENSE",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/LICENSE?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,27 +0,0 @@\n-Copyright (c) 2009 The Go Authors. All rights reserved.\n-\n-Redistribution and use in source and binary forms, with or without\n-modification, are permitted provided that the following conditions are\n-met:\n-\n-   * Redistributions of source code must retain the above copyright\n-notice, this list of conditions and the following disclaimer.\n-   * Redistributions in binary form must reproduce the above\n-copyright notice, this list of conditions and the following disclaimer\n-in the documentation and/or other materials provided with the\n-distribution.\n-   * Neither the name of Google Inc. nor the names of its\n-contributors may be used to endorse or promote products derived from\n-this software without specific prior written permission.\n-\n-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n-\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
    },
    {
      "sha": "733099041f84fa1e58611ab2e11af51c1f26d1d2",
      "filename": "backend/vendor/golang.org/x/tools/PATENTS",
      "status": "removed",
      "additions": 0,
      "deletions": 22,
      "changes": 22,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/PATENTS",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/PATENTS",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/PATENTS?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,22 +0,0 @@\n-Additional IP Rights Grant (Patents)\n-\n-\"This implementation\" means the copyrightable works distributed by\n-Google as part of the Go project.\n-\n-Google hereby grants to You a perpetual, worldwide, non-exclusive,\n-no-charge, royalty-free, irrevocable (except as stated in this section)\n-patent license to make, have made, use, offer to sell, sell, import,\n-transfer and otherwise run, modify and propagate the contents of this\n-implementation of Go, where such license applies only to those patent\n-claims, both currently owned or controlled by Google and acquired in\n-the future, licensable by Google that are necessarily infringed by this\n-implementation of Go.  This grant does not include claims that would be\n-infringed only as a consequence of further modification of this\n-implementation.  If you or your agent or exclusive licensee institute or\n-order or agree to the institution of patent litigation against any\n-entity (including a cross-claim or counterclaim in a lawsuit) alleging\n-that this implementation of Go or any code incorporated within this\n-implementation of Go constitutes direct or contributory patent\n-infringement, or inducement of patent infringement, then any patent\n-rights granted to you under this License for this implementation of Go\n-shall terminate as of the date such litigation is filed."
    },
    {
      "sha": "6b7052b892ca07ba23a1eddd35645d50992dc42c",
      "filename": "backend/vendor/golang.org/x/tools/go/ast/astutil/enclosing.go",
      "status": "removed",
      "additions": 0,
      "deletions": 627,
      "changes": 627,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/enclosing.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/enclosing.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/ast/astutil/enclosing.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,627 +0,0 @@\n-// Copyright 2013 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-package astutil\n-\n-// This file defines utilities for working with source positions.\n-\n-import (\n-\t\"fmt\"\n-\t\"go/ast\"\n-\t\"go/token\"\n-\t\"sort\"\n-)\n-\n-// PathEnclosingInterval returns the node that encloses the source\n-// interval [start, end), and all its ancestors up to the AST root.\n-//\n-// The definition of \"enclosing\" used by this function considers\n-// additional whitespace abutting a node to be enclosed by it.\n-// In this example:\n-//\n-//              z := x + y // add them\n-//                   <-A->\n-//                  <----B----->\n-//\n-// the ast.BinaryExpr(+) node is considered to enclose interval B\n-// even though its [Pos()..End()) is actually only interval A.\n-// This behaviour makes user interfaces more tolerant of imperfect\n-// input.\n-//\n-// This function treats tokens as nodes, though they are not included\n-// in the result. e.g. PathEnclosingInterval(\"+\") returns the\n-// enclosing ast.BinaryExpr(\"x + y\").\n-//\n-// If start==end, the 1-char interval following start is used instead.\n-//\n-// The 'exact' result is true if the interval contains only path[0]\n-// and perhaps some adjacent whitespace.  It is false if the interval\n-// overlaps multiple children of path[0], or if it contains only\n-// interior whitespace of path[0].\n-// In this example:\n-//\n-//              z := x + y // add them\n-//                <--C-->     <---E-->\n-//                  ^\n-//                  D\n-//\n-// intervals C, D and E are inexact.  C is contained by the\n-// z-assignment statement, because it spans three of its children (:=,\n-// x, +).  So too is the 1-char interval D, because it contains only\n-// interior whitespace of the assignment.  E is considered interior\n-// whitespace of the BlockStmt containing the assignment.\n-//\n-// Precondition: [start, end) both lie within the same file as root.\n-// TODO(adonovan): return (nil, false) in this case and remove precond.\n-// Requires FileSet; see loader.tokenFileContainsPos.\n-//\n-// Postcondition: path is never nil; it always contains at least 'root'.\n-//\n-func PathEnclosingInterval(root *ast.File, start, end token.Pos) (path []ast.Node, exact bool) {\n-\t// fmt.Printf(\"EnclosingInterval %d %d\\n\", start, end) // debugging\n-\n-\t// Precondition: node.[Pos..End) and adjoining whitespace contain [start, end).\n-\tvar visit func(node ast.Node) bool\n-\tvisit = func(node ast.Node) bool {\n-\t\tpath = append(path, node)\n-\n-\t\tnodePos := node.Pos()\n-\t\tnodeEnd := node.End()\n-\n-\t\t// fmt.Printf(\"visit(%T, %d, %d)\\n\", node, nodePos, nodeEnd) // debugging\n-\n-\t\t// Intersect [start, end) with interval of node.\n-\t\tif start < nodePos {\n-\t\t\tstart = nodePos\n-\t\t}\n-\t\tif end > nodeEnd {\n-\t\t\tend = nodeEnd\n-\t\t}\n-\n-\t\t// Find sole child that contains [start, end).\n-\t\tchildren := childrenOf(node)\n-\t\tl := len(children)\n-\t\tfor i, child := range children {\n-\t\t\t// [childPos, childEnd) is unaugmented interval of child.\n-\t\t\tchildPos := child.Pos()\n-\t\t\tchildEnd := child.End()\n-\n-\t\t\t// [augPos, augEnd) is whitespace-augmented interval of child.\n-\t\t\taugPos := childPos\n-\t\t\taugEnd := childEnd\n-\t\t\tif i > 0 {\n-\t\t\t\taugPos = children[i-1].End() // start of preceding whitespace\n-\t\t\t}\n-\t\t\tif i < l-1 {\n-\t\t\t\tnextChildPos := children[i+1].Pos()\n-\t\t\t\t// Does [start, end) lie between child and next child?\n-\t\t\t\tif start >= augEnd && end <= nextChildPos {\n-\t\t\t\t\treturn false // inexact match\n-\t\t\t\t}\n-\t\t\t\taugEnd = nextChildPos // end of following whitespace\n-\t\t\t}\n-\n-\t\t\t// fmt.Printf(\"\\tchild %d: [%d..%d)\\tcontains interval [%d..%d)?\\n\",\n-\t\t\t// \ti, augPos, augEnd, start, end) // debugging\n-\n-\t\t\t// Does augmented child strictly contain [start, end)?\n-\t\t\tif augPos <= start && end <= augEnd {\n-\t\t\t\t_, isToken := child.(tokenNode)\n-\t\t\t\treturn isToken || visit(child)\n-\t\t\t}\n-\n-\t\t\t// Does [start, end) overlap multiple children?\n-\t\t\t// i.e. left-augmented child contains start\n-\t\t\t// but LR-augmented child does not contain end.\n-\t\t\tif start < childEnd && end > augEnd {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t}\n-\n-\t\t// No single child contained [start, end),\n-\t\t// so node is the result.  Is it exact?\n-\n-\t\t// (It's tempting to put this condition before the\n-\t\t// child loop, but it gives the wrong result in the\n-\t\t// case where a node (e.g. ExprStmt) and its sole\n-\t\t// child have equal intervals.)\n-\t\tif start == nodePos && end == nodeEnd {\n-\t\t\treturn true // exact match\n-\t\t}\n-\n-\t\treturn false // inexact: overlaps multiple children\n-\t}\n-\n-\tif start > end {\n-\t\tstart, end = end, start\n-\t}\n-\n-\tif start < root.End() && end > root.Pos() {\n-\t\tif start == end {\n-\t\t\tend = start + 1 // empty interval => interval of size 1\n-\t\t}\n-\t\texact = visit(root)\n-\n-\t\t// Reverse the path:\n-\t\tfor i, l := 0, len(path); i < l/2; i++ {\n-\t\t\tpath[i], path[l-1-i] = path[l-1-i], path[i]\n-\t\t}\n-\t} else {\n-\t\t// Selection lies within whitespace preceding the\n-\t\t// first (or following the last) declaration in the file.\n-\t\t// The result nonetheless always includes the ast.File.\n-\t\tpath = append(path, root)\n-\t}\n-\n-\treturn\n-}\n-\n-// tokenNode is a dummy implementation of ast.Node for a single token.\n-// They are used transiently by PathEnclosingInterval but never escape\n-// this package.\n-//\n-type tokenNode struct {\n-\tpos token.Pos\n-\tend token.Pos\n-}\n-\n-func (n tokenNode) Pos() token.Pos {\n-\treturn n.pos\n-}\n-\n-func (n tokenNode) End() token.Pos {\n-\treturn n.end\n-}\n-\n-func tok(pos token.Pos, len int) ast.Node {\n-\treturn tokenNode{pos, pos + token.Pos(len)}\n-}\n-\n-// childrenOf returns the direct non-nil children of ast.Node n.\n-// It may include fake ast.Node implementations for bare tokens.\n-// it is not safe to call (e.g.) ast.Walk on such nodes.\n-//\n-func childrenOf(n ast.Node) []ast.Node {\n-\tvar children []ast.Node\n-\n-\t// First add nodes for all true subtrees.\n-\tast.Inspect(n, func(node ast.Node) bool {\n-\t\tif node == n { // push n\n-\t\t\treturn true // recur\n-\t\t}\n-\t\tif node != nil { // push child\n-\t\t\tchildren = append(children, node)\n-\t\t}\n-\t\treturn false // no recursion\n-\t})\n-\n-\t// Then add fake Nodes for bare tokens.\n-\tswitch n := n.(type) {\n-\tcase *ast.ArrayType:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lbrack, len(\"[\")),\n-\t\t\ttok(n.Elt.End(), len(\"]\")))\n-\n-\tcase *ast.AssignStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.TokPos, len(n.Tok.String())))\n-\n-\tcase *ast.BasicLit:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.ValuePos, len(n.Value)))\n-\n-\tcase *ast.BinaryExpr:\n-\t\tchildren = append(children, tok(n.OpPos, len(n.Op.String())))\n-\n-\tcase *ast.BlockStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lbrace, len(\"{\")),\n-\t\t\ttok(n.Rbrace, len(\"}\")))\n-\n-\tcase *ast.BranchStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.TokPos, len(n.Tok.String())))\n-\n-\tcase *ast.CallExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lparen, len(\"(\")),\n-\t\t\ttok(n.Rparen, len(\")\")))\n-\t\tif n.Ellipsis != 0 {\n-\t\t\tchildren = append(children, tok(n.Ellipsis, len(\"...\")))\n-\t\t}\n-\n-\tcase *ast.CaseClause:\n-\t\tif n.List == nil {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Case, len(\"default\")))\n-\t\t} else {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Case, len(\"case\")))\n-\t\t}\n-\t\tchildren = append(children, tok(n.Colon, len(\":\")))\n-\n-\tcase *ast.ChanType:\n-\t\tswitch n.Dir {\n-\t\tcase ast.RECV:\n-\t\t\tchildren = append(children, tok(n.Begin, len(\"<-chan\")))\n-\t\tcase ast.SEND:\n-\t\t\tchildren = append(children, tok(n.Begin, len(\"chan<-\")))\n-\t\tcase ast.RECV | ast.SEND:\n-\t\t\tchildren = append(children, tok(n.Begin, len(\"chan\")))\n-\t\t}\n-\n-\tcase *ast.CommClause:\n-\t\tif n.Comm == nil {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Case, len(\"default\")))\n-\t\t} else {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Case, len(\"case\")))\n-\t\t}\n-\t\tchildren = append(children, tok(n.Colon, len(\":\")))\n-\n-\tcase *ast.Comment:\n-\t\t// nop\n-\n-\tcase *ast.CommentGroup:\n-\t\t// nop\n-\n-\tcase *ast.CompositeLit:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lbrace, len(\"{\")),\n-\t\t\ttok(n.Rbrace, len(\"{\")))\n-\n-\tcase *ast.DeclStmt:\n-\t\t// nop\n-\n-\tcase *ast.DeferStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Defer, len(\"defer\")))\n-\n-\tcase *ast.Ellipsis:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Ellipsis, len(\"...\")))\n-\n-\tcase *ast.EmptyStmt:\n-\t\t// nop\n-\n-\tcase *ast.ExprStmt:\n-\t\t// nop\n-\n-\tcase *ast.Field:\n-\t\t// TODO(adonovan): Field.{Doc,Comment,Tag}?\n-\n-\tcase *ast.FieldList:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Opening, len(\"(\")),\n-\t\t\ttok(n.Closing, len(\")\")))\n-\n-\tcase *ast.File:\n-\t\t// TODO test: Doc\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Package, len(\"package\")))\n-\n-\tcase *ast.ForStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.For, len(\"for\")))\n-\n-\tcase *ast.FuncDecl:\n-\t\t// TODO(adonovan): FuncDecl.Comment?\n-\n-\t\t// Uniquely, FuncDecl breaks the invariant that\n-\t\t// preorder traversal yields tokens in lexical order:\n-\t\t// in fact, FuncDecl.Recv precedes FuncDecl.Type.Func.\n-\t\t//\n-\t\t// As a workaround, we inline the case for FuncType\n-\t\t// here and order things correctly.\n-\t\t//\n-\t\tchildren = nil // discard ast.Walk(FuncDecl) info subtrees\n-\t\tchildren = append(children, tok(n.Type.Func, len(\"func\")))\n-\t\tif n.Recv != nil {\n-\t\t\tchildren = append(children, n.Recv)\n-\t\t}\n-\t\tchildren = append(children, n.Name)\n-\t\tif n.Type.Params != nil {\n-\t\t\tchildren = append(children, n.Type.Params)\n-\t\t}\n-\t\tif n.Type.Results != nil {\n-\t\t\tchildren = append(children, n.Type.Results)\n-\t\t}\n-\t\tif n.Body != nil {\n-\t\t\tchildren = append(children, n.Body)\n-\t\t}\n-\n-\tcase *ast.FuncLit:\n-\t\t// nop\n-\n-\tcase *ast.FuncType:\n-\t\tif n.Func != 0 {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Func, len(\"func\")))\n-\t\t}\n-\n-\tcase *ast.GenDecl:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.TokPos, len(n.Tok.String())))\n-\t\tif n.Lparen != 0 {\n-\t\t\tchildren = append(children,\n-\t\t\t\ttok(n.Lparen, len(\"(\")),\n-\t\t\t\ttok(n.Rparen, len(\")\")))\n-\t\t}\n-\n-\tcase *ast.GoStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Go, len(\"go\")))\n-\n-\tcase *ast.Ident:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.NamePos, len(n.Name)))\n-\n-\tcase *ast.IfStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.If, len(\"if\")))\n-\n-\tcase *ast.ImportSpec:\n-\t\t// TODO(adonovan): ImportSpec.{Doc,EndPos}?\n-\n-\tcase *ast.IncDecStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.TokPos, len(n.Tok.String())))\n-\n-\tcase *ast.IndexExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lbrack, len(\"{\")),\n-\t\t\ttok(n.Rbrack, len(\"}\")))\n-\n-\tcase *ast.InterfaceType:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Interface, len(\"interface\")))\n-\n-\tcase *ast.KeyValueExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Colon, len(\":\")))\n-\n-\tcase *ast.LabeledStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Colon, len(\":\")))\n-\n-\tcase *ast.MapType:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Map, len(\"map\")))\n-\n-\tcase *ast.ParenExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lparen, len(\"(\")),\n-\t\t\ttok(n.Rparen, len(\")\")))\n-\n-\tcase *ast.RangeStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.For, len(\"for\")),\n-\t\t\ttok(n.TokPos, len(n.Tok.String())))\n-\n-\tcase *ast.ReturnStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Return, len(\"return\")))\n-\n-\tcase *ast.SelectStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Select, len(\"select\")))\n-\n-\tcase *ast.SelectorExpr:\n-\t\t// nop\n-\n-\tcase *ast.SendStmt:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Arrow, len(\"<-\")))\n-\n-\tcase *ast.SliceExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lbrack, len(\"[\")),\n-\t\t\ttok(n.Rbrack, len(\"]\")))\n-\n-\tcase *ast.StarExpr:\n-\t\tchildren = append(children, tok(n.Star, len(\"*\")))\n-\n-\tcase *ast.StructType:\n-\t\tchildren = append(children, tok(n.Struct, len(\"struct\")))\n-\n-\tcase *ast.SwitchStmt:\n-\t\tchildren = append(children, tok(n.Switch, len(\"switch\")))\n-\n-\tcase *ast.TypeAssertExpr:\n-\t\tchildren = append(children,\n-\t\t\ttok(n.Lparen-1, len(\".\")),\n-\t\t\ttok(n.Lparen, len(\"(\")),\n-\t\t\ttok(n.Rparen, len(\")\")))\n-\n-\tcase *ast.TypeSpec:\n-\t\t// TODO(adonovan): TypeSpec.{Doc,Comment}?\n-\n-\tcase *ast.TypeSwitchStmt:\n-\t\tchildren = append(children, tok(n.Switch, len(\"switch\")))\n-\n-\tcase *ast.UnaryExpr:\n-\t\tchildren = append(children, tok(n.OpPos, len(n.Op.String())))\n-\n-\tcase *ast.ValueSpec:\n-\t\t// TODO(adonovan): ValueSpec.{Doc,Comment}?\n-\n-\tcase *ast.BadDecl, *ast.BadExpr, *ast.BadStmt:\n-\t\t// nop\n-\t}\n-\n-\t// TODO(adonovan): opt: merge the logic of ast.Inspect() into\n-\t// the switch above so we can make interleaved callbacks for\n-\t// both Nodes and Tokens in the right order and avoid the need\n-\t// to sort.\n-\tsort.Sort(byPos(children))\n-\n-\treturn children\n-}\n-\n-type byPos []ast.Node\n-\n-func (sl byPos) Len() int {\n-\treturn len(sl)\n-}\n-func (sl byPos) Less(i, j int) bool {\n-\treturn sl[i].Pos() < sl[j].Pos()\n-}\n-func (sl byPos) Swap(i, j int) {\n-\tsl[i], sl[j] = sl[j], sl[i]\n-}\n-\n-// NodeDescription returns a description of the concrete type of n suitable\n-// for a user interface.\n-//\n-// TODO(adonovan): in some cases (e.g. Field, FieldList, Ident,\n-// StarExpr) we could be much more specific given the path to the AST\n-// root.  Perhaps we should do that.\n-//\n-func NodeDescription(n ast.Node) string {\n-\tswitch n := n.(type) {\n-\tcase *ast.ArrayType:\n-\t\treturn \"array type\"\n-\tcase *ast.AssignStmt:\n-\t\treturn \"assignment\"\n-\tcase *ast.BadDecl:\n-\t\treturn \"bad declaration\"\n-\tcase *ast.BadExpr:\n-\t\treturn \"bad expression\"\n-\tcase *ast.BadStmt:\n-\t\treturn \"bad statement\"\n-\tcase *ast.BasicLit:\n-\t\treturn \"basic literal\"\n-\tcase *ast.BinaryExpr:\n-\t\treturn fmt.Sprintf(\"binary %s operation\", n.Op)\n-\tcase *ast.BlockStmt:\n-\t\treturn \"block\"\n-\tcase *ast.BranchStmt:\n-\t\tswitch n.Tok {\n-\t\tcase token.BREAK:\n-\t\t\treturn \"break statement\"\n-\t\tcase token.CONTINUE:\n-\t\t\treturn \"continue statement\"\n-\t\tcase token.GOTO:\n-\t\t\treturn \"goto statement\"\n-\t\tcase token.FALLTHROUGH:\n-\t\t\treturn \"fall-through statement\"\n-\t\t}\n-\tcase *ast.CallExpr:\n-\t\tif len(n.Args) == 1 && !n.Ellipsis.IsValid() {\n-\t\t\treturn \"function call (or conversion)\"\n-\t\t}\n-\t\treturn \"function call\"\n-\tcase *ast.CaseClause:\n-\t\treturn \"case clause\"\n-\tcase *ast.ChanType:\n-\t\treturn \"channel type\"\n-\tcase *ast.CommClause:\n-\t\treturn \"communication clause\"\n-\tcase *ast.Comment:\n-\t\treturn \"comment\"\n-\tcase *ast.CommentGroup:\n-\t\treturn \"comment group\"\n-\tcase *ast.CompositeLit:\n-\t\treturn \"composite literal\"\n-\tcase *ast.DeclStmt:\n-\t\treturn NodeDescription(n.Decl) + \" statement\"\n-\tcase *ast.DeferStmt:\n-\t\treturn \"defer statement\"\n-\tcase *ast.Ellipsis:\n-\t\treturn \"ellipsis\"\n-\tcase *ast.EmptyStmt:\n-\t\treturn \"empty statement\"\n-\tcase *ast.ExprStmt:\n-\t\treturn \"expression statement\"\n-\tcase *ast.Field:\n-\t\t// Can be any of these:\n-\t\t// struct {x, y int}  -- struct field(s)\n-\t\t// struct {T}         -- anon struct field\n-\t\t// interface {I}      -- interface embedding\n-\t\t// interface {f()}    -- interface method\n-\t\t// func (A) func(B) C -- receiver, param(s), result(s)\n-\t\treturn \"field/method/parameter\"\n-\tcase *ast.FieldList:\n-\t\treturn \"field/method/parameter list\"\n-\tcase *ast.File:\n-\t\treturn \"source file\"\n-\tcase *ast.ForStmt:\n-\t\treturn \"for loop\"\n-\tcase *ast.FuncDecl:\n-\t\treturn \"function declaration\"\n-\tcase *ast.FuncLit:\n-\t\treturn \"function literal\"\n-\tcase *ast.FuncType:\n-\t\treturn \"function type\"\n-\tcase *ast.GenDecl:\n-\t\tswitch n.Tok {\n-\t\tcase token.IMPORT:\n-\t\t\treturn \"import declaration\"\n-\t\tcase token.CONST:\n-\t\t\treturn \"constant declaration\"\n-\t\tcase token.TYPE:\n-\t\t\treturn \"type declaration\"\n-\t\tcase token.VAR:\n-\t\t\treturn \"variable declaration\"\n-\t\t}\n-\tcase *ast.GoStmt:\n-\t\treturn \"go statement\"\n-\tcase *ast.Ident:\n-\t\treturn \"identifier\"\n-\tcase *ast.IfStmt:\n-\t\treturn \"if statement\"\n-\tcase *ast.ImportSpec:\n-\t\treturn \"import specification\"\n-\tcase *ast.IncDecStmt:\n-\t\tif n.Tok == token.INC {\n-\t\t\treturn \"increment statement\"\n-\t\t}\n-\t\treturn \"decrement statement\"\n-\tcase *ast.IndexExpr:\n-\t\treturn \"index expression\"\n-\tcase *ast.InterfaceType:\n-\t\treturn \"interface type\"\n-\tcase *ast.KeyValueExpr:\n-\t\treturn \"key/value association\"\n-\tcase *ast.LabeledStmt:\n-\t\treturn \"statement label\"\n-\tcase *ast.MapType:\n-\t\treturn \"map type\"\n-\tcase *ast.Package:\n-\t\treturn \"package\"\n-\tcase *ast.ParenExpr:\n-\t\treturn \"parenthesized \" + NodeDescription(n.X)\n-\tcase *ast.RangeStmt:\n-\t\treturn \"range loop\"\n-\tcase *ast.ReturnStmt:\n-\t\treturn \"return statement\"\n-\tcase *ast.SelectStmt:\n-\t\treturn \"select statement\"\n-\tcase *ast.SelectorExpr:\n-\t\treturn \"selector\"\n-\tcase *ast.SendStmt:\n-\t\treturn \"channel send\"\n-\tcase *ast.SliceExpr:\n-\t\treturn \"slice expression\"\n-\tcase *ast.StarExpr:\n-\t\treturn \"*-operation\" // load/store expr or pointer type\n-\tcase *ast.StructType:\n-\t\treturn \"struct type\"\n-\tcase *ast.SwitchStmt:\n-\t\treturn \"switch statement\"\n-\tcase *ast.TypeAssertExpr:\n-\t\treturn \"type assertion\"\n-\tcase *ast.TypeSpec:\n-\t\treturn \"type specification\"\n-\tcase *ast.TypeSwitchStmt:\n-\t\treturn \"type switch\"\n-\tcase *ast.UnaryExpr:\n-\t\treturn fmt.Sprintf(\"unary %s operation\", n.Op)\n-\tcase *ast.ValueSpec:\n-\t\treturn \"value specification\"\n-\n-\t}\n-\tpanic(fmt.Sprintf(\"unexpected node type: %T\", n))\n-}"
    },
    {
      "sha": "2087ceec9cfd6c0e2a9b2d8b8ca669d9a9d54635",
      "filename": "backend/vendor/golang.org/x/tools/go/ast/astutil/imports.go",
      "status": "removed",
      "additions": 0,
      "deletions": 482,
      "changes": 482,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/imports.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/imports.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/ast/astutil/imports.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,482 +0,0 @@\n-// Copyright 2013 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Package astutil contains common utilities for working with the Go AST.\n-package astutil // import \"golang.org/x/tools/go/ast/astutil\"\n-\n-import (\n-\t\"fmt\"\n-\t\"go/ast\"\n-\t\"go/token\"\n-\t\"strconv\"\n-\t\"strings\"\n-)\n-\n-// AddImport adds the import path to the file f, if absent.\n-func AddImport(fset *token.FileSet, f *ast.File, path string) (added bool) {\n-\treturn AddNamedImport(fset, f, \"\", path)\n-}\n-\n-// AddNamedImport adds the import with the given name and path to the file f, if absent.\n-// If name is not empty, it is used to rename the import.\n-//\n-// For example, calling\n-//\tAddNamedImport(fset, f, \"pathpkg\", \"path\")\n-// adds\n-//\timport pathpkg \"path\"\n-func AddNamedImport(fset *token.FileSet, f *ast.File, name, path string) (added bool) {\n-\tif imports(f, name, path) {\n-\t\treturn false\n-\t}\n-\n-\tnewImport := &ast.ImportSpec{\n-\t\tPath: &ast.BasicLit{\n-\t\t\tKind:  token.STRING,\n-\t\t\tValue: strconv.Quote(path),\n-\t\t},\n-\t}\n-\tif name != \"\" {\n-\t\tnewImport.Name = &ast.Ident{Name: name}\n-\t}\n-\n-\t// Find an import decl to add to.\n-\t// The goal is to find an existing import\n-\t// whose import path has the longest shared\n-\t// prefix with path.\n-\tvar (\n-\t\tbestMatch  = -1         // length of longest shared prefix\n-\t\tlastImport = -1         // index in f.Decls of the file's final import decl\n-\t\timpDecl    *ast.GenDecl // import decl containing the best match\n-\t\timpIndex   = -1         // spec index in impDecl containing the best match\n-\n-\t\tisThirdPartyPath = isThirdParty(path)\n-\t)\n-\tfor i, decl := range f.Decls {\n-\t\tgen, ok := decl.(*ast.GenDecl)\n-\t\tif ok && gen.Tok == token.IMPORT {\n-\t\t\tlastImport = i\n-\t\t\t// Do not add to import \"C\", to avoid disrupting the\n-\t\t\t// association with its doc comment, breaking cgo.\n-\t\t\tif declImports(gen, \"C\") {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\n-\t\t\t// Match an empty import decl if that's all that is available.\n-\t\t\tif len(gen.Specs) == 0 && bestMatch == -1 {\n-\t\t\t\timpDecl = gen\n-\t\t\t}\n-\n-\t\t\t// Compute longest shared prefix with imports in this group and find best\n-\t\t\t// matched import spec.\n-\t\t\t// 1. Always prefer import spec with longest shared prefix.\n-\t\t\t// 2. While match length is 0,\n-\t\t\t// - for stdlib package: prefer first import spec.\n-\t\t\t// - for third party package: prefer first third party import spec.\n-\t\t\t// We cannot use last import spec as best match for third party package\n-\t\t\t// because grouped imports are usually placed last by goimports -local\n-\t\t\t// flag.\n-\t\t\t// See issue #19190.\n-\t\t\tseenAnyThirdParty := false\n-\t\t\tfor j, spec := range gen.Specs {\n-\t\t\t\timpspec := spec.(*ast.ImportSpec)\n-\t\t\t\tp := importPath(impspec)\n-\t\t\t\tn := matchLen(p, path)\n-\t\t\t\tif n > bestMatch || (bestMatch == 0 && !seenAnyThirdParty && isThirdPartyPath) {\n-\t\t\t\t\tbestMatch = n\n-\t\t\t\t\timpDecl = gen\n-\t\t\t\t\timpIndex = j\n-\t\t\t\t}\n-\t\t\t\tseenAnyThirdParty = seenAnyThirdParty || isThirdParty(p)\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t// If no import decl found, add one after the last import.\n-\tif impDecl == nil {\n-\t\timpDecl = &ast.GenDecl{\n-\t\t\tTok: token.IMPORT,\n-\t\t}\n-\t\tif lastImport >= 0 {\n-\t\t\timpDecl.TokPos = f.Decls[lastImport].End()\n-\t\t} else {\n-\t\t\t// There are no existing imports.\n-\t\t\t// Our new import, preceded by a blank line,  goes after the package declaration\n-\t\t\t// and after the comment, if any, that starts on the same line as the\n-\t\t\t// package declaration.\n-\t\t\timpDecl.TokPos = f.Package\n-\n-\t\t\tfile := fset.File(f.Package)\n-\t\t\tpkgLine := file.Line(f.Package)\n-\t\t\tfor _, c := range f.Comments {\n-\t\t\t\tif file.Line(c.Pos()) > pkgLine {\n-\t\t\t\t\tbreak\n-\t\t\t\t}\n-\t\t\t\t// +2 for a blank line\n-\t\t\t\timpDecl.TokPos = c.End() + 2\n-\t\t\t}\n-\t\t}\n-\t\tf.Decls = append(f.Decls, nil)\n-\t\tcopy(f.Decls[lastImport+2:], f.Decls[lastImport+1:])\n-\t\tf.Decls[lastImport+1] = impDecl\n-\t}\n-\n-\t// Insert new import at insertAt.\n-\tinsertAt := 0\n-\tif impIndex >= 0 {\n-\t\t// insert after the found import\n-\t\tinsertAt = impIndex + 1\n-\t}\n-\timpDecl.Specs = append(impDecl.Specs, nil)\n-\tcopy(impDecl.Specs[insertAt+1:], impDecl.Specs[insertAt:])\n-\timpDecl.Specs[insertAt] = newImport\n-\tpos := impDecl.Pos()\n-\tif insertAt > 0 {\n-\t\t// If there is a comment after an existing import, preserve the comment\n-\t\t// position by adding the new import after the comment.\n-\t\tif spec, ok := impDecl.Specs[insertAt-1].(*ast.ImportSpec); ok && spec.Comment != nil {\n-\t\t\tpos = spec.Comment.End()\n-\t\t} else {\n-\t\t\t// Assign same position as the previous import,\n-\t\t\t// so that the sorter sees it as being in the same block.\n-\t\t\tpos = impDecl.Specs[insertAt-1].Pos()\n-\t\t}\n-\t}\n-\tif newImport.Name != nil {\n-\t\tnewImport.Name.NamePos = pos\n-\t}\n-\tnewImport.Path.ValuePos = pos\n-\tnewImport.EndPos = pos\n-\n-\t// Clean up parens. impDecl contains at least one spec.\n-\tif len(impDecl.Specs) == 1 {\n-\t\t// Remove unneeded parens.\n-\t\timpDecl.Lparen = token.NoPos\n-\t} else if !impDecl.Lparen.IsValid() {\n-\t\t// impDecl needs parens added.\n-\t\timpDecl.Lparen = impDecl.Specs[0].Pos()\n-\t}\n-\n-\tf.Imports = append(f.Imports, newImport)\n-\n-\tif len(f.Decls) <= 1 {\n-\t\treturn true\n-\t}\n-\n-\t// Merge all the import declarations into the first one.\n-\tvar first *ast.GenDecl\n-\tfor i := 0; i < len(f.Decls); i++ {\n-\t\tdecl := f.Decls[i]\n-\t\tgen, ok := decl.(*ast.GenDecl)\n-\t\tif !ok || gen.Tok != token.IMPORT || declImports(gen, \"C\") {\n-\t\t\tcontinue\n-\t\t}\n-\t\tif first == nil {\n-\t\t\tfirst = gen\n-\t\t\tcontinue // Don't touch the first one.\n-\t\t}\n-\t\t// We now know there is more than one package in this import\n-\t\t// declaration. Ensure that it ends up parenthesized.\n-\t\tfirst.Lparen = first.Pos()\n-\t\t// Move the imports of the other import declaration to the first one.\n-\t\tfor _, spec := range gen.Specs {\n-\t\t\tspec.(*ast.ImportSpec).Path.ValuePos = first.Pos()\n-\t\t\tfirst.Specs = append(first.Specs, spec)\n-\t\t}\n-\t\tf.Decls = append(f.Decls[:i], f.Decls[i+1:]...)\n-\t\ti--\n-\t}\n-\n-\treturn true\n-}\n-\n-func isThirdParty(importPath string) bool {\n-\t// Third party package import path usually contains \".\" (\".com\", \".org\", ...)\n-\t// This logic is taken from golang.org/x/tools/imports package.\n-\treturn strings.Contains(importPath, \".\")\n-}\n-\n-// DeleteImport deletes the import path from the file f, if present.\n-// If there are duplicate import declarations, all matching ones are deleted.\n-func DeleteImport(fset *token.FileSet, f *ast.File, path string) (deleted bool) {\n-\treturn DeleteNamedImport(fset, f, \"\", path)\n-}\n-\n-// DeleteNamedImport deletes the import with the given name and path from the file f, if present.\n-// If there are duplicate import declarations, all matching ones are deleted.\n-func DeleteNamedImport(fset *token.FileSet, f *ast.File, name, path string) (deleted bool) {\n-\tvar delspecs []*ast.ImportSpec\n-\tvar delcomments []*ast.CommentGroup\n-\n-\t// Find the import nodes that import path, if any.\n-\tfor i := 0; i < len(f.Decls); i++ {\n-\t\tdecl := f.Decls[i]\n-\t\tgen, ok := decl.(*ast.GenDecl)\n-\t\tif !ok || gen.Tok != token.IMPORT {\n-\t\t\tcontinue\n-\t\t}\n-\t\tfor j := 0; j < len(gen.Specs); j++ {\n-\t\t\tspec := gen.Specs[j]\n-\t\t\timpspec := spec.(*ast.ImportSpec)\n-\t\t\tif importName(impspec) != name || importPath(impspec) != path {\n-\t\t\t\tcontinue\n-\t\t\t}\n-\n-\t\t\t// We found an import spec that imports path.\n-\t\t\t// Delete it.\n-\t\t\tdelspecs = append(delspecs, impspec)\n-\t\t\tdeleted = true\n-\t\t\tcopy(gen.Specs[j:], gen.Specs[j+1:])\n-\t\t\tgen.Specs = gen.Specs[:len(gen.Specs)-1]\n-\n-\t\t\t// If this was the last import spec in this decl,\n-\t\t\t// delete the decl, too.\n-\t\t\tif len(gen.Specs) == 0 {\n-\t\t\t\tcopy(f.Decls[i:], f.Decls[i+1:])\n-\t\t\t\tf.Decls = f.Decls[:len(f.Decls)-1]\n-\t\t\t\ti--\n-\t\t\t\tbreak\n-\t\t\t} else if len(gen.Specs) == 1 {\n-\t\t\t\tif impspec.Doc != nil {\n-\t\t\t\t\tdelcomments = append(delcomments, impspec.Doc)\n-\t\t\t\t}\n-\t\t\t\tif impspec.Comment != nil {\n-\t\t\t\t\tdelcomments = append(delcomments, impspec.Comment)\n-\t\t\t\t}\n-\t\t\t\tfor _, cg := range f.Comments {\n-\t\t\t\t\t// Found comment on the same line as the import spec.\n-\t\t\t\t\tif cg.End() < impspec.Pos() && fset.Position(cg.End()).Line == fset.Position(impspec.Pos()).Line {\n-\t\t\t\t\t\tdelcomments = append(delcomments, cg)\n-\t\t\t\t\t\tbreak\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\n-\t\t\t\tspec := gen.Specs[0].(*ast.ImportSpec)\n-\n-\t\t\t\t// Move the documentation right after the import decl.\n-\t\t\t\tif spec.Doc != nil {\n-\t\t\t\t\tfor fset.Position(gen.TokPos).Line+1 < fset.Position(spec.Doc.Pos()).Line {\n-\t\t\t\t\t\tfset.File(gen.TokPos).MergeLine(fset.Position(gen.TokPos).Line)\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\tfor _, cg := range f.Comments {\n-\t\t\t\t\tif cg.End() < spec.Pos() && fset.Position(cg.End()).Line == fset.Position(spec.Pos()).Line {\n-\t\t\t\t\t\tfor fset.Position(gen.TokPos).Line+1 < fset.Position(spec.Pos()).Line {\n-\t\t\t\t\t\t\tfset.File(gen.TokPos).MergeLine(fset.Position(gen.TokPos).Line)\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\tbreak\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif j > 0 {\n-\t\t\t\tlastImpspec := gen.Specs[j-1].(*ast.ImportSpec)\n-\t\t\t\tlastLine := fset.Position(lastImpspec.Path.ValuePos).Line\n-\t\t\t\tline := fset.Position(impspec.Path.ValuePos).Line\n-\n-\t\t\t\t// We deleted an entry but now there may be\n-\t\t\t\t// a blank line-sized hole where the import was.\n-\t\t\t\tif line-lastLine > 1 || !gen.Rparen.IsValid() {\n-\t\t\t\t\t// There was a blank line immediately preceding the deleted import,\n-\t\t\t\t\t// so there's no need to close the hole. The right parenthesis is\n-\t\t\t\t\t// invalid after AddImport to an import statement without parenthesis.\n-\t\t\t\t\t// Do nothing.\n-\t\t\t\t} else if line != fset.File(gen.Rparen).LineCount() {\n-\t\t\t\t\t// There was no blank line. Close the hole.\n-\t\t\t\t\tfset.File(gen.Rparen).MergeLine(line)\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tj--\n-\t\t}\n-\t}\n-\n-\t// Delete imports from f.Imports.\n-\tfor i := 0; i < len(f.Imports); i++ {\n-\t\timp := f.Imports[i]\n-\t\tfor j, del := range delspecs {\n-\t\t\tif imp == del {\n-\t\t\t\tcopy(f.Imports[i:], f.Imports[i+1:])\n-\t\t\t\tf.Imports = f.Imports[:len(f.Imports)-1]\n-\t\t\t\tcopy(delspecs[j:], delspecs[j+1:])\n-\t\t\t\tdelspecs = delspecs[:len(delspecs)-1]\n-\t\t\t\ti--\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t// Delete comments from f.Comments.\n-\tfor i := 0; i < len(f.Comments); i++ {\n-\t\tcg := f.Comments[i]\n-\t\tfor j, del := range delcomments {\n-\t\t\tif cg == del {\n-\t\t\t\tcopy(f.Comments[i:], f.Comments[i+1:])\n-\t\t\t\tf.Comments = f.Comments[:len(f.Comments)-1]\n-\t\t\t\tcopy(delcomments[j:], delcomments[j+1:])\n-\t\t\t\tdelcomments = delcomments[:len(delcomments)-1]\n-\t\t\t\ti--\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tif len(delspecs) > 0 {\n-\t\tpanic(fmt.Sprintf(\"deleted specs from Decls but not Imports: %v\", delspecs))\n-\t}\n-\n-\treturn\n-}\n-\n-// RewriteImport rewrites any import of path oldPath to path newPath.\n-func RewriteImport(fset *token.FileSet, f *ast.File, oldPath, newPath string) (rewrote bool) {\n-\tfor _, imp := range f.Imports {\n-\t\tif importPath(imp) == oldPath {\n-\t\t\trewrote = true\n-\t\t\t// record old End, because the default is to compute\n-\t\t\t// it using the length of imp.Path.Value.\n-\t\t\timp.EndPos = imp.End()\n-\t\t\timp.Path.Value = strconv.Quote(newPath)\n-\t\t}\n-\t}\n-\treturn\n-}\n-\n-// UsesImport reports whether a given import is used.\n-func UsesImport(f *ast.File, path string) (used bool) {\n-\tspec := importSpec(f, path)\n-\tif spec == nil {\n-\t\treturn\n-\t}\n-\n-\tname := spec.Name.String()\n-\tswitch name {\n-\tcase \"<nil>\":\n-\t\t// If the package name is not explicitly specified,\n-\t\t// make an educated guess. This is not guaranteed to be correct.\n-\t\tlastSlash := strings.LastIndex(path, \"/\")\n-\t\tif lastSlash == -1 {\n-\t\t\tname = path\n-\t\t} else {\n-\t\t\tname = path[lastSlash+1:]\n-\t\t}\n-\tcase \"_\", \".\":\n-\t\t// Not sure if this import is used - err on the side of caution.\n-\t\treturn true\n-\t}\n-\n-\tast.Walk(visitFn(func(n ast.Node) {\n-\t\tsel, ok := n.(*ast.SelectorExpr)\n-\t\tif ok && isTopName(sel.X, name) {\n-\t\t\tused = true\n-\t\t}\n-\t}), f)\n-\n-\treturn\n-}\n-\n-type visitFn func(node ast.Node)\n-\n-func (fn visitFn) Visit(node ast.Node) ast.Visitor {\n-\tfn(node)\n-\treturn fn\n-}\n-\n-// imports reports whether f has an import with the specified name and path.\n-func imports(f *ast.File, name, path string) bool {\n-\tfor _, s := range f.Imports {\n-\t\tif importName(s) == name && importPath(s) == path {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// importSpec returns the import spec if f imports path,\n-// or nil otherwise.\n-func importSpec(f *ast.File, path string) *ast.ImportSpec {\n-\tfor _, s := range f.Imports {\n-\t\tif importPath(s) == path {\n-\t\t\treturn s\n-\t\t}\n-\t}\n-\treturn nil\n-}\n-\n-// importName returns the name of s,\n-// or \"\" if the import is not named.\n-func importName(s *ast.ImportSpec) string {\n-\tif s.Name == nil {\n-\t\treturn \"\"\n-\t}\n-\treturn s.Name.Name\n-}\n-\n-// importPath returns the unquoted import path of s,\n-// or \"\" if the path is not properly quoted.\n-func importPath(s *ast.ImportSpec) string {\n-\tt, err := strconv.Unquote(s.Path.Value)\n-\tif err != nil {\n-\t\treturn \"\"\n-\t}\n-\treturn t\n-}\n-\n-// declImports reports whether gen contains an import of path.\n-func declImports(gen *ast.GenDecl, path string) bool {\n-\tif gen.Tok != token.IMPORT {\n-\t\treturn false\n-\t}\n-\tfor _, spec := range gen.Specs {\n-\t\timpspec := spec.(*ast.ImportSpec)\n-\t\tif importPath(impspec) == path {\n-\t\t\treturn true\n-\t\t}\n-\t}\n-\treturn false\n-}\n-\n-// matchLen returns the length of the longest path segment prefix shared by x and y.\n-func matchLen(x, y string) int {\n-\tn := 0\n-\tfor i := 0; i < len(x) && i < len(y) && x[i] == y[i]; i++ {\n-\t\tif x[i] == '/' {\n-\t\t\tn++\n-\t\t}\n-\t}\n-\treturn n\n-}\n-\n-// isTopName returns true if n is a top-level unresolved identifier with the given name.\n-func isTopName(n ast.Expr, name string) bool {\n-\tid, ok := n.(*ast.Ident)\n-\treturn ok && id.Name == name && id.Obj == nil\n-}\n-\n-// Imports returns the file imports grouped by paragraph.\n-func Imports(fset *token.FileSet, f *ast.File) [][]*ast.ImportSpec {\n-\tvar groups [][]*ast.ImportSpec\n-\n-\tfor _, decl := range f.Decls {\n-\t\tgenDecl, ok := decl.(*ast.GenDecl)\n-\t\tif !ok || genDecl.Tok != token.IMPORT {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\tgroup := []*ast.ImportSpec{}\n-\n-\t\tvar lastLine int\n-\t\tfor _, spec := range genDecl.Specs {\n-\t\t\timportSpec := spec.(*ast.ImportSpec)\n-\t\t\tpos := importSpec.Path.ValuePos\n-\t\t\tline := fset.Position(pos).Line\n-\t\t\tif lastLine > 0 && pos > 0 && line-lastLine > 1 {\n-\t\t\t\tgroups = append(groups, group)\n-\t\t\t\tgroup = []*ast.ImportSpec{}\n-\t\t\t}\n-\t\t\tgroup = append(group, importSpec)\n-\t\t\tlastLine = line\n-\t\t}\n-\t\tgroups = append(groups, group)\n-\t}\n-\n-\treturn groups\n-}"
    },
    {
      "sha": "cf72ea990bda2c11ae7a87865c352b7fc9029730",
      "filename": "backend/vendor/golang.org/x/tools/go/ast/astutil/rewrite.go",
      "status": "removed",
      "additions": 0,
      "deletions": 477,
      "changes": 477,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/rewrite.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/rewrite.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/ast/astutil/rewrite.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,477 +0,0 @@\n-// Copyright 2017 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-package astutil\n-\n-import (\n-\t\"fmt\"\n-\t\"go/ast\"\n-\t\"reflect\"\n-\t\"sort\"\n-)\n-\n-// An ApplyFunc is invoked by Apply for each node n, even if n is nil,\n-// before and/or after the node's children, using a Cursor describing\n-// the current node and providing operations on it.\n-//\n-// The return value of ApplyFunc controls the syntax tree traversal.\n-// See Apply for details.\n-type ApplyFunc func(*Cursor) bool\n-\n-// Apply traverses a syntax tree recursively, starting with root,\n-// and calling pre and post for each node as described below.\n-// Apply returns the syntax tree, possibly modified.\n-//\n-// If pre is not nil, it is called for each node before the node's\n-// children are traversed (pre-order). If pre returns false, no\n-// children are traversed, and post is not called for that node.\n-//\n-// If post is not nil, and a prior call of pre didn't return false,\n-// post is called for each node after its children are traversed\n-// (post-order). If post returns false, traversal is terminated and\n-// Apply returns immediately.\n-//\n-// Only fields that refer to AST nodes are considered children;\n-// i.e., token.Pos, Scopes, Objects, and fields of basic types\n-// (strings, etc.) are ignored.\n-//\n-// Children are traversed in the order in which they appear in the\n-// respective node's struct definition. A package's files are\n-// traversed in the filenames' alphabetical order.\n-//\n-func Apply(root ast.Node, pre, post ApplyFunc) (result ast.Node) {\n-\tparent := &struct{ ast.Node }{root}\n-\tdefer func() {\n-\t\tif r := recover(); r != nil && r != abort {\n-\t\t\tpanic(r)\n-\t\t}\n-\t\tresult = parent.Node\n-\t}()\n-\ta := &application{pre: pre, post: post}\n-\ta.apply(parent, \"Node\", nil, root)\n-\treturn\n-}\n-\n-var abort = new(int) // singleton, to signal termination of Apply\n-\n-// A Cursor describes a node encountered during Apply.\n-// Information about the node and its parent is available\n-// from the Node, Parent, Name, and Index methods.\n-//\n-// If p is a variable of type and value of the current parent node\n-// c.Parent(), and f is the field identifier with name c.Name(),\n-// the following invariants hold:\n-//\n-//   p.f            == c.Node()  if c.Index() <  0\n-//   p.f[c.Index()] == c.Node()  if c.Index() >= 0\n-//\n-// The methods Replace, Delete, InsertBefore, and InsertAfter\n-// can be used to change the AST without disrupting Apply.\n-type Cursor struct {\n-\tparent ast.Node\n-\tname   string\n-\titer   *iterator // valid if non-nil\n-\tnode   ast.Node\n-}\n-\n-// Node returns the current Node.\n-func (c *Cursor) Node() ast.Node { return c.node }\n-\n-// Parent returns the parent of the current Node.\n-func (c *Cursor) Parent() ast.Node { return c.parent }\n-\n-// Name returns the name of the parent Node field that contains the current Node.\n-// If the parent is a *ast.Package and the current Node is a *ast.File, Name returns\n-// the filename for the current Node.\n-func (c *Cursor) Name() string { return c.name }\n-\n-// Index reports the index >= 0 of the current Node in the slice of Nodes that\n-// contains it, or a value < 0 if the current Node is not part of a slice.\n-// The index of the current node changes if InsertBefore is called while\n-// processing the current node.\n-func (c *Cursor) Index() int {\n-\tif c.iter != nil {\n-\t\treturn c.iter.index\n-\t}\n-\treturn -1\n-}\n-\n-// field returns the current node's parent field value.\n-func (c *Cursor) field() reflect.Value {\n-\treturn reflect.Indirect(reflect.ValueOf(c.parent)).FieldByName(c.name)\n-}\n-\n-// Replace replaces the current Node with n.\n-// The replacement node is not walked by Apply.\n-func (c *Cursor) Replace(n ast.Node) {\n-\tif _, ok := c.node.(*ast.File); ok {\n-\t\tfile, ok := n.(*ast.File)\n-\t\tif !ok {\n-\t\t\tpanic(\"attempt to replace *ast.File with non-*ast.File\")\n-\t\t}\n-\t\tc.parent.(*ast.Package).Files[c.name] = file\n-\t\treturn\n-\t}\n-\n-\tv := c.field()\n-\tif i := c.Index(); i >= 0 {\n-\t\tv = v.Index(i)\n-\t}\n-\tv.Set(reflect.ValueOf(n))\n-}\n-\n-// Delete deletes the current Node from its containing slice.\n-// If the current Node is not part of a slice, Delete panics.\n-// As a special case, if the current node is a package file,\n-// Delete removes it from the package's Files map.\n-func (c *Cursor) Delete() {\n-\tif _, ok := c.node.(*ast.File); ok {\n-\t\tdelete(c.parent.(*ast.Package).Files, c.name)\n-\t\treturn\n-\t}\n-\n-\ti := c.Index()\n-\tif i < 0 {\n-\t\tpanic(\"Delete node not contained in slice\")\n-\t}\n-\tv := c.field()\n-\tl := v.Len()\n-\treflect.Copy(v.Slice(i, l), v.Slice(i+1, l))\n-\tv.Index(l - 1).Set(reflect.Zero(v.Type().Elem()))\n-\tv.SetLen(l - 1)\n-\tc.iter.step--\n-}\n-\n-// InsertAfter inserts n after the current Node in its containing slice.\n-// If the current Node is not part of a slice, InsertAfter panics.\n-// Apply does not walk n.\n-func (c *Cursor) InsertAfter(n ast.Node) {\n-\ti := c.Index()\n-\tif i < 0 {\n-\t\tpanic(\"InsertAfter node not contained in slice\")\n-\t}\n-\tv := c.field()\n-\tv.Set(reflect.Append(v, reflect.Zero(v.Type().Elem())))\n-\tl := v.Len()\n-\treflect.Copy(v.Slice(i+2, l), v.Slice(i+1, l))\n-\tv.Index(i + 1).Set(reflect.ValueOf(n))\n-\tc.iter.step++\n-}\n-\n-// InsertBefore inserts n before the current Node in its containing slice.\n-// If the current Node is not part of a slice, InsertBefore panics.\n-// Apply will not walk n.\n-func (c *Cursor) InsertBefore(n ast.Node) {\n-\ti := c.Index()\n-\tif i < 0 {\n-\t\tpanic(\"InsertBefore node not contained in slice\")\n-\t}\n-\tv := c.field()\n-\tv.Set(reflect.Append(v, reflect.Zero(v.Type().Elem())))\n-\tl := v.Len()\n-\treflect.Copy(v.Slice(i+1, l), v.Slice(i, l))\n-\tv.Index(i).Set(reflect.ValueOf(n))\n-\tc.iter.index++\n-}\n-\n-// application carries all the shared data so we can pass it around cheaply.\n-type application struct {\n-\tpre, post ApplyFunc\n-\tcursor    Cursor\n-\titer      iterator\n-}\n-\n-func (a *application) apply(parent ast.Node, name string, iter *iterator, n ast.Node) {\n-\t// convert typed nil into untyped nil\n-\tif v := reflect.ValueOf(n); v.Kind() == reflect.Ptr && v.IsNil() {\n-\t\tn = nil\n-\t}\n-\n-\t// avoid heap-allocating a new cursor for each apply call; reuse a.cursor instead\n-\tsaved := a.cursor\n-\ta.cursor.parent = parent\n-\ta.cursor.name = name\n-\ta.cursor.iter = iter\n-\ta.cursor.node = n\n-\n-\tif a.pre != nil && !a.pre(&a.cursor) {\n-\t\ta.cursor = saved\n-\t\treturn\n-\t}\n-\n-\t// walk children\n-\t// (the order of the cases matches the order of the corresponding node types in go/ast)\n-\tswitch n := n.(type) {\n-\tcase nil:\n-\t\t// nothing to do\n-\n-\t// Comments and fields\n-\tcase *ast.Comment:\n-\t\t// nothing to do\n-\n-\tcase *ast.CommentGroup:\n-\t\tif n != nil {\n-\t\t\ta.applyList(n, \"List\")\n-\t\t}\n-\n-\tcase *ast.Field:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.applyList(n, \"Names\")\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.apply(n, \"Tag\", nil, n.Tag)\n-\t\ta.apply(n, \"Comment\", nil, n.Comment)\n-\n-\tcase *ast.FieldList:\n-\t\ta.applyList(n, \"List\")\n-\n-\t// Expressions\n-\tcase *ast.BadExpr, *ast.Ident, *ast.BasicLit:\n-\t\t// nothing to do\n-\n-\tcase *ast.Ellipsis:\n-\t\ta.apply(n, \"Elt\", nil, n.Elt)\n-\n-\tcase *ast.FuncLit:\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\tcase *ast.CompositeLit:\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.applyList(n, \"Elts\")\n-\n-\tcase *ast.ParenExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\n-\tcase *ast.SelectorExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Sel\", nil, n.Sel)\n-\n-\tcase *ast.IndexExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Index\", nil, n.Index)\n-\n-\tcase *ast.SliceExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Low\", nil, n.Low)\n-\t\ta.apply(n, \"High\", nil, n.High)\n-\t\ta.apply(n, \"Max\", nil, n.Max)\n-\n-\tcase *ast.TypeAssertExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\n-\tcase *ast.CallExpr:\n-\t\ta.apply(n, \"Fun\", nil, n.Fun)\n-\t\ta.applyList(n, \"Args\")\n-\n-\tcase *ast.StarExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\n-\tcase *ast.UnaryExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\n-\tcase *ast.BinaryExpr:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Y\", nil, n.Y)\n-\n-\tcase *ast.KeyValueExpr:\n-\t\ta.apply(n, \"Key\", nil, n.Key)\n-\t\ta.apply(n, \"Value\", nil, n.Value)\n-\n-\t// Types\n-\tcase *ast.ArrayType:\n-\t\ta.apply(n, \"Len\", nil, n.Len)\n-\t\ta.apply(n, \"Elt\", nil, n.Elt)\n-\n-\tcase *ast.StructType:\n-\t\ta.apply(n, \"Fields\", nil, n.Fields)\n-\n-\tcase *ast.FuncType:\n-\t\ta.apply(n, \"Params\", nil, n.Params)\n-\t\ta.apply(n, \"Results\", nil, n.Results)\n-\n-\tcase *ast.InterfaceType:\n-\t\ta.apply(n, \"Methods\", nil, n.Methods)\n-\n-\tcase *ast.MapType:\n-\t\ta.apply(n, \"Key\", nil, n.Key)\n-\t\ta.apply(n, \"Value\", nil, n.Value)\n-\n-\tcase *ast.ChanType:\n-\t\ta.apply(n, \"Value\", nil, n.Value)\n-\n-\t// Statements\n-\tcase *ast.BadStmt:\n-\t\t// nothing to do\n-\n-\tcase *ast.DeclStmt:\n-\t\ta.apply(n, \"Decl\", nil, n.Decl)\n-\n-\tcase *ast.EmptyStmt:\n-\t\t// nothing to do\n-\n-\tcase *ast.LabeledStmt:\n-\t\ta.apply(n, \"Label\", nil, n.Label)\n-\t\ta.apply(n, \"Stmt\", nil, n.Stmt)\n-\n-\tcase *ast.ExprStmt:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\n-\tcase *ast.SendStmt:\n-\t\ta.apply(n, \"Chan\", nil, n.Chan)\n-\t\ta.apply(n, \"Value\", nil, n.Value)\n-\n-\tcase *ast.IncDecStmt:\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\n-\tcase *ast.AssignStmt:\n-\t\ta.applyList(n, \"Lhs\")\n-\t\ta.applyList(n, \"Rhs\")\n-\n-\tcase *ast.GoStmt:\n-\t\ta.apply(n, \"Call\", nil, n.Call)\n-\n-\tcase *ast.DeferStmt:\n-\t\ta.apply(n, \"Call\", nil, n.Call)\n-\n-\tcase *ast.ReturnStmt:\n-\t\ta.applyList(n, \"Results\")\n-\n-\tcase *ast.BranchStmt:\n-\t\ta.apply(n, \"Label\", nil, n.Label)\n-\n-\tcase *ast.BlockStmt:\n-\t\ta.applyList(n, \"List\")\n-\n-\tcase *ast.IfStmt:\n-\t\ta.apply(n, \"Init\", nil, n.Init)\n-\t\ta.apply(n, \"Cond\", nil, n.Cond)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\t\ta.apply(n, \"Else\", nil, n.Else)\n-\n-\tcase *ast.CaseClause:\n-\t\ta.applyList(n, \"List\")\n-\t\ta.applyList(n, \"Body\")\n-\n-\tcase *ast.SwitchStmt:\n-\t\ta.apply(n, \"Init\", nil, n.Init)\n-\t\ta.apply(n, \"Tag\", nil, n.Tag)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\tcase *ast.TypeSwitchStmt:\n-\t\ta.apply(n, \"Init\", nil, n.Init)\n-\t\ta.apply(n, \"Assign\", nil, n.Assign)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\tcase *ast.CommClause:\n-\t\ta.apply(n, \"Comm\", nil, n.Comm)\n-\t\ta.applyList(n, \"Body\")\n-\n-\tcase *ast.SelectStmt:\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\tcase *ast.ForStmt:\n-\t\ta.apply(n, \"Init\", nil, n.Init)\n-\t\ta.apply(n, \"Cond\", nil, n.Cond)\n-\t\ta.apply(n, \"Post\", nil, n.Post)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\tcase *ast.RangeStmt:\n-\t\ta.apply(n, \"Key\", nil, n.Key)\n-\t\ta.apply(n, \"Value\", nil, n.Value)\n-\t\ta.apply(n, \"X\", nil, n.X)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\t// Declarations\n-\tcase *ast.ImportSpec:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.apply(n, \"Name\", nil, n.Name)\n-\t\ta.apply(n, \"Path\", nil, n.Path)\n-\t\ta.apply(n, \"Comment\", nil, n.Comment)\n-\n-\tcase *ast.ValueSpec:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.applyList(n, \"Names\")\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.applyList(n, \"Values\")\n-\t\ta.apply(n, \"Comment\", nil, n.Comment)\n-\n-\tcase *ast.TypeSpec:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.apply(n, \"Name\", nil, n.Name)\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.apply(n, \"Comment\", nil, n.Comment)\n-\n-\tcase *ast.BadDecl:\n-\t\t// nothing to do\n-\n-\tcase *ast.GenDecl:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.applyList(n, \"Specs\")\n-\n-\tcase *ast.FuncDecl:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.apply(n, \"Recv\", nil, n.Recv)\n-\t\ta.apply(n, \"Name\", nil, n.Name)\n-\t\ta.apply(n, \"Type\", nil, n.Type)\n-\t\ta.apply(n, \"Body\", nil, n.Body)\n-\n-\t// Files and packages\n-\tcase *ast.File:\n-\t\ta.apply(n, \"Doc\", nil, n.Doc)\n-\t\ta.apply(n, \"Name\", nil, n.Name)\n-\t\ta.applyList(n, \"Decls\")\n-\t\t// Don't walk n.Comments; they have either been walked already if\n-\t\t// they are Doc comments, or they can be easily walked explicitly.\n-\n-\tcase *ast.Package:\n-\t\t// collect and sort names for reproducible behavior\n-\t\tvar names []string\n-\t\tfor name := range n.Files {\n-\t\t\tnames = append(names, name)\n-\t\t}\n-\t\tsort.Strings(names)\n-\t\tfor _, name := range names {\n-\t\t\ta.apply(n, name, nil, n.Files[name])\n-\t\t}\n-\n-\tdefault:\n-\t\tpanic(fmt.Sprintf(\"Apply: unexpected node type %T\", n))\n-\t}\n-\n-\tif a.post != nil && !a.post(&a.cursor) {\n-\t\tpanic(abort)\n-\t}\n-\n-\ta.cursor = saved\n-}\n-\n-// An iterator controls iteration over a slice of nodes.\n-type iterator struct {\n-\tindex, step int\n-}\n-\n-func (a *application) applyList(parent ast.Node, name string) {\n-\t// avoid heap-allocating a new iterator for each applyList call; reuse a.iter instead\n-\tsaved := a.iter\n-\ta.iter.index = 0\n-\tfor {\n-\t\t// must reload parent.name each time, since cursor modifications might change it\n-\t\tv := reflect.Indirect(reflect.ValueOf(parent)).FieldByName(name)\n-\t\tif a.iter.index >= v.Len() {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\t// element x may be nil in a bad AST - be cautious\n-\t\tvar x ast.Node\n-\t\tif e := v.Index(a.iter.index); e.IsValid() {\n-\t\t\tx = e.Interface().(ast.Node)\n-\t\t}\n-\n-\t\ta.iter.step = 1\n-\t\ta.apply(parent, name, &a.iter, x)\n-\t\ta.iter.index += a.iter.step\n-\t}\n-\ta.iter = saved\n-}"
    },
    {
      "sha": "7630629824af1e839b5954b72a5d5021191d69ae",
      "filename": "backend/vendor/golang.org/x/tools/go/ast/astutil/util.go",
      "status": "removed",
      "additions": 0,
      "deletions": 14,
      "changes": 14,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/util.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/ast/astutil/util.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/ast/astutil/util.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,14 +0,0 @@\n-package astutil\n-\n-import \"go/ast\"\n-\n-// Unparen returns e with any enclosing parentheses stripped.\n-func Unparen(e ast.Expr) ast.Expr {\n-\tfor {\n-\t\tp, ok := e.(*ast.ParenExpr)\n-\t\tif !ok {\n-\t\t\treturn e\n-\t\t}\n-\t\te = p.X\n-\t}\n-}"
    },
    {
      "sha": "f8363d8faae379e98d29cb7f27b9f7818f5c8407",
      "filename": "backend/vendor/golang.org/x/tools/go/gcexportdata/gcexportdata.go",
      "status": "removed",
      "additions": 0,
      "deletions": 109,
      "changes": 109,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/gcexportdata/gcexportdata.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/gcexportdata/gcexportdata.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/gcexportdata/gcexportdata.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,109 +0,0 @@\n-// Copyright 2016 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Package gcexportdata provides functions for locating, reading, and\n-// writing export data files containing type information produced by the\n-// gc compiler.  This package supports go1.7 export data format and all\n-// later versions.\n-//\n-// Although it might seem convenient for this package to live alongside\n-// go/types in the standard library, this would cause version skew\n-// problems for developer tools that use it, since they must be able to\n-// consume the outputs of the gc compiler both before and after a Go\n-// update such as from Go 1.7 to Go 1.8.  Because this package lives in\n-// golang.org/x/tools, sites can update their version of this repo some\n-// time before the Go 1.8 release and rebuild and redeploy their\n-// developer tools, which will then be able to consume both Go 1.7 and\n-// Go 1.8 export data files, so they will work before and after the\n-// Go update. (See discussion at https://golang.org/issue/15651.)\n-//\n-package gcexportdata // import \"golang.org/x/tools/go/gcexportdata\"\n-\n-import (\n-\t\"bufio\"\n-\t\"bytes\"\n-\t\"fmt\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"io\"\n-\t\"io/ioutil\"\n-\n-\t\"golang.org/x/tools/go/internal/gcimporter\"\n-)\n-\n-// Find returns the name of an object (.o) or archive (.a) file\n-// containing type information for the specified import path,\n-// using the workspace layout conventions of go/build.\n-// If no file was found, an empty filename is returned.\n-//\n-// A relative srcDir is interpreted relative to the current working directory.\n-//\n-// Find also returns the package's resolved (canonical) import path,\n-// reflecting the effects of srcDir and vendoring on importPath.\n-func Find(importPath, srcDir string) (filename, path string) {\n-\treturn gcimporter.FindPkg(importPath, srcDir)\n-}\n-\n-// NewReader returns a reader for the export data section of an object\n-// (.o) or archive (.a) file read from r.  The new reader may provide\n-// additional trailing data beyond the end of the export data.\n-func NewReader(r io.Reader) (io.Reader, error) {\n-\tbuf := bufio.NewReader(r)\n-\t_, err := gcimporter.FindExportData(buf)\n-\t// If we ever switch to a zip-like archive format with the ToC\n-\t// at the end, we can return the correct portion of export data,\n-\t// but for now we must return the entire rest of the file.\n-\treturn buf, err\n-}\n-\n-// Read reads export data from in, decodes it, and returns type\n-// information for the package.\n-// The package name is specified by path.\n-// File position information is added to fset.\n-//\n-// Read may inspect and add to the imports map to ensure that references\n-// within the export data to other packages are consistent.  The caller\n-// must ensure that imports[path] does not exist, or exists but is\n-// incomplete (see types.Package.Complete), and Read inserts the\n-// resulting package into this map entry.\n-//\n-// On return, the state of the reader is undefined.\n-func Read(in io.Reader, fset *token.FileSet, imports map[string]*types.Package, path string) (*types.Package, error) {\n-\tdata, err := ioutil.ReadAll(in)\n-\tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"reading export data for %q: %v\", path, err)\n-\t}\n-\n-\tif bytes.HasPrefix(data, []byte(\"!<arch>\")) {\n-\t\treturn nil, fmt.Errorf(\"can't read export data for %q directly from an archive file (call gcexportdata.NewReader first to extract export data)\", path)\n-\t}\n-\n-\t// The App Engine Go runtime v1.6 uses the old export data format.\n-\t// TODO(adonovan): delete once v1.7 has been around for a while.\n-\tif bytes.HasPrefix(data, []byte(\"package \")) {\n-\t\treturn gcimporter.ImportData(imports, path, path, bytes.NewReader(data))\n-\t}\n-\n-\t// The indexed export format starts with an 'i'; the older\n-\t// binary export format starts with a 'c', 'd', or 'v'\n-\t// (from \"version\"). Select appropriate importer.\n-\tif len(data) > 0 && data[0] == 'i' {\n-\t\t_, pkg, err := gcimporter.IImportData(fset, imports, data[1:], path)\n-\t\treturn pkg, err\n-\t}\n-\n-\t_, pkg, err := gcimporter.BImportData(fset, imports, data, path)\n-\treturn pkg, err\n-}\n-\n-// Write writes encoded type information for the specified package to out.\n-// The FileSet provides file position information for named objects.\n-func Write(out io.Writer, fset *token.FileSet, pkg *types.Package) error {\n-\tb, err := gcimporter.IExportData(fset, pkg)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\t_, err = out.Write(b)\n-\treturn err\n-}"
    },
    {
      "sha": "efe221e7e1423e370d968eb512be02bb7ea6601e",
      "filename": "backend/vendor/golang.org/x/tools/go/gcexportdata/importer.go",
      "status": "removed",
      "additions": 0,
      "deletions": 73,
      "changes": 73,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/gcexportdata/importer.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/gcexportdata/importer.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/gcexportdata/importer.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,73 +0,0 @@\n-// Copyright 2016 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-package gcexportdata\n-\n-import (\n-\t\"fmt\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"os\"\n-)\n-\n-// NewImporter returns a new instance of the types.Importer interface\n-// that reads type information from export data files written by gc.\n-// The Importer also satisfies types.ImporterFrom.\n-//\n-// Export data files are located using \"go build\" workspace conventions\n-// and the build.Default context.\n-//\n-// Use this importer instead of go/importer.For(\"gc\", ...) to avoid the\n-// version-skew problems described in the documentation of this package,\n-// or to control the FileSet or access the imports map populated during\n-// package loading.\n-//\n-func NewImporter(fset *token.FileSet, imports map[string]*types.Package) types.ImporterFrom {\n-\treturn importer{fset, imports}\n-}\n-\n-type importer struct {\n-\tfset    *token.FileSet\n-\timports map[string]*types.Package\n-}\n-\n-func (imp importer) Import(importPath string) (*types.Package, error) {\n-\treturn imp.ImportFrom(importPath, \"\", 0)\n-}\n-\n-func (imp importer) ImportFrom(importPath, srcDir string, mode types.ImportMode) (_ *types.Package, err error) {\n-\tfilename, path := Find(importPath, srcDir)\n-\tif filename == \"\" {\n-\t\tif importPath == \"unsafe\" {\n-\t\t\t// Even for unsafe, call Find first in case\n-\t\t\t// the package was vendored.\n-\t\t\treturn types.Unsafe, nil\n-\t\t}\n-\t\treturn nil, fmt.Errorf(\"can't find import: %s\", importPath)\n-\t}\n-\n-\tif pkg, ok := imp.imports[path]; ok && pkg.Complete() {\n-\t\treturn pkg, nil // cache hit\n-\t}\n-\n-\t// open file\n-\tf, err := os.Open(filename)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\tdefer func() {\n-\t\tf.Close()\n-\t\tif err != nil {\n-\t\t\t// add file name to error\n-\t\t\terr = fmt.Errorf(\"reading export data: %s: %v\", filename, err)\n-\t\t}\n-\t}()\n-\n-\tr, err := NewReader(f)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\n-\treturn Read(r, imp.fset, imp.imports, path)\n-}"
    },
    {
      "sha": "a807d0aaa281325c537ceb8f6f6f81383225bfd2",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/bexport.go",
      "status": "removed",
      "additions": 0,
      "deletions": 852,
      "changes": 852,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bexport.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bexport.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bexport.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,852 +0,0 @@\n-// Copyright 2016 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Binary package export.\n-// This file was derived from $GOROOT/src/cmd/compile/internal/gc/bexport.go;\n-// see that file for specification of the format.\n-\n-package gcimporter\n-\n-import (\n-\t\"bytes\"\n-\t\"encoding/binary\"\n-\t\"fmt\"\n-\t\"go/ast\"\n-\t\"go/constant\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"math\"\n-\t\"math/big\"\n-\t\"sort\"\n-\t\"strings\"\n-)\n-\n-// If debugFormat is set, each integer and string value is preceded by a marker\n-// and position information in the encoding. This mechanism permits an importer\n-// to recognize immediately when it is out of sync. The importer recognizes this\n-// mode automatically (i.e., it can import export data produced with debugging\n-// support even if debugFormat is not set at the time of import). This mode will\n-// lead to massively larger export data (by a factor of 2 to 3) and should only\n-// be enabled during development and debugging.\n-//\n-// NOTE: This flag is the first flag to enable if importing dies because of\n-// (suspected) format errors, and whenever a change is made to the format.\n-const debugFormat = false // default: false\n-\n-// If trace is set, debugging output is printed to std out.\n-const trace = false // default: false\n-\n-// Current export format version. Increase with each format change.\n-// Note: The latest binary (non-indexed) export format is at version 6.\n-//       This exporter is still at level 4, but it doesn't matter since\n-//       the binary importer can handle older versions just fine.\n-// 6: package height (CL 105038) -- NOT IMPLEMENTED HERE\n-// 5: improved position encoding efficiency (issue 20080, CL 41619) -- NOT IMPLEMEMTED HERE\n-// 4: type name objects support type aliases, uses aliasTag\n-// 3: Go1.8 encoding (same as version 2, aliasTag defined but never used)\n-// 2: removed unused bool in ODCL export (compiler only)\n-// 1: header format change (more regular), export package for _ struct fields\n-// 0: Go1.7 encoding\n-const exportVersion = 4\n-\n-// trackAllTypes enables cycle tracking for all types, not just named\n-// types. The existing compiler invariants assume that unnamed types\n-// that are not completely set up are not used, or else there are spurious\n-// errors.\n-// If disabled, only named types are tracked, possibly leading to slightly\n-// less efficient encoding in rare cases. It also prevents the export of\n-// some corner-case type declarations (but those are not handled correctly\n-// with with the textual export format either).\n-// TODO(gri) enable and remove once issues caused by it are fixed\n-const trackAllTypes = false\n-\n-type exporter struct {\n-\tfset *token.FileSet\n-\tout  bytes.Buffer\n-\n-\t// object -> index maps, indexed in order of serialization\n-\tstrIndex map[string]int\n-\tpkgIndex map[*types.Package]int\n-\ttypIndex map[types.Type]int\n-\n-\t// position encoding\n-\tposInfoFormat bool\n-\tprevFile      string\n-\tprevLine      int\n-\n-\t// debugging support\n-\twritten int // bytes written\n-\tindent  int // for trace\n-}\n-\n-// internalError represents an error generated inside this package.\n-type internalError string\n-\n-func (e internalError) Error() string { return \"gcimporter: \" + string(e) }\n-\n-func internalErrorf(format string, args ...interface{}) error {\n-\treturn internalError(fmt.Sprintf(format, args...))\n-}\n-\n-// BExportData returns binary export data for pkg.\n-// If no file set is provided, position info will be missing.\n-func BExportData(fset *token.FileSet, pkg *types.Package) (b []byte, err error) {\n-\tdefer func() {\n-\t\tif e := recover(); e != nil {\n-\t\t\tif ierr, ok := e.(internalError); ok {\n-\t\t\t\terr = ierr\n-\t\t\t\treturn\n-\t\t\t}\n-\t\t\t// Not an internal error; panic again.\n-\t\t\tpanic(e)\n-\t\t}\n-\t}()\n-\n-\tp := exporter{\n-\t\tfset:          fset,\n-\t\tstrIndex:      map[string]int{\"\": 0}, // empty string is mapped to 0\n-\t\tpkgIndex:      make(map[*types.Package]int),\n-\t\ttypIndex:      make(map[types.Type]int),\n-\t\tposInfoFormat: true, // TODO(gri) might become a flag, eventually\n-\t}\n-\n-\t// write version info\n-\t// The version string must start with \"version %d\" where %d is the version\n-\t// number. Additional debugging information may follow after a blank; that\n-\t// text is ignored by the importer.\n-\tp.rawStringln(fmt.Sprintf(\"version %d\", exportVersion))\n-\tvar debug string\n-\tif debugFormat {\n-\t\tdebug = \"debug\"\n-\t}\n-\tp.rawStringln(debug) // cannot use p.bool since it's affected by debugFormat; also want to see this clearly\n-\tp.bool(trackAllTypes)\n-\tp.bool(p.posInfoFormat)\n-\n-\t// --- generic export data ---\n-\n-\t// populate type map with predeclared \"known\" types\n-\tfor index, typ := range predeclared() {\n-\t\tp.typIndex[typ] = index\n-\t}\n-\tif len(p.typIndex) != len(predeclared()) {\n-\t\treturn nil, internalError(\"duplicate entries in type map?\")\n-\t}\n-\n-\t// write package data\n-\tp.pkg(pkg, true)\n-\tif trace {\n-\t\tp.tracef(\"\\n\")\n-\t}\n-\n-\t// write objects\n-\tobjcount := 0\n-\tscope := pkg.Scope()\n-\tfor _, name := range scope.Names() {\n-\t\tif !ast.IsExported(name) {\n-\t\t\tcontinue\n-\t\t}\n-\t\tif trace {\n-\t\t\tp.tracef(\"\\n\")\n-\t\t}\n-\t\tp.obj(scope.Lookup(name))\n-\t\tobjcount++\n-\t}\n-\n-\t// indicate end of list\n-\tif trace {\n-\t\tp.tracef(\"\\n\")\n-\t}\n-\tp.tag(endTag)\n-\n-\t// for self-verification only (redundant)\n-\tp.int(objcount)\n-\n-\tif trace {\n-\t\tp.tracef(\"\\n\")\n-\t}\n-\n-\t// --- end of export data ---\n-\n-\treturn p.out.Bytes(), nil\n-}\n-\n-func (p *exporter) pkg(pkg *types.Package, emptypath bool) {\n-\tif pkg == nil {\n-\t\tpanic(internalError(\"unexpected nil pkg\"))\n-\t}\n-\n-\t// if we saw the package before, write its index (>= 0)\n-\tif i, ok := p.pkgIndex[pkg]; ok {\n-\t\tp.index('P', i)\n-\t\treturn\n-\t}\n-\n-\t// otherwise, remember the package, write the package tag (< 0) and package data\n-\tif trace {\n-\t\tp.tracef(\"P%d = { \", len(p.pkgIndex))\n-\t\tdefer p.tracef(\"} \")\n-\t}\n-\tp.pkgIndex[pkg] = len(p.pkgIndex)\n-\n-\tp.tag(packageTag)\n-\tp.string(pkg.Name())\n-\tif emptypath {\n-\t\tp.string(\"\")\n-\t} else {\n-\t\tp.string(pkg.Path())\n-\t}\n-}\n-\n-func (p *exporter) obj(obj types.Object) {\n-\tswitch obj := obj.(type) {\n-\tcase *types.Const:\n-\t\tp.tag(constTag)\n-\t\tp.pos(obj)\n-\t\tp.qualifiedName(obj)\n-\t\tp.typ(obj.Type())\n-\t\tp.value(obj.Val())\n-\n-\tcase *types.TypeName:\n-\t\tif obj.IsAlias() {\n-\t\t\tp.tag(aliasTag)\n-\t\t\tp.pos(obj)\n-\t\t\tp.qualifiedName(obj)\n-\t\t} else {\n-\t\t\tp.tag(typeTag)\n-\t\t}\n-\t\tp.typ(obj.Type())\n-\n-\tcase *types.Var:\n-\t\tp.tag(varTag)\n-\t\tp.pos(obj)\n-\t\tp.qualifiedName(obj)\n-\t\tp.typ(obj.Type())\n-\n-\tcase *types.Func:\n-\t\tp.tag(funcTag)\n-\t\tp.pos(obj)\n-\t\tp.qualifiedName(obj)\n-\t\tsig := obj.Type().(*types.Signature)\n-\t\tp.paramList(sig.Params(), sig.Variadic())\n-\t\tp.paramList(sig.Results(), false)\n-\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected object %v (%T)\", obj, obj))\n-\t}\n-}\n-\n-func (p *exporter) pos(obj types.Object) {\n-\tif !p.posInfoFormat {\n-\t\treturn\n-\t}\n-\n-\tfile, line := p.fileLine(obj)\n-\tif file == p.prevFile {\n-\t\t// common case: write line delta\n-\t\t// delta == 0 means different file or no line change\n-\t\tdelta := line - p.prevLine\n-\t\tp.int(delta)\n-\t\tif delta == 0 {\n-\t\t\tp.int(-1) // -1 means no file change\n-\t\t}\n-\t} else {\n-\t\t// different file\n-\t\tp.int(0)\n-\t\t// Encode filename as length of common prefix with previous\n-\t\t// filename, followed by (possibly empty) suffix. Filenames\n-\t\t// frequently share path prefixes, so this can save a lot\n-\t\t// of space and make export data size less dependent on file\n-\t\t// path length. The suffix is unlikely to be empty because\n-\t\t// file names tend to end in \".go\".\n-\t\tn := commonPrefixLen(p.prevFile, file)\n-\t\tp.int(n)           // n >= 0\n-\t\tp.string(file[n:]) // write suffix only\n-\t\tp.prevFile = file\n-\t\tp.int(line)\n-\t}\n-\tp.prevLine = line\n-}\n-\n-func (p *exporter) fileLine(obj types.Object) (file string, line int) {\n-\tif p.fset != nil {\n-\t\tpos := p.fset.Position(obj.Pos())\n-\t\tfile = pos.Filename\n-\t\tline = pos.Line\n-\t}\n-\treturn\n-}\n-\n-func commonPrefixLen(a, b string) int {\n-\tif len(a) > len(b) {\n-\t\ta, b = b, a\n-\t}\n-\t// len(a) <= len(b)\n-\ti := 0\n-\tfor i < len(a) && a[i] == b[i] {\n-\t\ti++\n-\t}\n-\treturn i\n-}\n-\n-func (p *exporter) qualifiedName(obj types.Object) {\n-\tp.string(obj.Name())\n-\tp.pkg(obj.Pkg(), false)\n-}\n-\n-func (p *exporter) typ(t types.Type) {\n-\tif t == nil {\n-\t\tpanic(internalError(\"nil type\"))\n-\t}\n-\n-\t// Possible optimization: Anonymous pointer types *T where\n-\t// T is a named type are common. We could canonicalize all\n-\t// such types *T to a single type PT = *T. This would lead\n-\t// to at most one *T entry in typIndex, and all future *T's\n-\t// would be encoded as the respective index directly. Would\n-\t// save 1 byte (pointerTag) per *T and reduce the typIndex\n-\t// size (at the cost of a canonicalization map). We can do\n-\t// this later, without encoding format change.\n-\n-\t// if we saw the type before, write its index (>= 0)\n-\tif i, ok := p.typIndex[t]; ok {\n-\t\tp.index('T', i)\n-\t\treturn\n-\t}\n-\n-\t// otherwise, remember the type, write the type tag (< 0) and type data\n-\tif trackAllTypes {\n-\t\tif trace {\n-\t\t\tp.tracef(\"T%d = {>\\n\", len(p.typIndex))\n-\t\t\tdefer p.tracef(\"<\\n} \")\n-\t\t}\n-\t\tp.typIndex[t] = len(p.typIndex)\n-\t}\n-\n-\tswitch t := t.(type) {\n-\tcase *types.Named:\n-\t\tif !trackAllTypes {\n-\t\t\t// if we don't track all types, track named types now\n-\t\t\tp.typIndex[t] = len(p.typIndex)\n-\t\t}\n-\n-\t\tp.tag(namedTag)\n-\t\tp.pos(t.Obj())\n-\t\tp.qualifiedName(t.Obj())\n-\t\tp.typ(t.Underlying())\n-\t\tif !types.IsInterface(t) {\n-\t\t\tp.assocMethods(t)\n-\t\t}\n-\n-\tcase *types.Array:\n-\t\tp.tag(arrayTag)\n-\t\tp.int64(t.Len())\n-\t\tp.typ(t.Elem())\n-\n-\tcase *types.Slice:\n-\t\tp.tag(sliceTag)\n-\t\tp.typ(t.Elem())\n-\n-\tcase *dddSlice:\n-\t\tp.tag(dddTag)\n-\t\tp.typ(t.elem)\n-\n-\tcase *types.Struct:\n-\t\tp.tag(structTag)\n-\t\tp.fieldList(t)\n-\n-\tcase *types.Pointer:\n-\t\tp.tag(pointerTag)\n-\t\tp.typ(t.Elem())\n-\n-\tcase *types.Signature:\n-\t\tp.tag(signatureTag)\n-\t\tp.paramList(t.Params(), t.Variadic())\n-\t\tp.paramList(t.Results(), false)\n-\n-\tcase *types.Interface:\n-\t\tp.tag(interfaceTag)\n-\t\tp.iface(t)\n-\n-\tcase *types.Map:\n-\t\tp.tag(mapTag)\n-\t\tp.typ(t.Key())\n-\t\tp.typ(t.Elem())\n-\n-\tcase *types.Chan:\n-\t\tp.tag(chanTag)\n-\t\tp.int(int(3 - t.Dir())) // hack\n-\t\tp.typ(t.Elem())\n-\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected type %T: %s\", t, t))\n-\t}\n-}\n-\n-func (p *exporter) assocMethods(named *types.Named) {\n-\t// Sort methods (for determinism).\n-\tvar methods []*types.Func\n-\tfor i := 0; i < named.NumMethods(); i++ {\n-\t\tmethods = append(methods, named.Method(i))\n-\t}\n-\tsort.Sort(methodsByName(methods))\n-\n-\tp.int(len(methods))\n-\n-\tif trace && methods != nil {\n-\t\tp.tracef(\"associated methods {>\\n\")\n-\t}\n-\n-\tfor i, m := range methods {\n-\t\tif trace && i > 0 {\n-\t\t\tp.tracef(\"\\n\")\n-\t\t}\n-\n-\t\tp.pos(m)\n-\t\tname := m.Name()\n-\t\tp.string(name)\n-\t\tif !exported(name) {\n-\t\t\tp.pkg(m.Pkg(), false)\n-\t\t}\n-\n-\t\tsig := m.Type().(*types.Signature)\n-\t\tp.paramList(types.NewTuple(sig.Recv()), false)\n-\t\tp.paramList(sig.Params(), sig.Variadic())\n-\t\tp.paramList(sig.Results(), false)\n-\t\tp.int(0) // dummy value for go:nointerface pragma - ignored by importer\n-\t}\n-\n-\tif trace && methods != nil {\n-\t\tp.tracef(\"<\\n} \")\n-\t}\n-}\n-\n-type methodsByName []*types.Func\n-\n-func (x methodsByName) Len() int           { return len(x) }\n-func (x methodsByName) Swap(i, j int)      { x[i], x[j] = x[j], x[i] }\n-func (x methodsByName) Less(i, j int) bool { return x[i].Name() < x[j].Name() }\n-\n-func (p *exporter) fieldList(t *types.Struct) {\n-\tif trace && t.NumFields() > 0 {\n-\t\tp.tracef(\"fields {>\\n\")\n-\t\tdefer p.tracef(\"<\\n} \")\n-\t}\n-\n-\tp.int(t.NumFields())\n-\tfor i := 0; i < t.NumFields(); i++ {\n-\t\tif trace && i > 0 {\n-\t\t\tp.tracef(\"\\n\")\n-\t\t}\n-\t\tp.field(t.Field(i))\n-\t\tp.string(t.Tag(i))\n-\t}\n-}\n-\n-func (p *exporter) field(f *types.Var) {\n-\tif !f.IsField() {\n-\t\tpanic(internalError(\"field expected\"))\n-\t}\n-\n-\tp.pos(f)\n-\tp.fieldName(f)\n-\tp.typ(f.Type())\n-}\n-\n-func (p *exporter) iface(t *types.Interface) {\n-\t// TODO(gri): enable importer to load embedded interfaces,\n-\t// then emit Embeddeds and ExplicitMethods separately here.\n-\tp.int(0)\n-\n-\tn := t.NumMethods()\n-\tif trace && n > 0 {\n-\t\tp.tracef(\"methods {>\\n\")\n-\t\tdefer p.tracef(\"<\\n} \")\n-\t}\n-\tp.int(n)\n-\tfor i := 0; i < n; i++ {\n-\t\tif trace && i > 0 {\n-\t\t\tp.tracef(\"\\n\")\n-\t\t}\n-\t\tp.method(t.Method(i))\n-\t}\n-}\n-\n-func (p *exporter) method(m *types.Func) {\n-\tsig := m.Type().(*types.Signature)\n-\tif sig.Recv() == nil {\n-\t\tpanic(internalError(\"method expected\"))\n-\t}\n-\n-\tp.pos(m)\n-\tp.string(m.Name())\n-\tif m.Name() != \"_\" && !ast.IsExported(m.Name()) {\n-\t\tp.pkg(m.Pkg(), false)\n-\t}\n-\n-\t// interface method; no need to encode receiver.\n-\tp.paramList(sig.Params(), sig.Variadic())\n-\tp.paramList(sig.Results(), false)\n-}\n-\n-func (p *exporter) fieldName(f *types.Var) {\n-\tname := f.Name()\n-\n-\tif f.Anonymous() {\n-\t\t// anonymous field - we distinguish between 3 cases:\n-\t\t// 1) field name matches base type name and is exported\n-\t\t// 2) field name matches base type name and is not exported\n-\t\t// 3) field name doesn't match base type name (alias name)\n-\t\tbname := basetypeName(f.Type())\n-\t\tif name == bname {\n-\t\t\tif ast.IsExported(name) {\n-\t\t\t\tname = \"\" // 1) we don't need to know the field name or package\n-\t\t\t} else {\n-\t\t\t\tname = \"?\" // 2) use unexported name \"?\" to force package export\n-\t\t\t}\n-\t\t} else {\n-\t\t\t// 3) indicate alias and export name as is\n-\t\t\t// (this requires an extra \"@\" but this is a rare case)\n-\t\t\tp.string(\"@\")\n-\t\t}\n-\t}\n-\n-\tp.string(name)\n-\tif name != \"\" && !ast.IsExported(name) {\n-\t\tp.pkg(f.Pkg(), false)\n-\t}\n-}\n-\n-func basetypeName(typ types.Type) string {\n-\tswitch typ := deref(typ).(type) {\n-\tcase *types.Basic:\n-\t\treturn typ.Name()\n-\tcase *types.Named:\n-\t\treturn typ.Obj().Name()\n-\tdefault:\n-\t\treturn \"\" // unnamed type\n-\t}\n-}\n-\n-func (p *exporter) paramList(params *types.Tuple, variadic bool) {\n-\t// use negative length to indicate unnamed parameters\n-\t// (look at the first parameter only since either all\n-\t// names are present or all are absent)\n-\tn := params.Len()\n-\tif n > 0 && params.At(0).Name() == \"\" {\n-\t\tn = -n\n-\t}\n-\tp.int(n)\n-\tfor i := 0; i < params.Len(); i++ {\n-\t\tq := params.At(i)\n-\t\tt := q.Type()\n-\t\tif variadic && i == params.Len()-1 {\n-\t\t\tt = &dddSlice{t.(*types.Slice).Elem()}\n-\t\t}\n-\t\tp.typ(t)\n-\t\tif n > 0 {\n-\t\t\tname := q.Name()\n-\t\t\tp.string(name)\n-\t\t\tif name != \"_\" {\n-\t\t\t\tp.pkg(q.Pkg(), false)\n-\t\t\t}\n-\t\t}\n-\t\tp.string(\"\") // no compiler-specific info\n-\t}\n-}\n-\n-func (p *exporter) value(x constant.Value) {\n-\tif trace {\n-\t\tp.tracef(\"= \")\n-\t}\n-\n-\tswitch x.Kind() {\n-\tcase constant.Bool:\n-\t\ttag := falseTag\n-\t\tif constant.BoolVal(x) {\n-\t\t\ttag = trueTag\n-\t\t}\n-\t\tp.tag(tag)\n-\n-\tcase constant.Int:\n-\t\tif v, exact := constant.Int64Val(x); exact {\n-\t\t\t// common case: x fits into an int64 - use compact encoding\n-\t\t\tp.tag(int64Tag)\n-\t\t\tp.int64(v)\n-\t\t\treturn\n-\t\t}\n-\t\t// uncommon case: large x - use float encoding\n-\t\t// (powers of 2 will be encoded efficiently with exponent)\n-\t\tp.tag(floatTag)\n-\t\tp.float(constant.ToFloat(x))\n-\n-\tcase constant.Float:\n-\t\tp.tag(floatTag)\n-\t\tp.float(x)\n-\n-\tcase constant.Complex:\n-\t\tp.tag(complexTag)\n-\t\tp.float(constant.Real(x))\n-\t\tp.float(constant.Imag(x))\n-\n-\tcase constant.String:\n-\t\tp.tag(stringTag)\n-\t\tp.string(constant.StringVal(x))\n-\n-\tcase constant.Unknown:\n-\t\t// package contains type errors\n-\t\tp.tag(unknownTag)\n-\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected value %v (%T)\", x, x))\n-\t}\n-}\n-\n-func (p *exporter) float(x constant.Value) {\n-\tif x.Kind() != constant.Float {\n-\t\tpanic(internalErrorf(\"unexpected constant %v, want float\", x))\n-\t}\n-\t// extract sign (there is no -0)\n-\tsign := constant.Sign(x)\n-\tif sign == 0 {\n-\t\t// x == 0\n-\t\tp.int(0)\n-\t\treturn\n-\t}\n-\t// x != 0\n-\n-\tvar f big.Float\n-\tif v, exact := constant.Float64Val(x); exact {\n-\t\t// float64\n-\t\tf.SetFloat64(v)\n-\t} else if num, denom := constant.Num(x), constant.Denom(x); num.Kind() == constant.Int {\n-\t\t// TODO(gri): add big.Rat accessor to constant.Value.\n-\t\tr := valueToRat(num)\n-\t\tf.SetRat(r.Quo(r, valueToRat(denom)))\n-\t} else {\n-\t\t// Value too large to represent as a fraction => inaccessible.\n-\t\t// TODO(gri): add big.Float accessor to constant.Value.\n-\t\tf.SetFloat64(math.MaxFloat64) // FIXME\n-\t}\n-\n-\t// extract exponent such that 0.5 <= m < 1.0\n-\tvar m big.Float\n-\texp := f.MantExp(&m)\n-\n-\t// extract mantissa as *big.Int\n-\t// - set exponent large enough so mant satisfies mant.IsInt()\n-\t// - get *big.Int from mant\n-\tm.SetMantExp(&m, int(m.MinPrec()))\n-\tmant, acc := m.Int(nil)\n-\tif acc != big.Exact {\n-\t\tpanic(internalError(\"internal error\"))\n-\t}\n-\n-\tp.int(sign)\n-\tp.int(exp)\n-\tp.string(string(mant.Bytes()))\n-}\n-\n-func valueToRat(x constant.Value) *big.Rat {\n-\t// Convert little-endian to big-endian.\n-\t// I can't believe this is necessary.\n-\tbytes := constant.Bytes(x)\n-\tfor i := 0; i < len(bytes)/2; i++ {\n-\t\tbytes[i], bytes[len(bytes)-1-i] = bytes[len(bytes)-1-i], bytes[i]\n-\t}\n-\treturn new(big.Rat).SetInt(new(big.Int).SetBytes(bytes))\n-}\n-\n-func (p *exporter) bool(b bool) bool {\n-\tif trace {\n-\t\tp.tracef(\"[\")\n-\t\tdefer p.tracef(\"= %v] \", b)\n-\t}\n-\n-\tx := 0\n-\tif b {\n-\t\tx = 1\n-\t}\n-\tp.int(x)\n-\treturn b\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Low-level encoders\n-\n-func (p *exporter) index(marker byte, index int) {\n-\tif index < 0 {\n-\t\tpanic(internalError(\"invalid index < 0\"))\n-\t}\n-\tif debugFormat {\n-\t\tp.marker('t')\n-\t}\n-\tif trace {\n-\t\tp.tracef(\"%c%d \", marker, index)\n-\t}\n-\tp.rawInt64(int64(index))\n-}\n-\n-func (p *exporter) tag(tag int) {\n-\tif tag >= 0 {\n-\t\tpanic(internalError(\"invalid tag >= 0\"))\n-\t}\n-\tif debugFormat {\n-\t\tp.marker('t')\n-\t}\n-\tif trace {\n-\t\tp.tracef(\"%s \", tagString[-tag])\n-\t}\n-\tp.rawInt64(int64(tag))\n-}\n-\n-func (p *exporter) int(x int) {\n-\tp.int64(int64(x))\n-}\n-\n-func (p *exporter) int64(x int64) {\n-\tif debugFormat {\n-\t\tp.marker('i')\n-\t}\n-\tif trace {\n-\t\tp.tracef(\"%d \", x)\n-\t}\n-\tp.rawInt64(x)\n-}\n-\n-func (p *exporter) string(s string) {\n-\tif debugFormat {\n-\t\tp.marker('s')\n-\t}\n-\tif trace {\n-\t\tp.tracef(\"%q \", s)\n-\t}\n-\t// if we saw the string before, write its index (>= 0)\n-\t// (the empty string is mapped to 0)\n-\tif i, ok := p.strIndex[s]; ok {\n-\t\tp.rawInt64(int64(i))\n-\t\treturn\n-\t}\n-\t// otherwise, remember string and write its negative length and bytes\n-\tp.strIndex[s] = len(p.strIndex)\n-\tp.rawInt64(-int64(len(s)))\n-\tfor i := 0; i < len(s); i++ {\n-\t\tp.rawByte(s[i])\n-\t}\n-}\n-\n-// marker emits a marker byte and position information which makes\n-// it easy for a reader to detect if it is \"out of sync\". Used for\n-// debugFormat format only.\n-func (p *exporter) marker(m byte) {\n-\tp.rawByte(m)\n-\t// Enable this for help tracking down the location\n-\t// of an incorrect marker when running in debugFormat.\n-\tif false && trace {\n-\t\tp.tracef(\"#%d \", p.written)\n-\t}\n-\tp.rawInt64(int64(p.written))\n-}\n-\n-// rawInt64 should only be used by low-level encoders.\n-func (p *exporter) rawInt64(x int64) {\n-\tvar tmp [binary.MaxVarintLen64]byte\n-\tn := binary.PutVarint(tmp[:], x)\n-\tfor i := 0; i < n; i++ {\n-\t\tp.rawByte(tmp[i])\n-\t}\n-}\n-\n-// rawStringln should only be used to emit the initial version string.\n-func (p *exporter) rawStringln(s string) {\n-\tfor i := 0; i < len(s); i++ {\n-\t\tp.rawByte(s[i])\n-\t}\n-\tp.rawByte('\\n')\n-}\n-\n-// rawByte is the bottleneck interface to write to p.out.\n-// rawByte escapes b as follows (any encoding does that\n-// hides '$'):\n-//\n-//\t'$'  => '|' 'S'\n-//\t'|'  => '|' '|'\n-//\n-// Necessary so other tools can find the end of the\n-// export data by searching for \"$$\".\n-// rawByte should only be used by low-level encoders.\n-func (p *exporter) rawByte(b byte) {\n-\tswitch b {\n-\tcase '$':\n-\t\t// write '$' as '|' 'S'\n-\t\tb = 'S'\n-\t\tfallthrough\n-\tcase '|':\n-\t\t// write '|' as '|' '|'\n-\t\tp.out.WriteByte('|')\n-\t\tp.written++\n-\t}\n-\tp.out.WriteByte(b)\n-\tp.written++\n-}\n-\n-// tracef is like fmt.Printf but it rewrites the format string\n-// to take care of indentation.\n-func (p *exporter) tracef(format string, args ...interface{}) {\n-\tif strings.ContainsAny(format, \"<>\\n\") {\n-\t\tvar buf bytes.Buffer\n-\t\tfor i := 0; i < len(format); i++ {\n-\t\t\t// no need to deal with runes\n-\t\t\tch := format[i]\n-\t\t\tswitch ch {\n-\t\t\tcase '>':\n-\t\t\t\tp.indent++\n-\t\t\t\tcontinue\n-\t\t\tcase '<':\n-\t\t\t\tp.indent--\n-\t\t\t\tcontinue\n-\t\t\t}\n-\t\t\tbuf.WriteByte(ch)\n-\t\t\tif ch == '\\n' {\n-\t\t\t\tfor j := p.indent; j > 0; j-- {\n-\t\t\t\t\tbuf.WriteString(\".  \")\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tformat = buf.String()\n-\t}\n-\tfmt.Printf(format, args...)\n-}\n-\n-// Debugging support.\n-// (tagString is only used when tracing is enabled)\n-var tagString = [...]string{\n-\t// Packages\n-\t-packageTag: \"package\",\n-\n-\t// Types\n-\t-namedTag:     \"named type\",\n-\t-arrayTag:     \"array\",\n-\t-sliceTag:     \"slice\",\n-\t-dddTag:       \"ddd\",\n-\t-structTag:    \"struct\",\n-\t-pointerTag:   \"pointer\",\n-\t-signatureTag: \"signature\",\n-\t-interfaceTag: \"interface\",\n-\t-mapTag:       \"map\",\n-\t-chanTag:      \"chan\",\n-\n-\t// Values\n-\t-falseTag:    \"false\",\n-\t-trueTag:     \"true\",\n-\t-int64Tag:    \"int64\",\n-\t-floatTag:    \"float\",\n-\t-fractionTag: \"fraction\",\n-\t-complexTag:  \"complex\",\n-\t-stringTag:   \"string\",\n-\t-unknownTag:  \"unknown\",\n-\n-\t// Type aliases\n-\t-aliasTag: \"alias\",\n-}"
    },
    {
      "sha": "e9f73d14a182e18631a4968d3942672cab5462db",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/bimport.go",
      "status": "removed",
      "additions": 0,
      "deletions": 1039,
      "changes": 1039,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bimport.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bimport.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/bimport.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,1039 +0,0 @@\n-// Copyright 2015 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// This file is a copy of $GOROOT/src/go/internal/gcimporter/bimport.go.\n-\n-package gcimporter\n-\n-import (\n-\t\"encoding/binary\"\n-\t\"fmt\"\n-\t\"go/constant\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"sort\"\n-\t\"strconv\"\n-\t\"strings\"\n-\t\"sync\"\n-\t\"unicode\"\n-\t\"unicode/utf8\"\n-)\n-\n-type importer struct {\n-\timports    map[string]*types.Package\n-\tdata       []byte\n-\timportpath string\n-\tbuf        []byte // for reading strings\n-\tversion    int    // export format version\n-\n-\t// object lists\n-\tstrList       []string           // in order of appearance\n-\tpathList      []string           // in order of appearance\n-\tpkgList       []*types.Package   // in order of appearance\n-\ttypList       []types.Type       // in order of appearance\n-\tinterfaceList []*types.Interface // for delayed completion only\n-\ttrackAllTypes bool\n-\n-\t// position encoding\n-\tposInfoFormat bool\n-\tprevFile      string\n-\tprevLine      int\n-\tfake          fakeFileSet\n-\n-\t// debugging support\n-\tdebugFormat bool\n-\tread        int // bytes read\n-}\n-\n-// BImportData imports a package from the serialized package data\n-// and returns the number of bytes consumed and a reference to the package.\n-// If the export data version is not recognized or the format is otherwise\n-// compromised, an error is returned.\n-func BImportData(fset *token.FileSet, imports map[string]*types.Package, data []byte, path string) (_ int, pkg *types.Package, err error) {\n-\t// catch panics and return them as errors\n-\tconst currentVersion = 6\n-\tversion := -1 // unknown version\n-\tdefer func() {\n-\t\tif e := recover(); e != nil {\n-\t\t\t// Return a (possibly nil or incomplete) package unchanged (see #16088).\n-\t\t\tif version > currentVersion {\n-\t\t\t\terr = fmt.Errorf(\"cannot import %q (%v), export data is newer version - update tool\", path, e)\n-\t\t\t} else {\n-\t\t\t\terr = fmt.Errorf(\"cannot import %q (%v), possibly version skew - reinstall package\", path, e)\n-\t\t\t}\n-\t\t}\n-\t}()\n-\n-\tp := importer{\n-\t\timports:    imports,\n-\t\tdata:       data,\n-\t\timportpath: path,\n-\t\tversion:    version,\n-\t\tstrList:    []string{\"\"}, // empty string is mapped to 0\n-\t\tpathList:   []string{\"\"}, // empty string is mapped to 0\n-\t\tfake: fakeFileSet{\n-\t\t\tfset:  fset,\n-\t\t\tfiles: make(map[string]*token.File),\n-\t\t},\n-\t}\n-\n-\t// read version info\n-\tvar versionstr string\n-\tif b := p.rawByte(); b == 'c' || b == 'd' {\n-\t\t// Go1.7 encoding; first byte encodes low-level\n-\t\t// encoding format (compact vs debug).\n-\t\t// For backward-compatibility only (avoid problems with\n-\t\t// old installed packages). Newly compiled packages use\n-\t\t// the extensible format string.\n-\t\t// TODO(gri) Remove this support eventually; after Go1.8.\n-\t\tif b == 'd' {\n-\t\t\tp.debugFormat = true\n-\t\t}\n-\t\tp.trackAllTypes = p.rawByte() == 'a'\n-\t\tp.posInfoFormat = p.int() != 0\n-\t\tversionstr = p.string()\n-\t\tif versionstr == \"v1\" {\n-\t\t\tversion = 0\n-\t\t}\n-\t} else {\n-\t\t// Go1.8 extensible encoding\n-\t\t// read version string and extract version number (ignore anything after the version number)\n-\t\tversionstr = p.rawStringln(b)\n-\t\tif s := strings.SplitN(versionstr, \" \", 3); len(s) >= 2 && s[0] == \"version\" {\n-\t\t\tif v, err := strconv.Atoi(s[1]); err == nil && v > 0 {\n-\t\t\t\tversion = v\n-\t\t\t}\n-\t\t}\n-\t}\n-\tp.version = version\n-\n-\t// read version specific flags - extend as necessary\n-\tswitch p.version {\n-\t// case currentVersion:\n-\t// \t...\n-\t//\tfallthrough\n-\tcase currentVersion, 5, 4, 3, 2, 1:\n-\t\tp.debugFormat = p.rawStringln(p.rawByte()) == \"debug\"\n-\t\tp.trackAllTypes = p.int() != 0\n-\t\tp.posInfoFormat = p.int() != 0\n-\tcase 0:\n-\t\t// Go1.7 encoding format - nothing to do here\n-\tdefault:\n-\t\terrorf(\"unknown bexport format version %d (%q)\", p.version, versionstr)\n-\t}\n-\n-\t// --- generic export data ---\n-\n-\t// populate typList with predeclared \"known\" types\n-\tp.typList = append(p.typList, predeclared()...)\n-\n-\t// read package data\n-\tpkg = p.pkg()\n-\n-\t// read objects of phase 1 only (see cmd/compile/internal/gc/bexport.go)\n-\tobjcount := 0\n-\tfor {\n-\t\ttag := p.tagOrIndex()\n-\t\tif tag == endTag {\n-\t\t\tbreak\n-\t\t}\n-\t\tp.obj(tag)\n-\t\tobjcount++\n-\t}\n-\n-\t// self-verification\n-\tif count := p.int(); count != objcount {\n-\t\terrorf(\"got %d objects; want %d\", objcount, count)\n-\t}\n-\n-\t// ignore compiler-specific import data\n-\n-\t// complete interfaces\n-\t// TODO(gri) re-investigate if we still need to do this in a delayed fashion\n-\tfor _, typ := range p.interfaceList {\n-\t\ttyp.Complete()\n-\t}\n-\n-\t// record all referenced packages as imports\n-\tlist := append(([]*types.Package)(nil), p.pkgList[1:]...)\n-\tsort.Sort(byPath(list))\n-\tpkg.SetImports(list)\n-\n-\t// package was imported completely and without errors\n-\tpkg.MarkComplete()\n-\n-\treturn p.read, pkg, nil\n-}\n-\n-func errorf(format string, args ...interface{}) {\n-\tpanic(fmt.Sprintf(format, args...))\n-}\n-\n-func (p *importer) pkg() *types.Package {\n-\t// if the package was seen before, i is its index (>= 0)\n-\ti := p.tagOrIndex()\n-\tif i >= 0 {\n-\t\treturn p.pkgList[i]\n-\t}\n-\n-\t// otherwise, i is the package tag (< 0)\n-\tif i != packageTag {\n-\t\terrorf(\"unexpected package tag %d version %d\", i, p.version)\n-\t}\n-\n-\t// read package data\n-\tname := p.string()\n-\tvar path string\n-\tif p.version >= 5 {\n-\t\tpath = p.path()\n-\t} else {\n-\t\tpath = p.string()\n-\t}\n-\tif p.version >= 6 {\n-\t\tp.int() // package height; unused by go/types\n-\t}\n-\n-\t// we should never see an empty package name\n-\tif name == \"\" {\n-\t\terrorf(\"empty package name in import\")\n-\t}\n-\n-\t// an empty path denotes the package we are currently importing;\n-\t// it must be the first package we see\n-\tif (path == \"\") != (len(p.pkgList) == 0) {\n-\t\terrorf(\"package path %q for pkg index %d\", path, len(p.pkgList))\n-\t}\n-\n-\t// if the package was imported before, use that one; otherwise create a new one\n-\tif path == \"\" {\n-\t\tpath = p.importpath\n-\t}\n-\tpkg := p.imports[path]\n-\tif pkg == nil {\n-\t\tpkg = types.NewPackage(path, name)\n-\t\tp.imports[path] = pkg\n-\t} else if pkg.Name() != name {\n-\t\terrorf(\"conflicting names %s and %s for package %q\", pkg.Name(), name, path)\n-\t}\n-\tp.pkgList = append(p.pkgList, pkg)\n-\n-\treturn pkg\n-}\n-\n-// objTag returns the tag value for each object kind.\n-func objTag(obj types.Object) int {\n-\tswitch obj.(type) {\n-\tcase *types.Const:\n-\t\treturn constTag\n-\tcase *types.TypeName:\n-\t\treturn typeTag\n-\tcase *types.Var:\n-\t\treturn varTag\n-\tcase *types.Func:\n-\t\treturn funcTag\n-\tdefault:\n-\t\terrorf(\"unexpected object: %v (%T)\", obj, obj) // panics\n-\t\tpanic(\"unreachable\")\n-\t}\n-}\n-\n-func sameObj(a, b types.Object) bool {\n-\t// Because unnamed types are not canonicalized, we cannot simply compare types for\n-\t// (pointer) identity.\n-\t// Ideally we'd check equality of constant values as well, but this is good enough.\n-\treturn objTag(a) == objTag(b) && types.Identical(a.Type(), b.Type())\n-}\n-\n-func (p *importer) declare(obj types.Object) {\n-\tpkg := obj.Pkg()\n-\tif alt := pkg.Scope().Insert(obj); alt != nil {\n-\t\t// This can only trigger if we import a (non-type) object a second time.\n-\t\t// Excluding type aliases, this cannot happen because 1) we only import a package\n-\t\t// once; and b) we ignore compiler-specific export data which may contain\n-\t\t// functions whose inlined function bodies refer to other functions that\n-\t\t// were already imported.\n-\t\t// However, type aliases require reexporting the original type, so we need\n-\t\t// to allow it (see also the comment in cmd/compile/internal/gc/bimport.go,\n-\t\t// method importer.obj, switch case importing functions).\n-\t\t// TODO(gri) review/update this comment once the gc compiler handles type aliases.\n-\t\tif !sameObj(obj, alt) {\n-\t\t\terrorf(\"inconsistent import:\\n\\t%v\\npreviously imported as:\\n\\t%v\\n\", obj, alt)\n-\t\t}\n-\t}\n-}\n-\n-func (p *importer) obj(tag int) {\n-\tswitch tag {\n-\tcase constTag:\n-\t\tpos := p.pos()\n-\t\tpkg, name := p.qualifiedName()\n-\t\ttyp := p.typ(nil, nil)\n-\t\tval := p.value()\n-\t\tp.declare(types.NewConst(pos, pkg, name, typ, val))\n-\n-\tcase aliasTag:\n-\t\t// TODO(gri) verify type alias hookup is correct\n-\t\tpos := p.pos()\n-\t\tpkg, name := p.qualifiedName()\n-\t\ttyp := p.typ(nil, nil)\n-\t\tp.declare(types.NewTypeName(pos, pkg, name, typ))\n-\n-\tcase typeTag:\n-\t\tp.typ(nil, nil)\n-\n-\tcase varTag:\n-\t\tpos := p.pos()\n-\t\tpkg, name := p.qualifiedName()\n-\t\ttyp := p.typ(nil, nil)\n-\t\tp.declare(types.NewVar(pos, pkg, name, typ))\n-\n-\tcase funcTag:\n-\t\tpos := p.pos()\n-\t\tpkg, name := p.qualifiedName()\n-\t\tparams, isddd := p.paramList()\n-\t\tresult, _ := p.paramList()\n-\t\tsig := types.NewSignature(nil, params, result, isddd)\n-\t\tp.declare(types.NewFunc(pos, pkg, name, sig))\n-\n-\tdefault:\n-\t\terrorf(\"unexpected object tag %d\", tag)\n-\t}\n-}\n-\n-const deltaNewFile = -64 // see cmd/compile/internal/gc/bexport.go\n-\n-func (p *importer) pos() token.Pos {\n-\tif !p.posInfoFormat {\n-\t\treturn token.NoPos\n-\t}\n-\n-\tfile := p.prevFile\n-\tline := p.prevLine\n-\tdelta := p.int()\n-\tline += delta\n-\tif p.version >= 5 {\n-\t\tif delta == deltaNewFile {\n-\t\t\tif n := p.int(); n >= 0 {\n-\t\t\t\t// file changed\n-\t\t\t\tfile = p.path()\n-\t\t\t\tline = n\n-\t\t\t}\n-\t\t}\n-\t} else {\n-\t\tif delta == 0 {\n-\t\t\tif n := p.int(); n >= 0 {\n-\t\t\t\t// file changed\n-\t\t\t\tfile = p.prevFile[:n] + p.string()\n-\t\t\t\tline = p.int()\n-\t\t\t}\n-\t\t}\n-\t}\n-\tp.prevFile = file\n-\tp.prevLine = line\n-\n-\treturn p.fake.pos(file, line, 0)\n-}\n-\n-// Synthesize a token.Pos\n-type fakeFileSet struct {\n-\tfset  *token.FileSet\n-\tfiles map[string]*token.File\n-}\n-\n-func (s *fakeFileSet) pos(file string, line, column int) token.Pos {\n-\t// TODO(mdempsky): Make use of column.\n-\n-\t// Since we don't know the set of needed file positions, we\n-\t// reserve maxlines positions per file.\n-\tconst maxlines = 64 * 1024\n-\tf := s.files[file]\n-\tif f == nil {\n-\t\tf = s.fset.AddFile(file, -1, maxlines)\n-\t\ts.files[file] = f\n-\t\t// Allocate the fake linebreak indices on first use.\n-\t\t// TODO(adonovan): opt: save ~512KB using a more complex scheme?\n-\t\tfakeLinesOnce.Do(func() {\n-\t\t\tfakeLines = make([]int, maxlines)\n-\t\t\tfor i := range fakeLines {\n-\t\t\t\tfakeLines[i] = i\n-\t\t\t}\n-\t\t})\n-\t\tf.SetLines(fakeLines)\n-\t}\n-\n-\tif line > maxlines {\n-\t\tline = 1\n-\t}\n-\n-\t// Treat the file as if it contained only newlines\n-\t// and column=1: use the line number as the offset.\n-\treturn f.Pos(line - 1)\n-}\n-\n-var (\n-\tfakeLines     []int\n-\tfakeLinesOnce sync.Once\n-)\n-\n-func (p *importer) qualifiedName() (pkg *types.Package, name string) {\n-\tname = p.string()\n-\tpkg = p.pkg()\n-\treturn\n-}\n-\n-func (p *importer) record(t types.Type) {\n-\tp.typList = append(p.typList, t)\n-}\n-\n-// A dddSlice is a types.Type representing ...T parameters.\n-// It only appears for parameter types and does not escape\n-// the importer.\n-type dddSlice struct {\n-\telem types.Type\n-}\n-\n-func (t *dddSlice) Underlying() types.Type { return t }\n-func (t *dddSlice) String() string         { return \"...\" + t.elem.String() }\n-\n-// parent is the package which declared the type; parent == nil means\n-// the package currently imported. The parent package is needed for\n-// exported struct fields and interface methods which don't contain\n-// explicit package information in the export data.\n-//\n-// A non-nil tname is used as the \"owner\" of the result type; i.e.,\n-// the result type is the underlying type of tname. tname is used\n-// to give interface methods a named receiver type where possible.\n-func (p *importer) typ(parent *types.Package, tname *types.Named) types.Type {\n-\t// if the type was seen before, i is its index (>= 0)\n-\ti := p.tagOrIndex()\n-\tif i >= 0 {\n-\t\treturn p.typList[i]\n-\t}\n-\n-\t// otherwise, i is the type tag (< 0)\n-\tswitch i {\n-\tcase namedTag:\n-\t\t// read type object\n-\t\tpos := p.pos()\n-\t\tparent, name := p.qualifiedName()\n-\t\tscope := parent.Scope()\n-\t\tobj := scope.Lookup(name)\n-\n-\t\t// if the object doesn't exist yet, create and insert it\n-\t\tif obj == nil {\n-\t\t\tobj = types.NewTypeName(pos, parent, name, nil)\n-\t\t\tscope.Insert(obj)\n-\t\t}\n-\n-\t\tif _, ok := obj.(*types.TypeName); !ok {\n-\t\t\terrorf(\"pkg = %s, name = %s => %s\", parent, name, obj)\n-\t\t}\n-\n-\t\t// associate new named type with obj if it doesn't exist yet\n-\t\tt0 := types.NewNamed(obj.(*types.TypeName), nil, nil)\n-\n-\t\t// but record the existing type, if any\n-\t\ttname := obj.Type().(*types.Named) // tname is either t0 or the existing type\n-\t\tp.record(tname)\n-\n-\t\t// read underlying type\n-\t\tt0.SetUnderlying(p.typ(parent, t0))\n-\n-\t\t// interfaces don't have associated methods\n-\t\tif types.IsInterface(t0) {\n-\t\t\treturn tname\n-\t\t}\n-\n-\t\t// read associated methods\n-\t\tfor i := p.int(); i > 0; i-- {\n-\t\t\t// TODO(gri) replace this with something closer to fieldName\n-\t\t\tpos := p.pos()\n-\t\t\tname := p.string()\n-\t\t\tif !exported(name) {\n-\t\t\t\tp.pkg()\n-\t\t\t}\n-\n-\t\t\trecv, _ := p.paramList() // TODO(gri) do we need a full param list for the receiver?\n-\t\t\tparams, isddd := p.paramList()\n-\t\t\tresult, _ := p.paramList()\n-\t\t\tp.int() // go:nointerface pragma - discarded\n-\n-\t\t\tsig := types.NewSignature(recv.At(0), params, result, isddd)\n-\t\t\tt0.AddMethod(types.NewFunc(pos, parent, name, sig))\n-\t\t}\n-\n-\t\treturn tname\n-\n-\tcase arrayTag:\n-\t\tt := new(types.Array)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\tn := p.int64()\n-\t\t*t = *types.NewArray(p.typ(parent, nil), n)\n-\t\treturn t\n-\n-\tcase sliceTag:\n-\t\tt := new(types.Slice)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\t*t = *types.NewSlice(p.typ(parent, nil))\n-\t\treturn t\n-\n-\tcase dddTag:\n-\t\tt := new(dddSlice)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\tt.elem = p.typ(parent, nil)\n-\t\treturn t\n-\n-\tcase structTag:\n-\t\tt := new(types.Struct)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\t*t = *types.NewStruct(p.fieldList(parent))\n-\t\treturn t\n-\n-\tcase pointerTag:\n-\t\tt := new(types.Pointer)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\t*t = *types.NewPointer(p.typ(parent, nil))\n-\t\treturn t\n-\n-\tcase signatureTag:\n-\t\tt := new(types.Signature)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\tparams, isddd := p.paramList()\n-\t\tresult, _ := p.paramList()\n-\t\t*t = *types.NewSignature(nil, params, result, isddd)\n-\t\treturn t\n-\n-\tcase interfaceTag:\n-\t\t// Create a dummy entry in the type list. This is safe because we\n-\t\t// cannot expect the interface type to appear in a cycle, as any\n-\t\t// such cycle must contain a named type which would have been\n-\t\t// first defined earlier.\n-\t\t// TODO(gri) Is this still true now that we have type aliases?\n-\t\t// See issue #23225.\n-\t\tn := len(p.typList)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(nil)\n-\t\t}\n-\n-\t\tvar embeddeds []types.Type\n-\t\tfor n := p.int(); n > 0; n-- {\n-\t\t\tp.pos()\n-\t\t\tembeddeds = append(embeddeds, p.typ(parent, nil))\n-\t\t}\n-\n-\t\tt := newInterface(p.methodList(parent, tname), embeddeds)\n-\t\tp.interfaceList = append(p.interfaceList, t)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.typList[n] = t\n-\t\t}\n-\t\treturn t\n-\n-\tcase mapTag:\n-\t\tt := new(types.Map)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\tkey := p.typ(parent, nil)\n-\t\tval := p.typ(parent, nil)\n-\t\t*t = *types.NewMap(key, val)\n-\t\treturn t\n-\n-\tcase chanTag:\n-\t\tt := new(types.Chan)\n-\t\tif p.trackAllTypes {\n-\t\t\tp.record(t)\n-\t\t}\n-\n-\t\tdir := chanDir(p.int())\n-\t\tval := p.typ(parent, nil)\n-\t\t*t = *types.NewChan(dir, val)\n-\t\treturn t\n-\n-\tdefault:\n-\t\terrorf(\"unexpected type tag %d\", i) // panics\n-\t\tpanic(\"unreachable\")\n-\t}\n-}\n-\n-func chanDir(d int) types.ChanDir {\n-\t// tag values must match the constants in cmd/compile/internal/gc/go.go\n-\tswitch d {\n-\tcase 1 /* Crecv */ :\n-\t\treturn types.RecvOnly\n-\tcase 2 /* Csend */ :\n-\t\treturn types.SendOnly\n-\tcase 3 /* Cboth */ :\n-\t\treturn types.SendRecv\n-\tdefault:\n-\t\terrorf(\"unexpected channel dir %d\", d)\n-\t\treturn 0\n-\t}\n-}\n-\n-func (p *importer) fieldList(parent *types.Package) (fields []*types.Var, tags []string) {\n-\tif n := p.int(); n > 0 {\n-\t\tfields = make([]*types.Var, n)\n-\t\ttags = make([]string, n)\n-\t\tfor i := range fields {\n-\t\t\tfields[i], tags[i] = p.field(parent)\n-\t\t}\n-\t}\n-\treturn\n-}\n-\n-func (p *importer) field(parent *types.Package) (*types.Var, string) {\n-\tpos := p.pos()\n-\tpkg, name, alias := p.fieldName(parent)\n-\ttyp := p.typ(parent, nil)\n-\ttag := p.string()\n-\n-\tanonymous := false\n-\tif name == \"\" {\n-\t\t// anonymous field - typ must be T or *T and T must be a type name\n-\t\tswitch typ := deref(typ).(type) {\n-\t\tcase *types.Basic: // basic types are named types\n-\t\t\tpkg = nil // // objects defined in Universe scope have no package\n-\t\t\tname = typ.Name()\n-\t\tcase *types.Named:\n-\t\t\tname = typ.Obj().Name()\n-\t\tdefault:\n-\t\t\terrorf(\"named base type expected\")\n-\t\t}\n-\t\tanonymous = true\n-\t} else if alias {\n-\t\t// anonymous field: we have an explicit name because it's an alias\n-\t\tanonymous = true\n-\t}\n-\n-\treturn types.NewField(pos, pkg, name, typ, anonymous), tag\n-}\n-\n-func (p *importer) methodList(parent *types.Package, baseType *types.Named) (methods []*types.Func) {\n-\tif n := p.int(); n > 0 {\n-\t\tmethods = make([]*types.Func, n)\n-\t\tfor i := range methods {\n-\t\t\tmethods[i] = p.method(parent, baseType)\n-\t\t}\n-\t}\n-\treturn\n-}\n-\n-func (p *importer) method(parent *types.Package, baseType *types.Named) *types.Func {\n-\tpos := p.pos()\n-\tpkg, name, _ := p.fieldName(parent)\n-\t// If we don't have a baseType, use a nil receiver.\n-\t// A receiver using the actual interface type (which\n-\t// we don't know yet) will be filled in when we call\n-\t// types.Interface.Complete.\n-\tvar recv *types.Var\n-\tif baseType != nil {\n-\t\trecv = types.NewVar(token.NoPos, parent, \"\", baseType)\n-\t}\n-\tparams, isddd := p.paramList()\n-\tresult, _ := p.paramList()\n-\tsig := types.NewSignature(recv, params, result, isddd)\n-\treturn types.NewFunc(pos, pkg, name, sig)\n-}\n-\n-func (p *importer) fieldName(parent *types.Package) (pkg *types.Package, name string, alias bool) {\n-\tname = p.string()\n-\tpkg = parent\n-\tif pkg == nil {\n-\t\t// use the imported package instead\n-\t\tpkg = p.pkgList[0]\n-\t}\n-\tif p.version == 0 && name == \"_\" {\n-\t\t// version 0 didn't export a package for _ fields\n-\t\treturn\n-\t}\n-\tswitch name {\n-\tcase \"\":\n-\t\t// 1) field name matches base type name and is exported: nothing to do\n-\tcase \"?\":\n-\t\t// 2) field name matches base type name and is not exported: need package\n-\t\tname = \"\"\n-\t\tpkg = p.pkg()\n-\tcase \"@\":\n-\t\t// 3) field name doesn't match type name (alias)\n-\t\tname = p.string()\n-\t\talias = true\n-\t\tfallthrough\n-\tdefault:\n-\t\tif !exported(name) {\n-\t\t\tpkg = p.pkg()\n-\t\t}\n-\t}\n-\treturn\n-}\n-\n-func (p *importer) paramList() (*types.Tuple, bool) {\n-\tn := p.int()\n-\tif n == 0 {\n-\t\treturn nil, false\n-\t}\n-\t// negative length indicates unnamed parameters\n-\tnamed := true\n-\tif n < 0 {\n-\t\tn = -n\n-\t\tnamed = false\n-\t}\n-\t// n > 0\n-\tparams := make([]*types.Var, n)\n-\tisddd := false\n-\tfor i := range params {\n-\t\tparams[i], isddd = p.param(named)\n-\t}\n-\treturn types.NewTuple(params...), isddd\n-}\n-\n-func (p *importer) param(named bool) (*types.Var, bool) {\n-\tt := p.typ(nil, nil)\n-\ttd, isddd := t.(*dddSlice)\n-\tif isddd {\n-\t\tt = types.NewSlice(td.elem)\n-\t}\n-\n-\tvar pkg *types.Package\n-\tvar name string\n-\tif named {\n-\t\tname = p.string()\n-\t\tif name == \"\" {\n-\t\t\terrorf(\"expected named parameter\")\n-\t\t}\n-\t\tif name != \"_\" {\n-\t\t\tpkg = p.pkg()\n-\t\t}\n-\t\tif i := strings.Index(name, \"\"); i > 0 {\n-\t\t\tname = name[:i] // cut off gc-specific parameter numbering\n-\t\t}\n-\t}\n-\n-\t// read and discard compiler-specific info\n-\tp.string()\n-\n-\treturn types.NewVar(token.NoPos, pkg, name, t), isddd\n-}\n-\n-func exported(name string) bool {\n-\tch, _ := utf8.DecodeRuneInString(name)\n-\treturn unicode.IsUpper(ch)\n-}\n-\n-func (p *importer) value() constant.Value {\n-\tswitch tag := p.tagOrIndex(); tag {\n-\tcase falseTag:\n-\t\treturn constant.MakeBool(false)\n-\tcase trueTag:\n-\t\treturn constant.MakeBool(true)\n-\tcase int64Tag:\n-\t\treturn constant.MakeInt64(p.int64())\n-\tcase floatTag:\n-\t\treturn p.float()\n-\tcase complexTag:\n-\t\tre := p.float()\n-\t\tim := p.float()\n-\t\treturn constant.BinaryOp(re, token.ADD, constant.MakeImag(im))\n-\tcase stringTag:\n-\t\treturn constant.MakeString(p.string())\n-\tcase unknownTag:\n-\t\treturn constant.MakeUnknown()\n-\tdefault:\n-\t\terrorf(\"unexpected value tag %d\", tag) // panics\n-\t\tpanic(\"unreachable\")\n-\t}\n-}\n-\n-func (p *importer) float() constant.Value {\n-\tsign := p.int()\n-\tif sign == 0 {\n-\t\treturn constant.MakeInt64(0)\n-\t}\n-\n-\texp := p.int()\n-\tmant := []byte(p.string()) // big endian\n-\n-\t// remove leading 0's if any\n-\tfor len(mant) > 0 && mant[0] == 0 {\n-\t\tmant = mant[1:]\n-\t}\n-\n-\t// convert to little endian\n-\t// TODO(gri) go/constant should have a more direct conversion function\n-\t//           (e.g., once it supports a big.Float based implementation)\n-\tfor i, j := 0, len(mant)-1; i < j; i, j = i+1, j-1 {\n-\t\tmant[i], mant[j] = mant[j], mant[i]\n-\t}\n-\n-\t// adjust exponent (constant.MakeFromBytes creates an integer value,\n-\t// but mant represents the mantissa bits such that 0.5 <= mant < 1.0)\n-\texp -= len(mant) << 3\n-\tif len(mant) > 0 {\n-\t\tfor msd := mant[len(mant)-1]; msd&0x80 == 0; msd <<= 1 {\n-\t\t\texp++\n-\t\t}\n-\t}\n-\n-\tx := constant.MakeFromBytes(mant)\n-\tswitch {\n-\tcase exp < 0:\n-\t\td := constant.Shift(constant.MakeInt64(1), token.SHL, uint(-exp))\n-\t\tx = constant.BinaryOp(x, token.QUO, d)\n-\tcase exp > 0:\n-\t\tx = constant.Shift(x, token.SHL, uint(exp))\n-\t}\n-\n-\tif sign < 0 {\n-\t\tx = constant.UnaryOp(token.SUB, x, 0)\n-\t}\n-\treturn x\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Low-level decoders\n-\n-func (p *importer) tagOrIndex() int {\n-\tif p.debugFormat {\n-\t\tp.marker('t')\n-\t}\n-\n-\treturn int(p.rawInt64())\n-}\n-\n-func (p *importer) int() int {\n-\tx := p.int64()\n-\tif int64(int(x)) != x {\n-\t\terrorf(\"exported integer too large\")\n-\t}\n-\treturn int(x)\n-}\n-\n-func (p *importer) int64() int64 {\n-\tif p.debugFormat {\n-\t\tp.marker('i')\n-\t}\n-\n-\treturn p.rawInt64()\n-}\n-\n-func (p *importer) path() string {\n-\tif p.debugFormat {\n-\t\tp.marker('p')\n-\t}\n-\t// if the path was seen before, i is its index (>= 0)\n-\t// (the empty string is at index 0)\n-\ti := p.rawInt64()\n-\tif i >= 0 {\n-\t\treturn p.pathList[i]\n-\t}\n-\t// otherwise, i is the negative path length (< 0)\n-\ta := make([]string, -i)\n-\tfor n := range a {\n-\t\ta[n] = p.string()\n-\t}\n-\ts := strings.Join(a, \"/\")\n-\tp.pathList = append(p.pathList, s)\n-\treturn s\n-}\n-\n-func (p *importer) string() string {\n-\tif p.debugFormat {\n-\t\tp.marker('s')\n-\t}\n-\t// if the string was seen before, i is its index (>= 0)\n-\t// (the empty string is at index 0)\n-\ti := p.rawInt64()\n-\tif i >= 0 {\n-\t\treturn p.strList[i]\n-\t}\n-\t// otherwise, i is the negative string length (< 0)\n-\tif n := int(-i); n <= cap(p.buf) {\n-\t\tp.buf = p.buf[:n]\n-\t} else {\n-\t\tp.buf = make([]byte, n)\n-\t}\n-\tfor i := range p.buf {\n-\t\tp.buf[i] = p.rawByte()\n-\t}\n-\ts := string(p.buf)\n-\tp.strList = append(p.strList, s)\n-\treturn s\n-}\n-\n-func (p *importer) marker(want byte) {\n-\tif got := p.rawByte(); got != want {\n-\t\terrorf(\"incorrect marker: got %c; want %c (pos = %d)\", got, want, p.read)\n-\t}\n-\n-\tpos := p.read\n-\tif n := int(p.rawInt64()); n != pos {\n-\t\terrorf(\"incorrect position: got %d; want %d\", n, pos)\n-\t}\n-}\n-\n-// rawInt64 should only be used by low-level decoders.\n-func (p *importer) rawInt64() int64 {\n-\ti, err := binary.ReadVarint(p)\n-\tif err != nil {\n-\t\terrorf(\"read error: %v\", err)\n-\t}\n-\treturn i\n-}\n-\n-// rawStringln should only be used to read the initial version string.\n-func (p *importer) rawStringln(b byte) string {\n-\tp.buf = p.buf[:0]\n-\tfor b != '\\n' {\n-\t\tp.buf = append(p.buf, b)\n-\t\tb = p.rawByte()\n-\t}\n-\treturn string(p.buf)\n-}\n-\n-// needed for binary.ReadVarint in rawInt64\n-func (p *importer) ReadByte() (byte, error) {\n-\treturn p.rawByte(), nil\n-}\n-\n-// byte is the bottleneck interface for reading p.data.\n-// It unescapes '|' 'S' to '$' and '|' '|' to '|'.\n-// rawByte should only be used by low-level decoders.\n-func (p *importer) rawByte() byte {\n-\tb := p.data[0]\n-\tr := 1\n-\tif b == '|' {\n-\t\tb = p.data[1]\n-\t\tr = 2\n-\t\tswitch b {\n-\t\tcase 'S':\n-\t\t\tb = '$'\n-\t\tcase '|':\n-\t\t\t// nothing to do\n-\t\tdefault:\n-\t\t\terrorf(\"unexpected escape sequence in export data\")\n-\t\t}\n-\t}\n-\tp.data = p.data[r:]\n-\tp.read += r\n-\treturn b\n-\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Export format\n-\n-// Tags. Must be < 0.\n-const (\n-\t// Objects\n-\tpackageTag = -(iota + 1)\n-\tconstTag\n-\ttypeTag\n-\tvarTag\n-\tfuncTag\n-\tendTag\n-\n-\t// Types\n-\tnamedTag\n-\tarrayTag\n-\tsliceTag\n-\tdddTag\n-\tstructTag\n-\tpointerTag\n-\tsignatureTag\n-\tinterfaceTag\n-\tmapTag\n-\tchanTag\n-\n-\t// Values\n-\tfalseTag\n-\ttrueTag\n-\tint64Tag\n-\tfloatTag\n-\tfractionTag // not used by gc\n-\tcomplexTag\n-\tstringTag\n-\tnilTag     // only used by gc (appears in exported inlined function bodies)\n-\tunknownTag // not used by gc (only appears in packages with errors)\n-\n-\t// Type aliases\n-\taliasTag\n-)\n-\n-var predeclOnce sync.Once\n-var predecl []types.Type // initialized lazily\n-\n-func predeclared() []types.Type {\n-\tpredeclOnce.Do(func() {\n-\t\t// initialize lazily to be sure that all\n-\t\t// elements have been initialized before\n-\t\tpredecl = []types.Type{ // basic types\n-\t\t\ttypes.Typ[types.Bool],\n-\t\t\ttypes.Typ[types.Int],\n-\t\t\ttypes.Typ[types.Int8],\n-\t\t\ttypes.Typ[types.Int16],\n-\t\t\ttypes.Typ[types.Int32],\n-\t\t\ttypes.Typ[types.Int64],\n-\t\t\ttypes.Typ[types.Uint],\n-\t\t\ttypes.Typ[types.Uint8],\n-\t\t\ttypes.Typ[types.Uint16],\n-\t\t\ttypes.Typ[types.Uint32],\n-\t\t\ttypes.Typ[types.Uint64],\n-\t\t\ttypes.Typ[types.Uintptr],\n-\t\t\ttypes.Typ[types.Float32],\n-\t\t\ttypes.Typ[types.Float64],\n-\t\t\ttypes.Typ[types.Complex64],\n-\t\t\ttypes.Typ[types.Complex128],\n-\t\t\ttypes.Typ[types.String],\n-\n-\t\t\t// basic type aliases\n-\t\t\ttypes.Universe.Lookup(\"byte\").Type(),\n-\t\t\ttypes.Universe.Lookup(\"rune\").Type(),\n-\n-\t\t\t// error\n-\t\t\ttypes.Universe.Lookup(\"error\").Type(),\n-\n-\t\t\t// untyped types\n-\t\t\ttypes.Typ[types.UntypedBool],\n-\t\t\ttypes.Typ[types.UntypedInt],\n-\t\t\ttypes.Typ[types.UntypedRune],\n-\t\t\ttypes.Typ[types.UntypedFloat],\n-\t\t\ttypes.Typ[types.UntypedComplex],\n-\t\t\ttypes.Typ[types.UntypedString],\n-\t\t\ttypes.Typ[types.UntypedNil],\n-\n-\t\t\t// package unsafe\n-\t\t\ttypes.Typ[types.UnsafePointer],\n-\n-\t\t\t// invalid type\n-\t\t\ttypes.Typ[types.Invalid], // only appears in packages with errors\n-\n-\t\t\t// used internally by gc; never used by this package or in .a files\n-\t\t\tanyType{},\n-\t\t}\n-\t})\n-\treturn predecl\n-}\n-\n-type anyType struct{}\n-\n-func (t anyType) Underlying() types.Type { return t }\n-func (t anyType) String() string         { return \"any\" }"
    },
    {
      "sha": "f33dc5613e712eb0dc9454864f772d1edcf8f425",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/exportdata.go",
      "status": "removed",
      "additions": 0,
      "deletions": 93,
      "changes": 93,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/exportdata.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/exportdata.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/exportdata.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,93 +0,0 @@\n-// Copyright 2011 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// This file is a copy of $GOROOT/src/go/internal/gcimporter/exportdata.go.\n-\n-// This file implements FindExportData.\n-\n-package gcimporter\n-\n-import (\n-\t\"bufio\"\n-\t\"fmt\"\n-\t\"io\"\n-\t\"strconv\"\n-\t\"strings\"\n-)\n-\n-func readGopackHeader(r *bufio.Reader) (name string, size int, err error) {\n-\t// See $GOROOT/include/ar.h.\n-\thdr := make([]byte, 16+12+6+6+8+10+2)\n-\t_, err = io.ReadFull(r, hdr)\n-\tif err != nil {\n-\t\treturn\n-\t}\n-\t// leave for debugging\n-\tif false {\n-\t\tfmt.Printf(\"header: %s\", hdr)\n-\t}\n-\ts := strings.TrimSpace(string(hdr[16+12+6+6+8:][:10]))\n-\tsize, err = strconv.Atoi(s)\n-\tif err != nil || hdr[len(hdr)-2] != '`' || hdr[len(hdr)-1] != '\\n' {\n-\t\terr = fmt.Errorf(\"invalid archive header\")\n-\t\treturn\n-\t}\n-\tname = strings.TrimSpace(string(hdr[:16]))\n-\treturn\n-}\n-\n-// FindExportData positions the reader r at the beginning of the\n-// export data section of an underlying GC-created object/archive\n-// file by reading from it. The reader must be positioned at the\n-// start of the file before calling this function. The hdr result\n-// is the string before the export data, either \"$$\" or \"$$B\".\n-//\n-func FindExportData(r *bufio.Reader) (hdr string, err error) {\n-\t// Read first line to make sure this is an object file.\n-\tline, err := r.ReadSlice('\\n')\n-\tif err != nil {\n-\t\terr = fmt.Errorf(\"can't find export data (%v)\", err)\n-\t\treturn\n-\t}\n-\n-\tif string(line) == \"!<arch>\\n\" {\n-\t\t// Archive file. Scan to __.PKGDEF.\n-\t\tvar name string\n-\t\tif name, _, err = readGopackHeader(r); err != nil {\n-\t\t\treturn\n-\t\t}\n-\n-\t\t// First entry should be __.PKGDEF.\n-\t\tif name != \"__.PKGDEF\" {\n-\t\t\terr = fmt.Errorf(\"go archive is missing __.PKGDEF\")\n-\t\t\treturn\n-\t\t}\n-\n-\t\t// Read first line of __.PKGDEF data, so that line\n-\t\t// is once again the first line of the input.\n-\t\tif line, err = r.ReadSlice('\\n'); err != nil {\n-\t\t\terr = fmt.Errorf(\"can't find export data (%v)\", err)\n-\t\t\treturn\n-\t\t}\n-\t}\n-\n-\t// Now at __.PKGDEF in archive or still at beginning of file.\n-\t// Either way, line should begin with \"go object \".\n-\tif !strings.HasPrefix(string(line), \"go object \") {\n-\t\terr = fmt.Errorf(\"not a Go object file\")\n-\t\treturn\n-\t}\n-\n-\t// Skip over object header to export data.\n-\t// Begins after first line starting with $$.\n-\tfor line[0] != '$' {\n-\t\tif line, err = r.ReadSlice('\\n'); err != nil {\n-\t\t\terr = fmt.Errorf(\"can't find export data (%v)\", err)\n-\t\t\treturn\n-\t\t}\n-\t}\n-\thdr = string(line)\n-\n-\treturn\n-}"
    },
    {
      "sha": "8dcd8bbb71a032c344dd8a94409e66fa1fbcdccc",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/gcimporter.go",
      "status": "removed",
      "additions": 0,
      "deletions": 1078,
      "changes": 1078,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/gcimporter.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/gcimporter.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/gcimporter.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,1078 +0,0 @@\n-// Copyright 2011 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// This file is a modified copy of $GOROOT/src/go/internal/gcimporter/gcimporter.go,\n-// but it also contains the original source-based importer code for Go1.6.\n-// Once we stop supporting 1.6, we can remove that code.\n-\n-// Package gcimporter provides various functions for reading\n-// gc-generated object files that can be used to implement the\n-// Importer interface defined by the Go 1.5 standard library package.\n-package gcimporter // import \"golang.org/x/tools/go/internal/gcimporter\"\n-\n-import (\n-\t\"bufio\"\n-\t\"errors\"\n-\t\"fmt\"\n-\t\"go/build\"\n-\t\"go/constant\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"io\"\n-\t\"io/ioutil\"\n-\t\"os\"\n-\t\"path/filepath\"\n-\t\"sort\"\n-\t\"strconv\"\n-\t\"strings\"\n-\t\"text/scanner\"\n-)\n-\n-// debugging/development support\n-const debug = false\n-\n-var pkgExts = [...]string{\".a\", \".o\"}\n-\n-// FindPkg returns the filename and unique package id for an import\n-// path based on package information provided by build.Import (using\n-// the build.Default build.Context). A relative srcDir is interpreted\n-// relative to the current working directory.\n-// If no file was found, an empty filename is returned.\n-//\n-func FindPkg(path, srcDir string) (filename, id string) {\n-\tif path == \"\" {\n-\t\treturn\n-\t}\n-\n-\tvar noext string\n-\tswitch {\n-\tdefault:\n-\t\t// \"x\" -> \"$GOPATH/pkg/$GOOS_$GOARCH/x.ext\", \"x\"\n-\t\t// Don't require the source files to be present.\n-\t\tif abs, err := filepath.Abs(srcDir); err == nil { // see issue 14282\n-\t\t\tsrcDir = abs\n-\t\t}\n-\t\tbp, _ := build.Import(path, srcDir, build.FindOnly|build.AllowBinary)\n-\t\tif bp.PkgObj == \"\" {\n-\t\t\tid = path // make sure we have an id to print in error message\n-\t\t\treturn\n-\t\t}\n-\t\tnoext = strings.TrimSuffix(bp.PkgObj, \".a\")\n-\t\tid = bp.ImportPath\n-\n-\tcase build.IsLocalImport(path):\n-\t\t// \"./x\" -> \"/this/directory/x.ext\", \"/this/directory/x\"\n-\t\tnoext = filepath.Join(srcDir, path)\n-\t\tid = noext\n-\n-\tcase filepath.IsAbs(path):\n-\t\t// for completeness only - go/build.Import\n-\t\t// does not support absolute imports\n-\t\t// \"/x\" -> \"/x.ext\", \"/x\"\n-\t\tnoext = path\n-\t\tid = path\n-\t}\n-\n-\tif false { // for debugging\n-\t\tif path != id {\n-\t\t\tfmt.Printf(\"%s -> %s\\n\", path, id)\n-\t\t}\n-\t}\n-\n-\t// try extensions\n-\tfor _, ext := range pkgExts {\n-\t\tfilename = noext + ext\n-\t\tif f, err := os.Stat(filename); err == nil && !f.IsDir() {\n-\t\t\treturn\n-\t\t}\n-\t}\n-\n-\tfilename = \"\" // not found\n-\treturn\n-}\n-\n-// ImportData imports a package by reading the gc-generated export data,\n-// adds the corresponding package object to the packages map indexed by id,\n-// and returns the object.\n-//\n-// The packages map must contains all packages already imported. The data\n-// reader position must be the beginning of the export data section. The\n-// filename is only used in error messages.\n-//\n-// If packages[id] contains the completely imported package, that package\n-// can be used directly, and there is no need to call this function (but\n-// there is also no harm but for extra time used).\n-//\n-func ImportData(packages map[string]*types.Package, filename, id string, data io.Reader) (pkg *types.Package, err error) {\n-\t// support for parser error handling\n-\tdefer func() {\n-\t\tswitch r := recover().(type) {\n-\t\tcase nil:\n-\t\t\t// nothing to do\n-\t\tcase importError:\n-\t\t\terr = r\n-\t\tdefault:\n-\t\t\tpanic(r) // internal error\n-\t\t}\n-\t}()\n-\n-\tvar p parser\n-\tp.init(filename, id, data, packages)\n-\tpkg = p.parseExport()\n-\n-\treturn\n-}\n-\n-// Import imports a gc-generated package given its import path and srcDir, adds\n-// the corresponding package object to the packages map, and returns the object.\n-// The packages map must contain all packages already imported.\n-//\n-func Import(packages map[string]*types.Package, path, srcDir string, lookup func(path string) (io.ReadCloser, error)) (pkg *types.Package, err error) {\n-\tvar rc io.ReadCloser\n-\tvar filename, id string\n-\tif lookup != nil {\n-\t\t// With custom lookup specified, assume that caller has\n-\t\t// converted path to a canonical import path for use in the map.\n-\t\tif path == \"unsafe\" {\n-\t\t\treturn types.Unsafe, nil\n-\t\t}\n-\t\tid = path\n-\n-\t\t// No need to re-import if the package was imported completely before.\n-\t\tif pkg = packages[id]; pkg != nil && pkg.Complete() {\n-\t\t\treturn\n-\t\t}\n-\t\tf, err := lookup(path)\n-\t\tif err != nil {\n-\t\t\treturn nil, err\n-\t\t}\n-\t\trc = f\n-\t} else {\n-\t\tfilename, id = FindPkg(path, srcDir)\n-\t\tif filename == \"\" {\n-\t\t\tif path == \"unsafe\" {\n-\t\t\t\treturn types.Unsafe, nil\n-\t\t\t}\n-\t\t\treturn nil, fmt.Errorf(\"can't find import: %q\", id)\n-\t\t}\n-\n-\t\t// no need to re-import if the package was imported completely before\n-\t\tif pkg = packages[id]; pkg != nil && pkg.Complete() {\n-\t\t\treturn\n-\t\t}\n-\n-\t\t// open file\n-\t\tf, err := os.Open(filename)\n-\t\tif err != nil {\n-\t\t\treturn nil, err\n-\t\t}\n-\t\tdefer func() {\n-\t\t\tif err != nil {\n-\t\t\t\t// add file name to error\n-\t\t\t\terr = fmt.Errorf(\"%s: %v\", filename, err)\n-\t\t\t}\n-\t\t}()\n-\t\trc = f\n-\t}\n-\tdefer rc.Close()\n-\n-\tvar hdr string\n-\tbuf := bufio.NewReader(rc)\n-\tif hdr, err = FindExportData(buf); err != nil {\n-\t\treturn\n-\t}\n-\n-\tswitch hdr {\n-\tcase \"$$\\n\":\n-\t\t// Work-around if we don't have a filename; happens only if lookup != nil.\n-\t\t// Either way, the filename is only needed for importer error messages, so\n-\t\t// this is fine.\n-\t\tif filename == \"\" {\n-\t\t\tfilename = path\n-\t\t}\n-\t\treturn ImportData(packages, filename, id, buf)\n-\n-\tcase \"$$B\\n\":\n-\t\tvar data []byte\n-\t\tdata, err = ioutil.ReadAll(buf)\n-\t\tif err != nil {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\t// TODO(gri): allow clients of go/importer to provide a FileSet.\n-\t\t// Or, define a new standard go/types/gcexportdata package.\n-\t\tfset := token.NewFileSet()\n-\n-\t\t// The indexed export format starts with an 'i'; the older\n-\t\t// binary export format starts with a 'c', 'd', or 'v'\n-\t\t// (from \"version\"). Select appropriate importer.\n-\t\tif len(data) > 0 && data[0] == 'i' {\n-\t\t\t_, pkg, err = IImportData(fset, packages, data[1:], id)\n-\t\t} else {\n-\t\t\t_, pkg, err = BImportData(fset, packages, data, id)\n-\t\t}\n-\n-\tdefault:\n-\t\terr = fmt.Errorf(\"unknown export data header: %q\", hdr)\n-\t}\n-\n-\treturn\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Parser\n-\n-// TODO(gri) Imported objects don't have position information.\n-//           Ideally use the debug table line info; alternatively\n-//           create some fake position (or the position of the\n-//           import). That way error messages referring to imported\n-//           objects can print meaningful information.\n-\n-// parser parses the exports inside a gc compiler-produced\n-// object/archive file and populates its scope with the results.\n-type parser struct {\n-\tscanner    scanner.Scanner\n-\ttok        rune                      // current token\n-\tlit        string                    // literal string; only valid for Ident, Int, String tokens\n-\tid         string                    // package id of imported package\n-\tsharedPkgs map[string]*types.Package // package id -> package object (across importer)\n-\tlocalPkgs  map[string]*types.Package // package id -> package object (just this package)\n-}\n-\n-func (p *parser) init(filename, id string, src io.Reader, packages map[string]*types.Package) {\n-\tp.scanner.Init(src)\n-\tp.scanner.Error = func(_ *scanner.Scanner, msg string) { p.error(msg) }\n-\tp.scanner.Mode = scanner.ScanIdents | scanner.ScanInts | scanner.ScanChars | scanner.ScanStrings | scanner.ScanComments | scanner.SkipComments\n-\tp.scanner.Whitespace = 1<<'\\t' | 1<<' '\n-\tp.scanner.Filename = filename // for good error messages\n-\tp.next()\n-\tp.id = id\n-\tp.sharedPkgs = packages\n-\tif debug {\n-\t\t// check consistency of packages map\n-\t\tfor _, pkg := range packages {\n-\t\t\tif pkg.Name() == \"\" {\n-\t\t\t\tfmt.Printf(\"no package name for %s\\n\", pkg.Path())\n-\t\t\t}\n-\t\t}\n-\t}\n-}\n-\n-func (p *parser) next() {\n-\tp.tok = p.scanner.Scan()\n-\tswitch p.tok {\n-\tcase scanner.Ident, scanner.Int, scanner.Char, scanner.String, '':\n-\t\tp.lit = p.scanner.TokenText()\n-\tdefault:\n-\t\tp.lit = \"\"\n-\t}\n-\tif debug {\n-\t\tfmt.Printf(\"%s: %q -> %q\\n\", scanner.TokenString(p.tok), p.scanner.TokenText(), p.lit)\n-\t}\n-}\n-\n-func declTypeName(pkg *types.Package, name string) *types.TypeName {\n-\tscope := pkg.Scope()\n-\tif obj := scope.Lookup(name); obj != nil {\n-\t\treturn obj.(*types.TypeName)\n-\t}\n-\tobj := types.NewTypeName(token.NoPos, pkg, name, nil)\n-\t// a named type may be referred to before the underlying type\n-\t// is known - set it up\n-\ttypes.NewNamed(obj, nil, nil)\n-\tscope.Insert(obj)\n-\treturn obj\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Error handling\n-\n-// Internal errors are boxed as importErrors.\n-type importError struct {\n-\tpos scanner.Position\n-\terr error\n-}\n-\n-func (e importError) Error() string {\n-\treturn fmt.Sprintf(\"import error %s (byte offset = %d): %s\", e.pos, e.pos.Offset, e.err)\n-}\n-\n-func (p *parser) error(err interface{}) {\n-\tif s, ok := err.(string); ok {\n-\t\terr = errors.New(s)\n-\t}\n-\t// panic with a runtime.Error if err is not an error\n-\tpanic(importError{p.scanner.Pos(), err.(error)})\n-}\n-\n-func (p *parser) errorf(format string, args ...interface{}) {\n-\tp.error(fmt.Sprintf(format, args...))\n-}\n-\n-func (p *parser) expect(tok rune) string {\n-\tlit := p.lit\n-\tif p.tok != tok {\n-\t\tp.errorf(\"expected %s, got %s (%s)\", scanner.TokenString(tok), scanner.TokenString(p.tok), lit)\n-\t}\n-\tp.next()\n-\treturn lit\n-}\n-\n-func (p *parser) expectSpecial(tok string) {\n-\tsep := 'x' // not white space\n-\ti := 0\n-\tfor i < len(tok) && p.tok == rune(tok[i]) && sep > ' ' {\n-\t\tsep = p.scanner.Peek() // if sep <= ' ', there is white space before the next token\n-\t\tp.next()\n-\t\ti++\n-\t}\n-\tif i < len(tok) {\n-\t\tp.errorf(\"expected %q, got %q\", tok, tok[0:i])\n-\t}\n-}\n-\n-func (p *parser) expectKeyword(keyword string) {\n-\tlit := p.expect(scanner.Ident)\n-\tif lit != keyword {\n-\t\tp.errorf(\"expected keyword %s, got %q\", keyword, lit)\n-\t}\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Qualified and unqualified names\n-\n-// PackageId = string_lit .\n-//\n-func (p *parser) parsePackageID() string {\n-\tid, err := strconv.Unquote(p.expect(scanner.String))\n-\tif err != nil {\n-\t\tp.error(err)\n-\t}\n-\t// id == \"\" stands for the imported package id\n-\t// (only known at time of package installation)\n-\tif id == \"\" {\n-\t\tid = p.id\n-\t}\n-\treturn id\n-}\n-\n-// PackageName = ident .\n-//\n-func (p *parser) parsePackageName() string {\n-\treturn p.expect(scanner.Ident)\n-}\n-\n-// dotIdentifier = ( ident | '' ) { ident | int | '' } .\n-func (p *parser) parseDotIdent() string {\n-\tident := \"\"\n-\tif p.tok != scanner.Int {\n-\t\tsep := 'x' // not white space\n-\t\tfor (p.tok == scanner.Ident || p.tok == scanner.Int || p.tok == '') && sep > ' ' {\n-\t\t\tident += p.lit\n-\t\t\tsep = p.scanner.Peek() // if sep <= ' ', there is white space before the next token\n-\t\t\tp.next()\n-\t\t}\n-\t}\n-\tif ident == \"\" {\n-\t\tp.expect(scanner.Ident) // use expect() for error handling\n-\t}\n-\treturn ident\n-}\n-\n-// QualifiedName = \"@\" PackageId \".\" ( \"?\" | dotIdentifier ) .\n-//\n-func (p *parser) parseQualifiedName() (id, name string) {\n-\tp.expect('@')\n-\tid = p.parsePackageID()\n-\tp.expect('.')\n-\t// Per rev f280b8a485fd (10/2/2013), qualified names may be used for anonymous fields.\n-\tif p.tok == '?' {\n-\t\tp.next()\n-\t} else {\n-\t\tname = p.parseDotIdent()\n-\t}\n-\treturn\n-}\n-\n-// getPkg returns the package for a given id. If the package is\n-// not found, create the package and add it to the p.localPkgs\n-// and p.sharedPkgs maps. name is the (expected) name of the\n-// package. If name == \"\", the package name is expected to be\n-// set later via an import clause in the export data.\n-//\n-// id identifies a package, usually by a canonical package path like\n-// \"encoding/json\" but possibly by a non-canonical import path like\n-// \"./json\".\n-//\n-func (p *parser) getPkg(id, name string) *types.Package {\n-\t// package unsafe is not in the packages maps - handle explicitly\n-\tif id == \"unsafe\" {\n-\t\treturn types.Unsafe\n-\t}\n-\n-\tpkg := p.localPkgs[id]\n-\tif pkg == nil {\n-\t\t// first import of id from this package\n-\t\tpkg = p.sharedPkgs[id]\n-\t\tif pkg == nil {\n-\t\t\t// first import of id by this importer;\n-\t\t\t// add (possibly unnamed) pkg to shared packages\n-\t\t\tpkg = types.NewPackage(id, name)\n-\t\t\tp.sharedPkgs[id] = pkg\n-\t\t}\n-\t\t// add (possibly unnamed) pkg to local packages\n-\t\tif p.localPkgs == nil {\n-\t\t\tp.localPkgs = make(map[string]*types.Package)\n-\t\t}\n-\t\tp.localPkgs[id] = pkg\n-\t} else if name != \"\" {\n-\t\t// package exists already and we have an expected package name;\n-\t\t// make sure names match or set package name if necessary\n-\t\tif pname := pkg.Name(); pname == \"\" {\n-\t\t\tpkg.SetName(name)\n-\t\t} else if pname != name {\n-\t\t\tp.errorf(\"%s package name mismatch: %s (given) vs %s (expected)\", id, pname, name)\n-\t\t}\n-\t}\n-\treturn pkg\n-}\n-\n-// parseExportedName is like parseQualifiedName, but\n-// the package id is resolved to an imported *types.Package.\n-//\n-func (p *parser) parseExportedName() (pkg *types.Package, name string) {\n-\tid, name := p.parseQualifiedName()\n-\tpkg = p.getPkg(id, \"\")\n-\treturn\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Types\n-\n-// BasicType = identifier .\n-//\n-func (p *parser) parseBasicType() types.Type {\n-\tid := p.expect(scanner.Ident)\n-\tobj := types.Universe.Lookup(id)\n-\tif obj, ok := obj.(*types.TypeName); ok {\n-\t\treturn obj.Type()\n-\t}\n-\tp.errorf(\"not a basic type: %s\", id)\n-\treturn nil\n-}\n-\n-// ArrayType = \"[\" int_lit \"]\" Type .\n-//\n-func (p *parser) parseArrayType(parent *types.Package) types.Type {\n-\t// \"[\" already consumed and lookahead known not to be \"]\"\n-\tlit := p.expect(scanner.Int)\n-\tp.expect(']')\n-\telem := p.parseType(parent)\n-\tn, err := strconv.ParseInt(lit, 10, 64)\n-\tif err != nil {\n-\t\tp.error(err)\n-\t}\n-\treturn types.NewArray(elem, n)\n-}\n-\n-// MapType = \"map\" \"[\" Type \"]\" Type .\n-//\n-func (p *parser) parseMapType(parent *types.Package) types.Type {\n-\tp.expectKeyword(\"map\")\n-\tp.expect('[')\n-\tkey := p.parseType(parent)\n-\tp.expect(']')\n-\telem := p.parseType(parent)\n-\treturn types.NewMap(key, elem)\n-}\n-\n-// Name = identifier | \"?\" | QualifiedName .\n-//\n-// For unqualified and anonymous names, the returned package is the parent\n-// package unless parent == nil, in which case the returned package is the\n-// package being imported. (The parent package is not nil if the the name\n-// is an unqualified struct field or interface method name belonging to a\n-// type declared in another package.)\n-//\n-// For qualified names, the returned package is nil (and not created if\n-// it doesn't exist yet) unless materializePkg is set (which creates an\n-// unnamed package with valid package path). In the latter case, a\n-// subsequent import clause is expected to provide a name for the package.\n-//\n-func (p *parser) parseName(parent *types.Package, materializePkg bool) (pkg *types.Package, name string) {\n-\tpkg = parent\n-\tif pkg == nil {\n-\t\tpkg = p.sharedPkgs[p.id]\n-\t}\n-\tswitch p.tok {\n-\tcase scanner.Ident:\n-\t\tname = p.lit\n-\t\tp.next()\n-\tcase '?':\n-\t\t// anonymous\n-\t\tp.next()\n-\tcase '@':\n-\t\t// exported name prefixed with package path\n-\t\tpkg = nil\n-\t\tvar id string\n-\t\tid, name = p.parseQualifiedName()\n-\t\tif materializePkg {\n-\t\t\tpkg = p.getPkg(id, \"\")\n-\t\t}\n-\tdefault:\n-\t\tp.error(\"name expected\")\n-\t}\n-\treturn\n-}\n-\n-func deref(typ types.Type) types.Type {\n-\tif p, _ := typ.(*types.Pointer); p != nil {\n-\t\treturn p.Elem()\n-\t}\n-\treturn typ\n-}\n-\n-// Field = Name Type [ string_lit ] .\n-//\n-func (p *parser) parseField(parent *types.Package) (*types.Var, string) {\n-\tpkg, name := p.parseName(parent, true)\n-\n-\tif name == \"_\" {\n-\t\t// Blank fields should be package-qualified because they\n-\t\t// are unexported identifiers, but gc does not qualify them.\n-\t\t// Assuming that the ident belongs to the current package\n-\t\t// causes types to change during re-exporting, leading\n-\t\t// to spurious \"can't assign A to B\" errors from go/types.\n-\t\t// As a workaround, pretend all blank fields belong\n-\t\t// to the same unique dummy package.\n-\t\tconst blankpkg = \"<_>\"\n-\t\tpkg = p.getPkg(blankpkg, blankpkg)\n-\t}\n-\n-\ttyp := p.parseType(parent)\n-\tanonymous := false\n-\tif name == \"\" {\n-\t\t// anonymous field - typ must be T or *T and T must be a type name\n-\t\tswitch typ := deref(typ).(type) {\n-\t\tcase *types.Basic: // basic types are named types\n-\t\t\tpkg = nil // objects defined in Universe scope have no package\n-\t\t\tname = typ.Name()\n-\t\tcase *types.Named:\n-\t\t\tname = typ.Obj().Name()\n-\t\tdefault:\n-\t\t\tp.errorf(\"anonymous field expected\")\n-\t\t}\n-\t\tanonymous = true\n-\t}\n-\ttag := \"\"\n-\tif p.tok == scanner.String {\n-\t\ts := p.expect(scanner.String)\n-\t\tvar err error\n-\t\ttag, err = strconv.Unquote(s)\n-\t\tif err != nil {\n-\t\t\tp.errorf(\"invalid struct tag %s: %s\", s, err)\n-\t\t}\n-\t}\n-\treturn types.NewField(token.NoPos, pkg, name, typ, anonymous), tag\n-}\n-\n-// StructType = \"struct\" \"{\" [ FieldList ] \"}\" .\n-// FieldList  = Field { \";\" Field } .\n-//\n-func (p *parser) parseStructType(parent *types.Package) types.Type {\n-\tvar fields []*types.Var\n-\tvar tags []string\n-\n-\tp.expectKeyword(\"struct\")\n-\tp.expect('{')\n-\tfor i := 0; p.tok != '}' && p.tok != scanner.EOF; i++ {\n-\t\tif i > 0 {\n-\t\t\tp.expect(';')\n-\t\t}\n-\t\tfld, tag := p.parseField(parent)\n-\t\tif tag != \"\" && tags == nil {\n-\t\t\ttags = make([]string, i)\n-\t\t}\n-\t\tif tags != nil {\n-\t\t\ttags = append(tags, tag)\n-\t\t}\n-\t\tfields = append(fields, fld)\n-\t}\n-\tp.expect('}')\n-\n-\treturn types.NewStruct(fields, tags)\n-}\n-\n-// Parameter = ( identifier | \"?\" ) [ \"...\" ] Type [ string_lit ] .\n-//\n-func (p *parser) parseParameter() (par *types.Var, isVariadic bool) {\n-\t_, name := p.parseName(nil, false)\n-\t// remove gc-specific parameter numbering\n-\tif i := strings.Index(name, \"\"); i >= 0 {\n-\t\tname = name[:i]\n-\t}\n-\tif p.tok == '.' {\n-\t\tp.expectSpecial(\"...\")\n-\t\tisVariadic = true\n-\t}\n-\ttyp := p.parseType(nil)\n-\tif isVariadic {\n-\t\ttyp = types.NewSlice(typ)\n-\t}\n-\t// ignore argument tag (e.g. \"noescape\")\n-\tif p.tok == scanner.String {\n-\t\tp.next()\n-\t}\n-\t// TODO(gri) should we provide a package?\n-\tpar = types.NewVar(token.NoPos, nil, name, typ)\n-\treturn\n-}\n-\n-// Parameters    = \"(\" [ ParameterList ] \")\" .\n-// ParameterList = { Parameter \",\" } Parameter .\n-//\n-func (p *parser) parseParameters() (list []*types.Var, isVariadic bool) {\n-\tp.expect('(')\n-\tfor p.tok != ')' && p.tok != scanner.EOF {\n-\t\tif len(list) > 0 {\n-\t\t\tp.expect(',')\n-\t\t}\n-\t\tpar, variadic := p.parseParameter()\n-\t\tlist = append(list, par)\n-\t\tif variadic {\n-\t\t\tif isVariadic {\n-\t\t\t\tp.error(\"... not on final argument\")\n-\t\t\t}\n-\t\t\tisVariadic = true\n-\t\t}\n-\t}\n-\tp.expect(')')\n-\n-\treturn\n-}\n-\n-// Signature = Parameters [ Result ] .\n-// Result    = Type | Parameters .\n-//\n-func (p *parser) parseSignature(recv *types.Var) *types.Signature {\n-\tparams, isVariadic := p.parseParameters()\n-\n-\t// optional result type\n-\tvar results []*types.Var\n-\tif p.tok == '(' {\n-\t\tvar variadic bool\n-\t\tresults, variadic = p.parseParameters()\n-\t\tif variadic {\n-\t\t\tp.error(\"... not permitted on result type\")\n-\t\t}\n-\t}\n-\n-\treturn types.NewSignature(recv, types.NewTuple(params...), types.NewTuple(results...), isVariadic)\n-}\n-\n-// InterfaceType = \"interface\" \"{\" [ MethodList ] \"}\" .\n-// MethodList    = Method { \";\" Method } .\n-// Method        = Name Signature .\n-//\n-// The methods of embedded interfaces are always \"inlined\"\n-// by the compiler and thus embedded interfaces are never\n-// visible in the export data.\n-//\n-func (p *parser) parseInterfaceType(parent *types.Package) types.Type {\n-\tvar methods []*types.Func\n-\n-\tp.expectKeyword(\"interface\")\n-\tp.expect('{')\n-\tfor i := 0; p.tok != '}' && p.tok != scanner.EOF; i++ {\n-\t\tif i > 0 {\n-\t\t\tp.expect(';')\n-\t\t}\n-\t\tpkg, name := p.parseName(parent, true)\n-\t\tsig := p.parseSignature(nil)\n-\t\tmethods = append(methods, types.NewFunc(token.NoPos, pkg, name, sig))\n-\t}\n-\tp.expect('}')\n-\n-\t// Complete requires the type's embedded interfaces to be fully defined,\n-\t// but we do not define any\n-\treturn newInterface(methods, nil).Complete()\n-}\n-\n-// ChanType = ( \"chan\" [ \"<-\" ] | \"<-\" \"chan\" ) Type .\n-//\n-func (p *parser) parseChanType(parent *types.Package) types.Type {\n-\tdir := types.SendRecv\n-\tif p.tok == scanner.Ident {\n-\t\tp.expectKeyword(\"chan\")\n-\t\tif p.tok == '<' {\n-\t\t\tp.expectSpecial(\"<-\")\n-\t\t\tdir = types.SendOnly\n-\t\t}\n-\t} else {\n-\t\tp.expectSpecial(\"<-\")\n-\t\tp.expectKeyword(\"chan\")\n-\t\tdir = types.RecvOnly\n-\t}\n-\telem := p.parseType(parent)\n-\treturn types.NewChan(dir, elem)\n-}\n-\n-// Type =\n-//\tBasicType | TypeName | ArrayType | SliceType | StructType |\n-//      PointerType | FuncType | InterfaceType | MapType | ChanType |\n-//      \"(\" Type \")\" .\n-//\n-// BasicType   = ident .\n-// TypeName    = ExportedName .\n-// SliceType   = \"[\" \"]\" Type .\n-// PointerType = \"*\" Type .\n-// FuncType    = \"func\" Signature .\n-//\n-func (p *parser) parseType(parent *types.Package) types.Type {\n-\tswitch p.tok {\n-\tcase scanner.Ident:\n-\t\tswitch p.lit {\n-\t\tdefault:\n-\t\t\treturn p.parseBasicType()\n-\t\tcase \"struct\":\n-\t\t\treturn p.parseStructType(parent)\n-\t\tcase \"func\":\n-\t\t\t// FuncType\n-\t\t\tp.next()\n-\t\t\treturn p.parseSignature(nil)\n-\t\tcase \"interface\":\n-\t\t\treturn p.parseInterfaceType(parent)\n-\t\tcase \"map\":\n-\t\t\treturn p.parseMapType(parent)\n-\t\tcase \"chan\":\n-\t\t\treturn p.parseChanType(parent)\n-\t\t}\n-\tcase '@':\n-\t\t// TypeName\n-\t\tpkg, name := p.parseExportedName()\n-\t\treturn declTypeName(pkg, name).Type()\n-\tcase '[':\n-\t\tp.next() // look ahead\n-\t\tif p.tok == ']' {\n-\t\t\t// SliceType\n-\t\t\tp.next()\n-\t\t\treturn types.NewSlice(p.parseType(parent))\n-\t\t}\n-\t\treturn p.parseArrayType(parent)\n-\tcase '*':\n-\t\t// PointerType\n-\t\tp.next()\n-\t\treturn types.NewPointer(p.parseType(parent))\n-\tcase '<':\n-\t\treturn p.parseChanType(parent)\n-\tcase '(':\n-\t\t// \"(\" Type \")\"\n-\t\tp.next()\n-\t\ttyp := p.parseType(parent)\n-\t\tp.expect(')')\n-\t\treturn typ\n-\t}\n-\tp.errorf(\"expected type, got %s (%q)\", scanner.TokenString(p.tok), p.lit)\n-\treturn nil\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Declarations\n-\n-// ImportDecl = \"import\" PackageName PackageId .\n-//\n-func (p *parser) parseImportDecl() {\n-\tp.expectKeyword(\"import\")\n-\tname := p.parsePackageName()\n-\tp.getPkg(p.parsePackageID(), name)\n-}\n-\n-// int_lit = [ \"+\" | \"-\" ] { \"0\" ... \"9\" } .\n-//\n-func (p *parser) parseInt() string {\n-\ts := \"\"\n-\tswitch p.tok {\n-\tcase '-':\n-\t\ts = \"-\"\n-\t\tp.next()\n-\tcase '+':\n-\t\tp.next()\n-\t}\n-\treturn s + p.expect(scanner.Int)\n-}\n-\n-// number = int_lit [ \"p\" int_lit ] .\n-//\n-func (p *parser) parseNumber() (typ *types.Basic, val constant.Value) {\n-\t// mantissa\n-\tmant := constant.MakeFromLiteral(p.parseInt(), token.INT, 0)\n-\tif mant == nil {\n-\t\tpanic(\"invalid mantissa\")\n-\t}\n-\n-\tif p.lit == \"p\" {\n-\t\t// exponent (base 2)\n-\t\tp.next()\n-\t\texp, err := strconv.ParseInt(p.parseInt(), 10, 0)\n-\t\tif err != nil {\n-\t\t\tp.error(err)\n-\t\t}\n-\t\tif exp < 0 {\n-\t\t\tdenom := constant.MakeInt64(1)\n-\t\t\tdenom = constant.Shift(denom, token.SHL, uint(-exp))\n-\t\t\ttyp = types.Typ[types.UntypedFloat]\n-\t\t\tval = constant.BinaryOp(mant, token.QUO, denom)\n-\t\t\treturn\n-\t\t}\n-\t\tif exp > 0 {\n-\t\t\tmant = constant.Shift(mant, token.SHL, uint(exp))\n-\t\t}\n-\t\ttyp = types.Typ[types.UntypedFloat]\n-\t\tval = mant\n-\t\treturn\n-\t}\n-\n-\ttyp = types.Typ[types.UntypedInt]\n-\tval = mant\n-\treturn\n-}\n-\n-// ConstDecl   = \"const\" ExportedName [ Type ] \"=\" Literal .\n-// Literal     = bool_lit | int_lit | float_lit | complex_lit | rune_lit | string_lit .\n-// bool_lit    = \"true\" | \"false\" .\n-// complex_lit = \"(\" float_lit \"+\" float_lit \"i\" \")\" .\n-// rune_lit    = \"(\" int_lit \"+\" int_lit \")\" .\n-// string_lit  = `\"` { unicode_char } `\"` .\n-//\n-func (p *parser) parseConstDecl() {\n-\tp.expectKeyword(\"const\")\n-\tpkg, name := p.parseExportedName()\n-\n-\tvar typ0 types.Type\n-\tif p.tok != '=' {\n-\t\t// constant types are never structured - no need for parent type\n-\t\ttyp0 = p.parseType(nil)\n-\t}\n-\n-\tp.expect('=')\n-\tvar typ types.Type\n-\tvar val constant.Value\n-\tswitch p.tok {\n-\tcase scanner.Ident:\n-\t\t// bool_lit\n-\t\tif p.lit != \"true\" && p.lit != \"false\" {\n-\t\t\tp.error(\"expected true or false\")\n-\t\t}\n-\t\ttyp = types.Typ[types.UntypedBool]\n-\t\tval = constant.MakeBool(p.lit == \"true\")\n-\t\tp.next()\n-\n-\tcase '-', scanner.Int:\n-\t\t// int_lit\n-\t\ttyp, val = p.parseNumber()\n-\n-\tcase '(':\n-\t\t// complex_lit or rune_lit\n-\t\tp.next()\n-\t\tif p.tok == scanner.Char {\n-\t\t\tp.next()\n-\t\t\tp.expect('+')\n-\t\t\ttyp = types.Typ[types.UntypedRune]\n-\t\t\t_, val = p.parseNumber()\n-\t\t\tp.expect(')')\n-\t\t\tbreak\n-\t\t}\n-\t\t_, re := p.parseNumber()\n-\t\tp.expect('+')\n-\t\t_, im := p.parseNumber()\n-\t\tp.expectKeyword(\"i\")\n-\t\tp.expect(')')\n-\t\ttyp = types.Typ[types.UntypedComplex]\n-\t\tval = constant.BinaryOp(re, token.ADD, constant.MakeImag(im))\n-\n-\tcase scanner.Char:\n-\t\t// rune_lit\n-\t\ttyp = types.Typ[types.UntypedRune]\n-\t\tval = constant.MakeFromLiteral(p.lit, token.CHAR, 0)\n-\t\tp.next()\n-\n-\tcase scanner.String:\n-\t\t// string_lit\n-\t\ttyp = types.Typ[types.UntypedString]\n-\t\tval = constant.MakeFromLiteral(p.lit, token.STRING, 0)\n-\t\tp.next()\n-\n-\tdefault:\n-\t\tp.errorf(\"expected literal got %s\", scanner.TokenString(p.tok))\n-\t}\n-\n-\tif typ0 == nil {\n-\t\ttyp0 = typ\n-\t}\n-\n-\tpkg.Scope().Insert(types.NewConst(token.NoPos, pkg, name, typ0, val))\n-}\n-\n-// TypeDecl = \"type\" ExportedName Type .\n-//\n-func (p *parser) parseTypeDecl() {\n-\tp.expectKeyword(\"type\")\n-\tpkg, name := p.parseExportedName()\n-\tobj := declTypeName(pkg, name)\n-\n-\t// The type object may have been imported before and thus already\n-\t// have a type associated with it. We still need to parse the type\n-\t// structure, but throw it away if the object already has a type.\n-\t// This ensures that all imports refer to the same type object for\n-\t// a given type declaration.\n-\ttyp := p.parseType(pkg)\n-\n-\tif name := obj.Type().(*types.Named); name.Underlying() == nil {\n-\t\tname.SetUnderlying(typ)\n-\t}\n-}\n-\n-// VarDecl = \"var\" ExportedName Type .\n-//\n-func (p *parser) parseVarDecl() {\n-\tp.expectKeyword(\"var\")\n-\tpkg, name := p.parseExportedName()\n-\ttyp := p.parseType(pkg)\n-\tpkg.Scope().Insert(types.NewVar(token.NoPos, pkg, name, typ))\n-}\n-\n-// Func = Signature [ Body ] .\n-// Body = \"{\" ... \"}\" .\n-//\n-func (p *parser) parseFunc(recv *types.Var) *types.Signature {\n-\tsig := p.parseSignature(recv)\n-\tif p.tok == '{' {\n-\t\tp.next()\n-\t\tfor i := 1; i > 0; p.next() {\n-\t\t\tswitch p.tok {\n-\t\t\tcase '{':\n-\t\t\t\ti++\n-\t\t\tcase '}':\n-\t\t\t\ti--\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn sig\n-}\n-\n-// MethodDecl = \"func\" Receiver Name Func .\n-// Receiver   = \"(\" ( identifier | \"?\" ) [ \"*\" ] ExportedName \")\" .\n-//\n-func (p *parser) parseMethodDecl() {\n-\t// \"func\" already consumed\n-\tp.expect('(')\n-\trecv, _ := p.parseParameter() // receiver\n-\tp.expect(')')\n-\n-\t// determine receiver base type object\n-\tbase := deref(recv.Type()).(*types.Named)\n-\n-\t// parse method name, signature, and possibly inlined body\n-\t_, name := p.parseName(nil, false)\n-\tsig := p.parseFunc(recv)\n-\n-\t// methods always belong to the same package as the base type object\n-\tpkg := base.Obj().Pkg()\n-\n-\t// add method to type unless type was imported before\n-\t// and method exists already\n-\t// TODO(gri) This leads to a quadratic algorithm - ok for now because method counts are small.\n-\tbase.AddMethod(types.NewFunc(token.NoPos, pkg, name, sig))\n-}\n-\n-// FuncDecl = \"func\" ExportedName Func .\n-//\n-func (p *parser) parseFuncDecl() {\n-\t// \"func\" already consumed\n-\tpkg, name := p.parseExportedName()\n-\ttyp := p.parseFunc(nil)\n-\tpkg.Scope().Insert(types.NewFunc(token.NoPos, pkg, name, typ))\n-}\n-\n-// Decl = [ ImportDecl | ConstDecl | TypeDecl | VarDecl | FuncDecl | MethodDecl ] \"\\n\" .\n-//\n-func (p *parser) parseDecl() {\n-\tif p.tok == scanner.Ident {\n-\t\tswitch p.lit {\n-\t\tcase \"import\":\n-\t\t\tp.parseImportDecl()\n-\t\tcase \"const\":\n-\t\t\tp.parseConstDecl()\n-\t\tcase \"type\":\n-\t\t\tp.parseTypeDecl()\n-\t\tcase \"var\":\n-\t\t\tp.parseVarDecl()\n-\t\tcase \"func\":\n-\t\t\tp.next() // look ahead\n-\t\t\tif p.tok == '(' {\n-\t\t\t\tp.parseMethodDecl()\n-\t\t\t} else {\n-\t\t\t\tp.parseFuncDecl()\n-\t\t\t}\n-\t\t}\n-\t}\n-\tp.expect('\\n')\n-}\n-\n-// ----------------------------------------------------------------------------\n-// Export\n-\n-// Export        = \"PackageClause { Decl } \"$$\" .\n-// PackageClause = \"package\" PackageName [ \"safe\" ] \"\\n\" .\n-//\n-func (p *parser) parseExport() *types.Package {\n-\tp.expectKeyword(\"package\")\n-\tname := p.parsePackageName()\n-\tif p.tok == scanner.Ident && p.lit == \"safe\" {\n-\t\t// package was compiled with -u option - ignore\n-\t\tp.next()\n-\t}\n-\tp.expect('\\n')\n-\n-\tpkg := p.getPkg(p.id, name)\n-\n-\tfor p.tok != '$' && p.tok != scanner.EOF {\n-\t\tp.parseDecl()\n-\t}\n-\n-\tif ch := p.scanner.Peek(); p.tok != '$' || ch != '$' {\n-\t\t// don't call next()/expect() since reading past the\n-\t\t// export data may cause scanner errors (e.g. NUL chars)\n-\t\tp.errorf(\"expected '$$', got %s %c\", scanner.TokenString(p.tok), ch)\n-\t}\n-\n-\tif n := p.scanner.ErrorCount; n != 0 {\n-\t\tp.errorf(\"expected no scanner errors, got %d\", n)\n-\t}\n-\n-\t// Record all locally referenced packages as imports.\n-\tvar imports []*types.Package\n-\tfor id, pkg2 := range p.localPkgs {\n-\t\tif pkg2.Name() == \"\" {\n-\t\t\tp.errorf(\"%s package has no name\", id)\n-\t\t}\n-\t\tif id == p.id {\n-\t\t\tcontinue // avoid self-edge\n-\t\t}\n-\t\timports = append(imports, pkg2)\n-\t}\n-\tsort.Sort(byPath(imports))\n-\tpkg.SetImports(imports)\n-\n-\t// package was imported completely and without errors\n-\tpkg.MarkComplete()\n-\n-\treturn pkg\n-}\n-\n-type byPath []*types.Package\n-\n-func (a byPath) Len() int           { return len(a) }\n-func (a byPath) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\n-func (a byPath) Less(i, j int) bool { return a[i].Path() < a[j].Path() }"
    },
    {
      "sha": "4be32a2e55fe086634dfe61ddf4c57f112813519",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/iexport.go",
      "status": "removed",
      "additions": 0,
      "deletions": 739,
      "changes": 739,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iexport.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iexport.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iexport.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,739 +0,0 @@\n-// Copyright 2019 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Indexed binary package export.\n-// This file was derived from $GOROOT/src/cmd/compile/internal/gc/iexport.go;\n-// see that file for specification of the format.\n-\n-package gcimporter\n-\n-import (\n-\t\"bytes\"\n-\t\"encoding/binary\"\n-\t\"go/ast\"\n-\t\"go/constant\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"io\"\n-\t\"math/big\"\n-\t\"reflect\"\n-\t\"sort\"\n-)\n-\n-// Current indexed export format version. Increase with each format change.\n-// 0: Go1.11 encoding\n-const iexportVersion = 0\n-\n-// IExportData returns the binary export data for pkg.\n-//\n-// If no file set is provided, position info will be missing.\n-// The package path of the top-level package will not be recorded,\n-// so that calls to IImportData can override with a provided package path.\n-func IExportData(fset *token.FileSet, pkg *types.Package) (b []byte, err error) {\n-\tdefer func() {\n-\t\tif e := recover(); e != nil {\n-\t\t\tif ierr, ok := e.(internalError); ok {\n-\t\t\t\terr = ierr\n-\t\t\t\treturn\n-\t\t\t}\n-\t\t\t// Not an internal error; panic again.\n-\t\t\tpanic(e)\n-\t\t}\n-\t}()\n-\n-\tp := iexporter{\n-\t\tout:         bytes.NewBuffer(nil),\n-\t\tfset:        fset,\n-\t\tallPkgs:     map[*types.Package]bool{},\n-\t\tstringIndex: map[string]uint64{},\n-\t\tdeclIndex:   map[types.Object]uint64{},\n-\t\ttypIndex:    map[types.Type]uint64{},\n-\t\tlocalpkg:    pkg,\n-\t}\n-\n-\tfor i, pt := range predeclared() {\n-\t\tp.typIndex[pt] = uint64(i)\n-\t}\n-\tif len(p.typIndex) > predeclReserved {\n-\t\tpanic(internalErrorf(\"too many predeclared types: %d > %d\", len(p.typIndex), predeclReserved))\n-\t}\n-\n-\t// Initialize work queue with exported declarations.\n-\tscope := pkg.Scope()\n-\tfor _, name := range scope.Names() {\n-\t\tif ast.IsExported(name) {\n-\t\t\tp.pushDecl(scope.Lookup(name))\n-\t\t}\n-\t}\n-\n-\t// Loop until no more work.\n-\tfor !p.declTodo.empty() {\n-\t\tp.doDecl(p.declTodo.popHead())\n-\t}\n-\n-\t// Append indices to data0 section.\n-\tdataLen := uint64(p.data0.Len())\n-\tw := p.newWriter()\n-\tw.writeIndex(p.declIndex)\n-\tw.flush()\n-\n-\t// Assemble header.\n-\tvar hdr intWriter\n-\thdr.WriteByte('i')\n-\thdr.uint64(iexportVersion)\n-\thdr.uint64(uint64(p.strings.Len()))\n-\thdr.uint64(dataLen)\n-\n-\t// Flush output.\n-\tio.Copy(p.out, &hdr)\n-\tio.Copy(p.out, &p.strings)\n-\tio.Copy(p.out, &p.data0)\n-\n-\treturn p.out.Bytes(), nil\n-}\n-\n-// writeIndex writes out an object index. mainIndex indicates whether\n-// we're writing out the main index, which is also read by\n-// non-compiler tools and includes a complete package description\n-// (i.e., name and height).\n-func (w *exportWriter) writeIndex(index map[types.Object]uint64) {\n-\t// Build a map from packages to objects from that package.\n-\tpkgObjs := map[*types.Package][]types.Object{}\n-\n-\t// For the main index, make sure to include every package that\n-\t// we reference, even if we're not exporting (or reexporting)\n-\t// any symbols from it.\n-\tpkgObjs[w.p.localpkg] = nil\n-\tfor pkg := range w.p.allPkgs {\n-\t\tpkgObjs[pkg] = nil\n-\t}\n-\n-\tfor obj := range index {\n-\t\tpkgObjs[obj.Pkg()] = append(pkgObjs[obj.Pkg()], obj)\n-\t}\n-\n-\tvar pkgs []*types.Package\n-\tfor pkg, objs := range pkgObjs {\n-\t\tpkgs = append(pkgs, pkg)\n-\n-\t\tsort.Slice(objs, func(i, j int) bool {\n-\t\t\treturn objs[i].Name() < objs[j].Name()\n-\t\t})\n-\t}\n-\n-\tsort.Slice(pkgs, func(i, j int) bool {\n-\t\treturn w.exportPath(pkgs[i]) < w.exportPath(pkgs[j])\n-\t})\n-\n-\tw.uint64(uint64(len(pkgs)))\n-\tfor _, pkg := range pkgs {\n-\t\tw.string(w.exportPath(pkg))\n-\t\tw.string(pkg.Name())\n-\t\tw.uint64(uint64(0)) // package height is not needed for go/types\n-\n-\t\tobjs := pkgObjs[pkg]\n-\t\tw.uint64(uint64(len(objs)))\n-\t\tfor _, obj := range objs {\n-\t\t\tw.string(obj.Name())\n-\t\t\tw.uint64(index[obj])\n-\t\t}\n-\t}\n-}\n-\n-type iexporter struct {\n-\tfset *token.FileSet\n-\tout  *bytes.Buffer\n-\n-\tlocalpkg *types.Package\n-\n-\t// allPkgs tracks all packages that have been referenced by\n-\t// the export data, so we can ensure to include them in the\n-\t// main index.\n-\tallPkgs map[*types.Package]bool\n-\n-\tdeclTodo objQueue\n-\n-\tstrings     intWriter\n-\tstringIndex map[string]uint64\n-\n-\tdata0     intWriter\n-\tdeclIndex map[types.Object]uint64\n-\ttypIndex  map[types.Type]uint64\n-}\n-\n-// stringOff returns the offset of s within the string section.\n-// If not already present, it's added to the end.\n-func (p *iexporter) stringOff(s string) uint64 {\n-\toff, ok := p.stringIndex[s]\n-\tif !ok {\n-\t\toff = uint64(p.strings.Len())\n-\t\tp.stringIndex[s] = off\n-\n-\t\tp.strings.uint64(uint64(len(s)))\n-\t\tp.strings.WriteString(s)\n-\t}\n-\treturn off\n-}\n-\n-// pushDecl adds n to the declaration work queue, if not already present.\n-func (p *iexporter) pushDecl(obj types.Object) {\n-\t// Package unsafe is known to the compiler and predeclared.\n-\tassert(obj.Pkg() != types.Unsafe)\n-\n-\tif _, ok := p.declIndex[obj]; ok {\n-\t\treturn\n-\t}\n-\n-\tp.declIndex[obj] = ^uint64(0) // mark n present in work queue\n-\tp.declTodo.pushTail(obj)\n-}\n-\n-// exportWriter handles writing out individual data section chunks.\n-type exportWriter struct {\n-\tp *iexporter\n-\n-\tdata     intWriter\n-\tcurrPkg  *types.Package\n-\tprevFile string\n-\tprevLine int64\n-}\n-\n-func (w *exportWriter) exportPath(pkg *types.Package) string {\n-\tif pkg == w.p.localpkg {\n-\t\treturn \"\"\n-\t}\n-\treturn pkg.Path()\n-}\n-\n-func (p *iexporter) doDecl(obj types.Object) {\n-\tw := p.newWriter()\n-\tw.setPkg(obj.Pkg(), false)\n-\n-\tswitch obj := obj.(type) {\n-\tcase *types.Var:\n-\t\tw.tag('V')\n-\t\tw.pos(obj.Pos())\n-\t\tw.typ(obj.Type(), obj.Pkg())\n-\n-\tcase *types.Func:\n-\t\tsig, _ := obj.Type().(*types.Signature)\n-\t\tif sig.Recv() != nil {\n-\t\t\tpanic(internalErrorf(\"unexpected method: %v\", sig))\n-\t\t}\n-\t\tw.tag('F')\n-\t\tw.pos(obj.Pos())\n-\t\tw.signature(sig)\n-\n-\tcase *types.Const:\n-\t\tw.tag('C')\n-\t\tw.pos(obj.Pos())\n-\t\tw.value(obj.Type(), obj.Val())\n-\n-\tcase *types.TypeName:\n-\t\tif obj.IsAlias() {\n-\t\t\tw.tag('A')\n-\t\t\tw.pos(obj.Pos())\n-\t\t\tw.typ(obj.Type(), obj.Pkg())\n-\t\t\tbreak\n-\t\t}\n-\n-\t\t// Defined type.\n-\t\tw.tag('T')\n-\t\tw.pos(obj.Pos())\n-\n-\t\tunderlying := obj.Type().Underlying()\n-\t\tw.typ(underlying, obj.Pkg())\n-\n-\t\tt := obj.Type()\n-\t\tif types.IsInterface(t) {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\tnamed, ok := t.(*types.Named)\n-\t\tif !ok {\n-\t\t\tpanic(internalErrorf(\"%s is not a defined type\", t))\n-\t\t}\n-\n-\t\tn := named.NumMethods()\n-\t\tw.uint64(uint64(n))\n-\t\tfor i := 0; i < n; i++ {\n-\t\t\tm := named.Method(i)\n-\t\t\tw.pos(m.Pos())\n-\t\t\tw.string(m.Name())\n-\t\t\tsig, _ := m.Type().(*types.Signature)\n-\t\t\tw.param(sig.Recv())\n-\t\t\tw.signature(sig)\n-\t\t}\n-\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected object: %v\", obj))\n-\t}\n-\n-\tp.declIndex[obj] = w.flush()\n-}\n-\n-func (w *exportWriter) tag(tag byte) {\n-\tw.data.WriteByte(tag)\n-}\n-\n-func (w *exportWriter) pos(pos token.Pos) {\n-\tif w.p.fset == nil {\n-\t\tw.int64(0)\n-\t\treturn\n-\t}\n-\n-\tp := w.p.fset.Position(pos)\n-\tfile := p.Filename\n-\tline := int64(p.Line)\n-\n-\t// When file is the same as the last position (common case),\n-\t// we can save a few bytes by delta encoding just the line\n-\t// number.\n-\t//\n-\t// Note: Because data objects may be read out of order (or not\n-\t// at all), we can only apply delta encoding within a single\n-\t// object. This is handled implicitly by tracking prevFile and\n-\t// prevLine as fields of exportWriter.\n-\n-\tif file == w.prevFile {\n-\t\tdelta := line - w.prevLine\n-\t\tw.int64(delta)\n-\t\tif delta == deltaNewFile {\n-\t\t\tw.int64(-1)\n-\t\t}\n-\t} else {\n-\t\tw.int64(deltaNewFile)\n-\t\tw.int64(line) // line >= 0\n-\t\tw.string(file)\n-\t\tw.prevFile = file\n-\t}\n-\tw.prevLine = line\n-}\n-\n-func (w *exportWriter) pkg(pkg *types.Package) {\n-\t// Ensure any referenced packages are declared in the main index.\n-\tw.p.allPkgs[pkg] = true\n-\n-\tw.string(w.exportPath(pkg))\n-}\n-\n-func (w *exportWriter) qualifiedIdent(obj types.Object) {\n-\t// Ensure any referenced declarations are written out too.\n-\tw.p.pushDecl(obj)\n-\n-\tw.string(obj.Name())\n-\tw.pkg(obj.Pkg())\n-}\n-\n-func (w *exportWriter) typ(t types.Type, pkg *types.Package) {\n-\tw.data.uint64(w.p.typOff(t, pkg))\n-}\n-\n-func (p *iexporter) newWriter() *exportWriter {\n-\treturn &exportWriter{p: p}\n-}\n-\n-func (w *exportWriter) flush() uint64 {\n-\toff := uint64(w.p.data0.Len())\n-\tio.Copy(&w.p.data0, &w.data)\n-\treturn off\n-}\n-\n-func (p *iexporter) typOff(t types.Type, pkg *types.Package) uint64 {\n-\toff, ok := p.typIndex[t]\n-\tif !ok {\n-\t\tw := p.newWriter()\n-\t\tw.doTyp(t, pkg)\n-\t\toff = predeclReserved + w.flush()\n-\t\tp.typIndex[t] = off\n-\t}\n-\treturn off\n-}\n-\n-func (w *exportWriter) startType(k itag) {\n-\tw.data.uint64(uint64(k))\n-}\n-\n-func (w *exportWriter) doTyp(t types.Type, pkg *types.Package) {\n-\tswitch t := t.(type) {\n-\tcase *types.Named:\n-\t\tw.startType(definedType)\n-\t\tw.qualifiedIdent(t.Obj())\n-\n-\tcase *types.Pointer:\n-\t\tw.startType(pointerType)\n-\t\tw.typ(t.Elem(), pkg)\n-\n-\tcase *types.Slice:\n-\t\tw.startType(sliceType)\n-\t\tw.typ(t.Elem(), pkg)\n-\n-\tcase *types.Array:\n-\t\tw.startType(arrayType)\n-\t\tw.uint64(uint64(t.Len()))\n-\t\tw.typ(t.Elem(), pkg)\n-\n-\tcase *types.Chan:\n-\t\tw.startType(chanType)\n-\t\t// 1 RecvOnly; 2 SendOnly; 3 SendRecv\n-\t\tvar dir uint64\n-\t\tswitch t.Dir() {\n-\t\tcase types.RecvOnly:\n-\t\t\tdir = 1\n-\t\tcase types.SendOnly:\n-\t\t\tdir = 2\n-\t\tcase types.SendRecv:\n-\t\t\tdir = 3\n-\t\t}\n-\t\tw.uint64(dir)\n-\t\tw.typ(t.Elem(), pkg)\n-\n-\tcase *types.Map:\n-\t\tw.startType(mapType)\n-\t\tw.typ(t.Key(), pkg)\n-\t\tw.typ(t.Elem(), pkg)\n-\n-\tcase *types.Signature:\n-\t\tw.startType(signatureType)\n-\t\tw.setPkg(pkg, true)\n-\t\tw.signature(t)\n-\n-\tcase *types.Struct:\n-\t\tw.startType(structType)\n-\t\tw.setPkg(pkg, true)\n-\n-\t\tn := t.NumFields()\n-\t\tw.uint64(uint64(n))\n-\t\tfor i := 0; i < n; i++ {\n-\t\t\tf := t.Field(i)\n-\t\t\tw.pos(f.Pos())\n-\t\t\tw.string(f.Name())\n-\t\t\tw.typ(f.Type(), pkg)\n-\t\t\tw.bool(f.Anonymous())\n-\t\t\tw.string(t.Tag(i)) // note (or tag)\n-\t\t}\n-\n-\tcase *types.Interface:\n-\t\tw.startType(interfaceType)\n-\t\tw.setPkg(pkg, true)\n-\n-\t\tn := t.NumEmbeddeds()\n-\t\tw.uint64(uint64(n))\n-\t\tfor i := 0; i < n; i++ {\n-\t\t\tf := t.Embedded(i)\n-\t\t\tw.pos(f.Obj().Pos())\n-\t\t\tw.typ(f.Obj().Type(), f.Obj().Pkg())\n-\t\t}\n-\n-\t\tn = t.NumExplicitMethods()\n-\t\tw.uint64(uint64(n))\n-\t\tfor i := 0; i < n; i++ {\n-\t\t\tm := t.ExplicitMethod(i)\n-\t\t\tw.pos(m.Pos())\n-\t\t\tw.string(m.Name())\n-\t\t\tsig, _ := m.Type().(*types.Signature)\n-\t\t\tw.signature(sig)\n-\t\t}\n-\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected type: %v, %v\", t, reflect.TypeOf(t)))\n-\t}\n-}\n-\n-func (w *exportWriter) setPkg(pkg *types.Package, write bool) {\n-\tif write {\n-\t\tw.pkg(pkg)\n-\t}\n-\n-\tw.currPkg = pkg\n-}\n-\n-func (w *exportWriter) signature(sig *types.Signature) {\n-\tw.paramList(sig.Params())\n-\tw.paramList(sig.Results())\n-\tif sig.Params().Len() > 0 {\n-\t\tw.bool(sig.Variadic())\n-\t}\n-}\n-\n-func (w *exportWriter) paramList(tup *types.Tuple) {\n-\tn := tup.Len()\n-\tw.uint64(uint64(n))\n-\tfor i := 0; i < n; i++ {\n-\t\tw.param(tup.At(i))\n-\t}\n-}\n-\n-func (w *exportWriter) param(obj types.Object) {\n-\tw.pos(obj.Pos())\n-\tw.localIdent(obj)\n-\tw.typ(obj.Type(), obj.Pkg())\n-}\n-\n-func (w *exportWriter) value(typ types.Type, v constant.Value) {\n-\tw.typ(typ, nil)\n-\n-\tswitch v.Kind() {\n-\tcase constant.Bool:\n-\t\tw.bool(constant.BoolVal(v))\n-\tcase constant.Int:\n-\t\tvar i big.Int\n-\t\tif i64, exact := constant.Int64Val(v); exact {\n-\t\t\ti.SetInt64(i64)\n-\t\t} else if ui64, exact := constant.Uint64Val(v); exact {\n-\t\t\ti.SetUint64(ui64)\n-\t\t} else {\n-\t\t\ti.SetString(v.ExactString(), 10)\n-\t\t}\n-\t\tw.mpint(&i, typ)\n-\tcase constant.Float:\n-\t\tf := constantToFloat(v)\n-\t\tw.mpfloat(f, typ)\n-\tcase constant.Complex:\n-\t\tw.mpfloat(constantToFloat(constant.Real(v)), typ)\n-\t\tw.mpfloat(constantToFloat(constant.Imag(v)), typ)\n-\tcase constant.String:\n-\t\tw.string(constant.StringVal(v))\n-\tcase constant.Unknown:\n-\t\t// package contains type errors\n-\tdefault:\n-\t\tpanic(internalErrorf(\"unexpected value %v (%T)\", v, v))\n-\t}\n-}\n-\n-// constantToFloat converts a constant.Value with kind constant.Float to a\n-// big.Float.\n-func constantToFloat(x constant.Value) *big.Float {\n-\tassert(x.Kind() == constant.Float)\n-\t// Use the same floating-point precision (512) as cmd/compile\n-\t// (see Mpprec in cmd/compile/internal/gc/mpfloat.go).\n-\tconst mpprec = 512\n-\tvar f big.Float\n-\tf.SetPrec(mpprec)\n-\tif v, exact := constant.Float64Val(x); exact {\n-\t\t// float64\n-\t\tf.SetFloat64(v)\n-\t} else if num, denom := constant.Num(x), constant.Denom(x); num.Kind() == constant.Int {\n-\t\t// TODO(gri): add big.Rat accessor to constant.Value.\n-\t\tn := valueToRat(num)\n-\t\td := valueToRat(denom)\n-\t\tf.SetRat(n.Quo(n, d))\n-\t} else {\n-\t\t// Value too large to represent as a fraction => inaccessible.\n-\t\t// TODO(gri): add big.Float accessor to constant.Value.\n-\t\t_, ok := f.SetString(x.ExactString())\n-\t\tassert(ok)\n-\t}\n-\treturn &f\n-}\n-\n-// mpint exports a multi-precision integer.\n-//\n-// For unsigned types, small values are written out as a single\n-// byte. Larger values are written out as a length-prefixed big-endian\n-// byte string, where the length prefix is encoded as its complement.\n-// For example, bytes 0, 1, and 2 directly represent the integer\n-// values 0, 1, and 2; while bytes 255, 254, and 253 indicate a 1-,\n-// 2-, and 3-byte big-endian string follow.\n-//\n-// Encoding for signed types use the same general approach as for\n-// unsigned types, except small values use zig-zag encoding and the\n-// bottom bit of length prefix byte for large values is reserved as a\n-// sign bit.\n-//\n-// The exact boundary between small and large encodings varies\n-// according to the maximum number of bytes needed to encode a value\n-// of type typ. As a special case, 8-bit types are always encoded as a\n-// single byte.\n-//\n-// TODO(mdempsky): Is this level of complexity really worthwhile?\n-func (w *exportWriter) mpint(x *big.Int, typ types.Type) {\n-\tbasic, ok := typ.Underlying().(*types.Basic)\n-\tif !ok {\n-\t\tpanic(internalErrorf(\"unexpected type %v (%T)\", typ.Underlying(), typ.Underlying()))\n-\t}\n-\n-\tsigned, maxBytes := intSize(basic)\n-\n-\tnegative := x.Sign() < 0\n-\tif !signed && negative {\n-\t\tpanic(internalErrorf(\"negative unsigned integer; type %v, value %v\", typ, x))\n-\t}\n-\n-\tb := x.Bytes()\n-\tif len(b) > 0 && b[0] == 0 {\n-\t\tpanic(internalErrorf(\"leading zeros\"))\n-\t}\n-\tif uint(len(b)) > maxBytes {\n-\t\tpanic(internalErrorf(\"bad mpint length: %d > %d (type %v, value %v)\", len(b), maxBytes, typ, x))\n-\t}\n-\n-\tmaxSmall := 256 - maxBytes\n-\tif signed {\n-\t\tmaxSmall = 256 - 2*maxBytes\n-\t}\n-\tif maxBytes == 1 {\n-\t\tmaxSmall = 256\n-\t}\n-\n-\t// Check if x can use small value encoding.\n-\tif len(b) <= 1 {\n-\t\tvar ux uint\n-\t\tif len(b) == 1 {\n-\t\t\tux = uint(b[0])\n-\t\t}\n-\t\tif signed {\n-\t\t\tux <<= 1\n-\t\t\tif negative {\n-\t\t\t\tux--\n-\t\t\t}\n-\t\t}\n-\t\tif ux < maxSmall {\n-\t\t\tw.data.WriteByte(byte(ux))\n-\t\t\treturn\n-\t\t}\n-\t}\n-\n-\tn := 256 - uint(len(b))\n-\tif signed {\n-\t\tn = 256 - 2*uint(len(b))\n-\t\tif negative {\n-\t\t\tn |= 1\n-\t\t}\n-\t}\n-\tif n < maxSmall || n >= 256 {\n-\t\tpanic(internalErrorf(\"encoding mistake: %d, %v, %v => %d\", len(b), signed, negative, n))\n-\t}\n-\n-\tw.data.WriteByte(byte(n))\n-\tw.data.Write(b)\n-}\n-\n-// mpfloat exports a multi-precision floating point number.\n-//\n-// The number's value is decomposed into mantissa  2**exponent, where\n-// mantissa is an integer. The value is written out as mantissa (as a\n-// multi-precision integer) and then the exponent, except exponent is\n-// omitted if mantissa is zero.\n-func (w *exportWriter) mpfloat(f *big.Float, typ types.Type) {\n-\tif f.IsInf() {\n-\t\tpanic(\"infinite constant\")\n-\t}\n-\n-\t// Break into f = mant  2**exp, with 0.5 <= mant < 1.\n-\tvar mant big.Float\n-\texp := int64(f.MantExp(&mant))\n-\n-\t// Scale so that mant is an integer.\n-\tprec := mant.MinPrec()\n-\tmant.SetMantExp(&mant, int(prec))\n-\texp -= int64(prec)\n-\n-\tmanti, acc := mant.Int(nil)\n-\tif acc != big.Exact {\n-\t\tpanic(internalErrorf(\"mantissa scaling failed for %f (%s)\", f, acc))\n-\t}\n-\tw.mpint(manti, typ)\n-\tif manti.Sign() != 0 {\n-\t\tw.int64(exp)\n-\t}\n-}\n-\n-func (w *exportWriter) bool(b bool) bool {\n-\tvar x uint64\n-\tif b {\n-\t\tx = 1\n-\t}\n-\tw.uint64(x)\n-\treturn b\n-}\n-\n-func (w *exportWriter) int64(x int64)   { w.data.int64(x) }\n-func (w *exportWriter) uint64(x uint64) { w.data.uint64(x) }\n-func (w *exportWriter) string(s string) { w.uint64(w.p.stringOff(s)) }\n-\n-func (w *exportWriter) localIdent(obj types.Object) {\n-\t// Anonymous parameters.\n-\tif obj == nil {\n-\t\tw.string(\"\")\n-\t\treturn\n-\t}\n-\n-\tname := obj.Name()\n-\tif name == \"_\" {\n-\t\tw.string(\"_\")\n-\t\treturn\n-\t}\n-\n-\tw.string(name)\n-}\n-\n-type intWriter struct {\n-\tbytes.Buffer\n-}\n-\n-func (w *intWriter) int64(x int64) {\n-\tvar buf [binary.MaxVarintLen64]byte\n-\tn := binary.PutVarint(buf[:], x)\n-\tw.Write(buf[:n])\n-}\n-\n-func (w *intWriter) uint64(x uint64) {\n-\tvar buf [binary.MaxVarintLen64]byte\n-\tn := binary.PutUvarint(buf[:], x)\n-\tw.Write(buf[:n])\n-}\n-\n-func assert(cond bool) {\n-\tif !cond {\n-\t\tpanic(\"internal error: assertion failed\")\n-\t}\n-}\n-\n-// The below is copied from go/src/cmd/compile/internal/gc/syntax.go.\n-\n-// objQueue is a FIFO queue of types.Object. The zero value of objQueue is\n-// a ready-to-use empty queue.\n-type objQueue struct {\n-\tring       []types.Object\n-\thead, tail int\n-}\n-\n-// empty returns true if q contains no Nodes.\n-func (q *objQueue) empty() bool {\n-\treturn q.head == q.tail\n-}\n-\n-// pushTail appends n to the tail of the queue.\n-func (q *objQueue) pushTail(obj types.Object) {\n-\tif len(q.ring) == 0 {\n-\t\tq.ring = make([]types.Object, 16)\n-\t} else if q.head+len(q.ring) == q.tail {\n-\t\t// Grow the ring.\n-\t\tnring := make([]types.Object, len(q.ring)*2)\n-\t\t// Copy the old elements.\n-\t\tpart := q.ring[q.head%len(q.ring):]\n-\t\tif q.tail-q.head <= len(part) {\n-\t\t\tpart = part[:q.tail-q.head]\n-\t\t\tcopy(nring, part)\n-\t\t} else {\n-\t\t\tpos := copy(nring, part)\n-\t\t\tcopy(nring[pos:], q.ring[:q.tail%len(q.ring)])\n-\t\t}\n-\t\tq.ring, q.head, q.tail = nring, 0, q.tail-q.head\n-\t}\n-\n-\tq.ring[q.tail%len(q.ring)] = obj\n-\tq.tail++\n-}\n-\n-// popHead pops a node from the head of the queue. It panics if q is empty.\n-func (q *objQueue) popHead() types.Object {\n-\tif q.empty() {\n-\t\tpanic(\"dequeue empty\")\n-\t}\n-\tobj := q.ring[q.head%len(q.ring)]\n-\tq.head++\n-\treturn obj\n-}"
    },
    {
      "sha": "a31a880263e123683154599025fda8f5e29f1685",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/iimport.go",
      "status": "removed",
      "additions": 0,
      "deletions": 630,
      "changes": 630,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iimport.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iimport.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/iimport.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,630 +0,0 @@\n-// Copyright 2018 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Indexed package import.\n-// See cmd/compile/internal/gc/iexport.go for the export data format.\n-\n-// This file is a copy of $GOROOT/src/go/internal/gcimporter/iimport.go.\n-\n-package gcimporter\n-\n-import (\n-\t\"bytes\"\n-\t\"encoding/binary\"\n-\t\"fmt\"\n-\t\"go/constant\"\n-\t\"go/token\"\n-\t\"go/types\"\n-\t\"io\"\n-\t\"sort\"\n-)\n-\n-type intReader struct {\n-\t*bytes.Reader\n-\tpath string\n-}\n-\n-func (r *intReader) int64() int64 {\n-\ti, err := binary.ReadVarint(r.Reader)\n-\tif err != nil {\n-\t\terrorf(\"import %q: read varint error: %v\", r.path, err)\n-\t}\n-\treturn i\n-}\n-\n-func (r *intReader) uint64() uint64 {\n-\ti, err := binary.ReadUvarint(r.Reader)\n-\tif err != nil {\n-\t\terrorf(\"import %q: read varint error: %v\", r.path, err)\n-\t}\n-\treturn i\n-}\n-\n-const predeclReserved = 32\n-\n-type itag uint64\n-\n-const (\n-\t// Types\n-\tdefinedType itag = iota\n-\tpointerType\n-\tsliceType\n-\tarrayType\n-\tchanType\n-\tmapType\n-\tsignatureType\n-\tstructType\n-\tinterfaceType\n-)\n-\n-// IImportData imports a package from the serialized package data\n-// and returns the number of bytes consumed and a reference to the package.\n-// If the export data version is not recognized or the format is otherwise\n-// compromised, an error is returned.\n-func IImportData(fset *token.FileSet, imports map[string]*types.Package, data []byte, path string) (_ int, pkg *types.Package, err error) {\n-\tconst currentVersion = 1\n-\tversion := int64(-1)\n-\tdefer func() {\n-\t\tif e := recover(); e != nil {\n-\t\t\tif version > currentVersion {\n-\t\t\t\terr = fmt.Errorf(\"cannot import %q (%v), export data is newer version - update tool\", path, e)\n-\t\t\t} else {\n-\t\t\t\terr = fmt.Errorf(\"cannot import %q (%v), possibly version skew - reinstall package\", path, e)\n-\t\t\t}\n-\t\t}\n-\t}()\n-\n-\tr := &intReader{bytes.NewReader(data), path}\n-\n-\tversion = int64(r.uint64())\n-\tswitch version {\n-\tcase currentVersion, 0:\n-\tdefault:\n-\t\terrorf(\"unknown iexport format version %d\", version)\n-\t}\n-\n-\tsLen := int64(r.uint64())\n-\tdLen := int64(r.uint64())\n-\n-\twhence, _ := r.Seek(0, io.SeekCurrent)\n-\tstringData := data[whence : whence+sLen]\n-\tdeclData := data[whence+sLen : whence+sLen+dLen]\n-\tr.Seek(sLen+dLen, io.SeekCurrent)\n-\n-\tp := iimporter{\n-\t\tipath:   path,\n-\t\tversion: int(version),\n-\n-\t\tstringData:  stringData,\n-\t\tstringCache: make(map[uint64]string),\n-\t\tpkgCache:    make(map[uint64]*types.Package),\n-\n-\t\tdeclData: declData,\n-\t\tpkgIndex: make(map[*types.Package]map[string]uint64),\n-\t\ttypCache: make(map[uint64]types.Type),\n-\n-\t\tfake: fakeFileSet{\n-\t\t\tfset:  fset,\n-\t\t\tfiles: make(map[string]*token.File),\n-\t\t},\n-\t}\n-\n-\tfor i, pt := range predeclared() {\n-\t\tp.typCache[uint64(i)] = pt\n-\t}\n-\n-\tpkgList := make([]*types.Package, r.uint64())\n-\tfor i := range pkgList {\n-\t\tpkgPathOff := r.uint64()\n-\t\tpkgPath := p.stringAt(pkgPathOff)\n-\t\tpkgName := p.stringAt(r.uint64())\n-\t\t_ = r.uint64() // package height; unused by go/types\n-\n-\t\tif pkgPath == \"\" {\n-\t\t\tpkgPath = path\n-\t\t}\n-\t\tpkg := imports[pkgPath]\n-\t\tif pkg == nil {\n-\t\t\tpkg = types.NewPackage(pkgPath, pkgName)\n-\t\t\timports[pkgPath] = pkg\n-\t\t} else if pkg.Name() != pkgName {\n-\t\t\terrorf(\"conflicting names %s and %s for package %q\", pkg.Name(), pkgName, path)\n-\t\t}\n-\n-\t\tp.pkgCache[pkgPathOff] = pkg\n-\n-\t\tnameIndex := make(map[string]uint64)\n-\t\tfor nSyms := r.uint64(); nSyms > 0; nSyms-- {\n-\t\t\tname := p.stringAt(r.uint64())\n-\t\t\tnameIndex[name] = r.uint64()\n-\t\t}\n-\n-\t\tp.pkgIndex[pkg] = nameIndex\n-\t\tpkgList[i] = pkg\n-\t}\n-\tif len(pkgList) == 0 {\n-\t\terrorf(\"no packages found for %s\", path)\n-\t\tpanic(\"unreachable\")\n-\t}\n-\tp.ipkg = pkgList[0]\n-\tnames := make([]string, 0, len(p.pkgIndex[p.ipkg]))\n-\tfor name := range p.pkgIndex[p.ipkg] {\n-\t\tnames = append(names, name)\n-\t}\n-\tsort.Strings(names)\n-\tfor _, name := range names {\n-\t\tp.doDecl(p.ipkg, name)\n-\t}\n-\n-\tfor _, typ := range p.interfaceList {\n-\t\ttyp.Complete()\n-\t}\n-\n-\t// record all referenced packages as imports\n-\tlist := append(([]*types.Package)(nil), pkgList[1:]...)\n-\tsort.Sort(byPath(list))\n-\tp.ipkg.SetImports(list)\n-\n-\t// package was imported completely and without errors\n-\tp.ipkg.MarkComplete()\n-\n-\tconsumed, _ := r.Seek(0, io.SeekCurrent)\n-\treturn int(consumed), p.ipkg, nil\n-}\n-\n-type iimporter struct {\n-\tipath   string\n-\tipkg    *types.Package\n-\tversion int\n-\n-\tstringData  []byte\n-\tstringCache map[uint64]string\n-\tpkgCache    map[uint64]*types.Package\n-\n-\tdeclData []byte\n-\tpkgIndex map[*types.Package]map[string]uint64\n-\ttypCache map[uint64]types.Type\n-\n-\tfake          fakeFileSet\n-\tinterfaceList []*types.Interface\n-}\n-\n-func (p *iimporter) doDecl(pkg *types.Package, name string) {\n-\t// See if we've already imported this declaration.\n-\tif obj := pkg.Scope().Lookup(name); obj != nil {\n-\t\treturn\n-\t}\n-\n-\toff, ok := p.pkgIndex[pkg][name]\n-\tif !ok {\n-\t\terrorf(\"%v.%v not in index\", pkg, name)\n-\t}\n-\n-\tr := &importReader{p: p, currPkg: pkg}\n-\tr.declReader.Reset(p.declData[off:])\n-\n-\tr.obj(name)\n-}\n-\n-func (p *iimporter) stringAt(off uint64) string {\n-\tif s, ok := p.stringCache[off]; ok {\n-\t\treturn s\n-\t}\n-\n-\tslen, n := binary.Uvarint(p.stringData[off:])\n-\tif n <= 0 {\n-\t\terrorf(\"varint failed\")\n-\t}\n-\tspos := off + uint64(n)\n-\ts := string(p.stringData[spos : spos+slen])\n-\tp.stringCache[off] = s\n-\treturn s\n-}\n-\n-func (p *iimporter) pkgAt(off uint64) *types.Package {\n-\tif pkg, ok := p.pkgCache[off]; ok {\n-\t\treturn pkg\n-\t}\n-\tpath := p.stringAt(off)\n-\tif path == p.ipath {\n-\t\treturn p.ipkg\n-\t}\n-\terrorf(\"missing package %q in %q\", path, p.ipath)\n-\treturn nil\n-}\n-\n-func (p *iimporter) typAt(off uint64, base *types.Named) types.Type {\n-\tif t, ok := p.typCache[off]; ok && (base == nil || !isInterface(t)) {\n-\t\treturn t\n-\t}\n-\n-\tif off < predeclReserved {\n-\t\terrorf(\"predeclared type missing from cache: %v\", off)\n-\t}\n-\n-\tr := &importReader{p: p}\n-\tr.declReader.Reset(p.declData[off-predeclReserved:])\n-\tt := r.doType(base)\n-\n-\tif base == nil || !isInterface(t) {\n-\t\tp.typCache[off] = t\n-\t}\n-\treturn t\n-}\n-\n-type importReader struct {\n-\tp          *iimporter\n-\tdeclReader bytes.Reader\n-\tcurrPkg    *types.Package\n-\tprevFile   string\n-\tprevLine   int64\n-\tprevColumn int64\n-}\n-\n-func (r *importReader) obj(name string) {\n-\ttag := r.byte()\n-\tpos := r.pos()\n-\n-\tswitch tag {\n-\tcase 'A':\n-\t\ttyp := r.typ()\n-\n-\t\tr.declare(types.NewTypeName(pos, r.currPkg, name, typ))\n-\n-\tcase 'C':\n-\t\ttyp, val := r.value()\n-\n-\t\tr.declare(types.NewConst(pos, r.currPkg, name, typ, val))\n-\n-\tcase 'F':\n-\t\tsig := r.signature(nil)\n-\n-\t\tr.declare(types.NewFunc(pos, r.currPkg, name, sig))\n-\n-\tcase 'T':\n-\t\t// Types can be recursive. We need to setup a stub\n-\t\t// declaration before recursing.\n-\t\tobj := types.NewTypeName(pos, r.currPkg, name, nil)\n-\t\tnamed := types.NewNamed(obj, nil, nil)\n-\t\tr.declare(obj)\n-\n-\t\tunderlying := r.p.typAt(r.uint64(), named).Underlying()\n-\t\tnamed.SetUnderlying(underlying)\n-\n-\t\tif !isInterface(underlying) {\n-\t\t\tfor n := r.uint64(); n > 0; n-- {\n-\t\t\t\tmpos := r.pos()\n-\t\t\t\tmname := r.ident()\n-\t\t\t\trecv := r.param()\n-\t\t\t\tmsig := r.signature(recv)\n-\n-\t\t\t\tnamed.AddMethod(types.NewFunc(mpos, r.currPkg, mname, msig))\n-\t\t\t}\n-\t\t}\n-\n-\tcase 'V':\n-\t\ttyp := r.typ()\n-\n-\t\tr.declare(types.NewVar(pos, r.currPkg, name, typ))\n-\n-\tdefault:\n-\t\terrorf(\"unexpected tag: %v\", tag)\n-\t}\n-}\n-\n-func (r *importReader) declare(obj types.Object) {\n-\tobj.Pkg().Scope().Insert(obj)\n-}\n-\n-func (r *importReader) value() (typ types.Type, val constant.Value) {\n-\ttyp = r.typ()\n-\n-\tswitch b := typ.Underlying().(*types.Basic); b.Info() & types.IsConstType {\n-\tcase types.IsBoolean:\n-\t\tval = constant.MakeBool(r.bool())\n-\n-\tcase types.IsString:\n-\t\tval = constant.MakeString(r.string())\n-\n-\tcase types.IsInteger:\n-\t\tval = r.mpint(b)\n-\n-\tcase types.IsFloat:\n-\t\tval = r.mpfloat(b)\n-\n-\tcase types.IsComplex:\n-\t\tre := r.mpfloat(b)\n-\t\tim := r.mpfloat(b)\n-\t\tval = constant.BinaryOp(re, token.ADD, constant.MakeImag(im))\n-\n-\tdefault:\n-\t\tif b.Kind() == types.Invalid {\n-\t\t\tval = constant.MakeUnknown()\n-\t\t\treturn\n-\t\t}\n-\t\terrorf(\"unexpected type %v\", typ) // panics\n-\t\tpanic(\"unreachable\")\n-\t}\n-\n-\treturn\n-}\n-\n-func intSize(b *types.Basic) (signed bool, maxBytes uint) {\n-\tif (b.Info() & types.IsUntyped) != 0 {\n-\t\treturn true, 64\n-\t}\n-\n-\tswitch b.Kind() {\n-\tcase types.Float32, types.Complex64:\n-\t\treturn true, 3\n-\tcase types.Float64, types.Complex128:\n-\t\treturn true, 7\n-\t}\n-\n-\tsigned = (b.Info() & types.IsUnsigned) == 0\n-\tswitch b.Kind() {\n-\tcase types.Int8, types.Uint8:\n-\t\tmaxBytes = 1\n-\tcase types.Int16, types.Uint16:\n-\t\tmaxBytes = 2\n-\tcase types.Int32, types.Uint32:\n-\t\tmaxBytes = 4\n-\tdefault:\n-\t\tmaxBytes = 8\n-\t}\n-\n-\treturn\n-}\n-\n-func (r *importReader) mpint(b *types.Basic) constant.Value {\n-\tsigned, maxBytes := intSize(b)\n-\n-\tmaxSmall := 256 - maxBytes\n-\tif signed {\n-\t\tmaxSmall = 256 - 2*maxBytes\n-\t}\n-\tif maxBytes == 1 {\n-\t\tmaxSmall = 256\n-\t}\n-\n-\tn, _ := r.declReader.ReadByte()\n-\tif uint(n) < maxSmall {\n-\t\tv := int64(n)\n-\t\tif signed {\n-\t\t\tv >>= 1\n-\t\t\tif n&1 != 0 {\n-\t\t\t\tv = ^v\n-\t\t\t}\n-\t\t}\n-\t\treturn constant.MakeInt64(v)\n-\t}\n-\n-\tv := -n\n-\tif signed {\n-\t\tv = -(n &^ 1) >> 1\n-\t}\n-\tif v < 1 || uint(v) > maxBytes {\n-\t\terrorf(\"weird decoding: %v, %v => %v\", n, signed, v)\n-\t}\n-\n-\tbuf := make([]byte, v)\n-\tio.ReadFull(&r.declReader, buf)\n-\n-\t// convert to little endian\n-\t// TODO(gri) go/constant should have a more direct conversion function\n-\t//           (e.g., once it supports a big.Float based implementation)\n-\tfor i, j := 0, len(buf)-1; i < j; i, j = i+1, j-1 {\n-\t\tbuf[i], buf[j] = buf[j], buf[i]\n-\t}\n-\n-\tx := constant.MakeFromBytes(buf)\n-\tif signed && n&1 != 0 {\n-\t\tx = constant.UnaryOp(token.SUB, x, 0)\n-\t}\n-\treturn x\n-}\n-\n-func (r *importReader) mpfloat(b *types.Basic) constant.Value {\n-\tx := r.mpint(b)\n-\tif constant.Sign(x) == 0 {\n-\t\treturn x\n-\t}\n-\n-\texp := r.int64()\n-\tswitch {\n-\tcase exp > 0:\n-\t\tx = constant.Shift(x, token.SHL, uint(exp))\n-\tcase exp < 0:\n-\t\td := constant.Shift(constant.MakeInt64(1), token.SHL, uint(-exp))\n-\t\tx = constant.BinaryOp(x, token.QUO, d)\n-\t}\n-\treturn x\n-}\n-\n-func (r *importReader) ident() string {\n-\treturn r.string()\n-}\n-\n-func (r *importReader) qualifiedIdent() (*types.Package, string) {\n-\tname := r.string()\n-\tpkg := r.pkg()\n-\treturn pkg, name\n-}\n-\n-func (r *importReader) pos() token.Pos {\n-\tif r.p.version >= 1 {\n-\t\tr.posv1()\n-\t} else {\n-\t\tr.posv0()\n-\t}\n-\n-\tif r.prevFile == \"\" && r.prevLine == 0 && r.prevColumn == 0 {\n-\t\treturn token.NoPos\n-\t}\n-\treturn r.p.fake.pos(r.prevFile, int(r.prevLine), int(r.prevColumn))\n-}\n-\n-func (r *importReader) posv0() {\n-\tdelta := r.int64()\n-\tif delta != deltaNewFile {\n-\t\tr.prevLine += delta\n-\t} else if l := r.int64(); l == -1 {\n-\t\tr.prevLine += deltaNewFile\n-\t} else {\n-\t\tr.prevFile = r.string()\n-\t\tr.prevLine = l\n-\t}\n-}\n-\n-func (r *importReader) posv1() {\n-\tdelta := r.int64()\n-\tr.prevColumn += delta >> 1\n-\tif delta&1 != 0 {\n-\t\tdelta = r.int64()\n-\t\tr.prevLine += delta >> 1\n-\t\tif delta&1 != 0 {\n-\t\t\tr.prevFile = r.string()\n-\t\t}\n-\t}\n-}\n-\n-func (r *importReader) typ() types.Type {\n-\treturn r.p.typAt(r.uint64(), nil)\n-}\n-\n-func isInterface(t types.Type) bool {\n-\t_, ok := t.(*types.Interface)\n-\treturn ok\n-}\n-\n-func (r *importReader) pkg() *types.Package { return r.p.pkgAt(r.uint64()) }\n-func (r *importReader) string() string      { return r.p.stringAt(r.uint64()) }\n-\n-func (r *importReader) doType(base *types.Named) types.Type {\n-\tswitch k := r.kind(); k {\n-\tdefault:\n-\t\terrorf(\"unexpected kind tag in %q: %v\", r.p.ipath, k)\n-\t\treturn nil\n-\n-\tcase definedType:\n-\t\tpkg, name := r.qualifiedIdent()\n-\t\tr.p.doDecl(pkg, name)\n-\t\treturn pkg.Scope().Lookup(name).(*types.TypeName).Type()\n-\tcase pointerType:\n-\t\treturn types.NewPointer(r.typ())\n-\tcase sliceType:\n-\t\treturn types.NewSlice(r.typ())\n-\tcase arrayType:\n-\t\tn := r.uint64()\n-\t\treturn types.NewArray(r.typ(), int64(n))\n-\tcase chanType:\n-\t\tdir := chanDir(int(r.uint64()))\n-\t\treturn types.NewChan(dir, r.typ())\n-\tcase mapType:\n-\t\treturn types.NewMap(r.typ(), r.typ())\n-\tcase signatureType:\n-\t\tr.currPkg = r.pkg()\n-\t\treturn r.signature(nil)\n-\n-\tcase structType:\n-\t\tr.currPkg = r.pkg()\n-\n-\t\tfields := make([]*types.Var, r.uint64())\n-\t\ttags := make([]string, len(fields))\n-\t\tfor i := range fields {\n-\t\t\tfpos := r.pos()\n-\t\t\tfname := r.ident()\n-\t\t\tftyp := r.typ()\n-\t\t\temb := r.bool()\n-\t\t\ttag := r.string()\n-\n-\t\t\tfields[i] = types.NewField(fpos, r.currPkg, fname, ftyp, emb)\n-\t\t\ttags[i] = tag\n-\t\t}\n-\t\treturn types.NewStruct(fields, tags)\n-\n-\tcase interfaceType:\n-\t\tr.currPkg = r.pkg()\n-\n-\t\tembeddeds := make([]types.Type, r.uint64())\n-\t\tfor i := range embeddeds {\n-\t\t\t_ = r.pos()\n-\t\t\tembeddeds[i] = r.typ()\n-\t\t}\n-\n-\t\tmethods := make([]*types.Func, r.uint64())\n-\t\tfor i := range methods {\n-\t\t\tmpos := r.pos()\n-\t\t\tmname := r.ident()\n-\n-\t\t\t// TODO(mdempsky): Matches bimport.go, but I\n-\t\t\t// don't agree with this.\n-\t\t\tvar recv *types.Var\n-\t\t\tif base != nil {\n-\t\t\t\trecv = types.NewVar(token.NoPos, r.currPkg, \"\", base)\n-\t\t\t}\n-\n-\t\t\tmsig := r.signature(recv)\n-\t\t\tmethods[i] = types.NewFunc(mpos, r.currPkg, mname, msig)\n-\t\t}\n-\n-\t\ttyp := newInterface(methods, embeddeds)\n-\t\tr.p.interfaceList = append(r.p.interfaceList, typ)\n-\t\treturn typ\n-\t}\n-}\n-\n-func (r *importReader) kind() itag {\n-\treturn itag(r.uint64())\n-}\n-\n-func (r *importReader) signature(recv *types.Var) *types.Signature {\n-\tparams := r.paramList()\n-\tresults := r.paramList()\n-\tvariadic := params.Len() > 0 && r.bool()\n-\treturn types.NewSignature(recv, params, results, variadic)\n-}\n-\n-func (r *importReader) paramList() *types.Tuple {\n-\txs := make([]*types.Var, r.uint64())\n-\tfor i := range xs {\n-\t\txs[i] = r.param()\n-\t}\n-\treturn types.NewTuple(xs...)\n-}\n-\n-func (r *importReader) param() *types.Var {\n-\tpos := r.pos()\n-\tname := r.ident()\n-\ttyp := r.typ()\n-\treturn types.NewParam(pos, r.currPkg, name, typ)\n-}\n-\n-func (r *importReader) bool() bool {\n-\treturn r.uint64() != 0\n-}\n-\n-func (r *importReader) int64() int64 {\n-\tn, err := binary.ReadVarint(&r.declReader)\n-\tif err != nil {\n-\t\terrorf(\"readVarint: %v\", err)\n-\t}\n-\treturn n\n-}\n-\n-func (r *importReader) uint64() uint64 {\n-\tn, err := binary.ReadUvarint(&r.declReader)\n-\tif err != nil {\n-\t\terrorf(\"readUvarint: %v\", err)\n-\t}\n-\treturn n\n-}\n-\n-func (r *importReader) byte() byte {\n-\tx, err := r.declReader.ReadByte()\n-\tif err != nil {\n-\t\terrorf(\"declReader.ReadByte: %v\", err)\n-\t}\n-\treturn x\n-}"
    },
    {
      "sha": "463f2522714638323cb37cd9523a6be99d3bdac8",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface10.go",
      "status": "removed",
      "additions": 0,
      "deletions": 21,
      "changes": 21,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface10.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface10.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface10.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,21 +0,0 @@\n-// Copyright 2018 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// +build !go1.11\n-\n-package gcimporter\n-\n-import \"go/types\"\n-\n-func newInterface(methods []*types.Func, embeddeds []types.Type) *types.Interface {\n-\tnamed := make([]*types.Named, len(embeddeds))\n-\tfor i, e := range embeddeds {\n-\t\tvar ok bool\n-\t\tnamed[i], ok = e.(*types.Named)\n-\t\tif !ok {\n-\t\t\tpanic(\"embedding of non-defined interfaces in interfaces is not supported before Go 1.11\")\n-\t\t}\n-\t}\n-\treturn types.NewInterface(methods, named)\n-}"
    },
    {
      "sha": "ab28b95cbb84f5dd327ab613498d261d6364c917",
      "filename": "backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface11.go",
      "status": "removed",
      "additions": 0,
      "deletions": 13,
      "changes": 13,
      "blob_url": "https://github.com/umputun/remark42/blob/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface11.go",
      "raw_url": "https://github.com/umputun/remark42/raw/8818faf1892407023fc00647e483132aa282424d/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface11.go",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/golang.org/x/tools/go/internal/gcimporter/newInterface11.go?ref=8818faf1892407023fc00647e483132aa282424d",
      "patch": "@@ -1,13 +0,0 @@\n-// Copyright 2018 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// +build go1.11\n-\n-package gcimporter\n-\n-import \"go/types\"\n-\n-func newInterface(methods []*types.Func, embeddeds []types.Type) *types.Interface {\n-\treturn types.NewInterfaceType(methods, embeddeds)\n-}"
    },
    {
      "sha": "29444e945b92673472e026dc9cb061622138f370",
      "filename": "backend/vendor/modules.txt",
      "status": "modified",
      "additions": 10,
      "deletions": 19,
      "changes": 29,
      "blob_url": "https://github.com/umputun/remark42/blob/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/modules.txt",
      "raw_url": "https://github.com/umputun/remark42/raw/c852ea4834dbed5e739fcdfecce51fe7638236a2/backend/vendor/modules.txt",
      "contents_url": "https://api.github.com/repos/umputun/remark42/contents/backend/vendor/modules.txt?ref=c852ea4834dbed5e739fcdfecce51fe7638236a2",
      "patch": "@@ -3,10 +3,10 @@ cloud.google.com/go/compute/metadata\n # github.com/Depado/bfchroma v1.3.0\n ## explicit\n github.com/Depado/bfchroma\n-# github.com/PuerkitoBio/goquery v1.7.1\n+# github.com/PuerkitoBio/goquery v1.8.0\n ## explicit\n github.com/PuerkitoBio/goquery\n-# github.com/alecthomas/chroma v0.9.2\n+# github.com/alecthomas/chroma v0.9.4\n ## explicit\n github.com/alecthomas/chroma\n github.com/alecthomas/chroma/formatters/html\n@@ -39,13 +39,11 @@ github.com/alecthomas/chroma/lexers/x\n github.com/alecthomas/chroma/lexers/y\n github.com/alecthomas/chroma/lexers/z\n github.com/alecthomas/chroma/styles\n-# github.com/andybalholm/cascadia v1.2.0\n+# github.com/andybalholm/cascadia v1.3.1\n github.com/andybalholm/cascadia\n # github.com/aymerick/douceur v0.2.0\n github.com/aymerick/douceur/css\n github.com/aymerick/douceur/parser\n-# github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964\n-github.com/danwakefield/fnmatch\n # github.com/davecgh/go-spew v1.1.1\n github.com/davecgh/go-spew/spew\n # github.com/dghubble/oauth1 v0.7.0\n@@ -66,7 +64,7 @@ github.com/dlclark/regexp2/syntax\n # github.com/go-chi/chi v4.1.1+incompatible\n github.com/go-chi/chi\n github.com/go-chi/chi/middleware\n-# github.com/go-chi/chi/v5 v5.0.4\n+# github.com/go-chi/chi/v5 v5.0.5\n ## explicit\n github.com/go-chi/chi/v5\n github.com/go-chi/chi/v5/middleware\n@@ -173,7 +171,7 @@ github.com/rs/xid\n # github.com/russross/blackfriday/v2 v2.1.0\n ## explicit\n github.com/russross/blackfriday/v2\n-# github.com/slack-go/slack v0.9.4\n+# github.com/slack-go/slack v0.9.5\n ## explicit\n github.com/slack-go/slack\n github.com/slack-go/slack/internal/backoff\n@@ -237,24 +235,21 @@ go.mongodb.org/mongo-driver/x/mongo/driver/session\n go.mongodb.org/mongo-driver/x/mongo/driver/topology\n go.mongodb.org/mongo-driver/x/mongo/driver/uuid\n go.mongodb.org/mongo-driver/x/mongo/driver/wiremessage\n-# go.uber.org/goleak v1.1.10\n+# go.uber.org/goleak v1.1.12\n ## explicit\n go.uber.org/goleak\n go.uber.org/goleak/internal/stack\n-# golang.org/x/crypto v0.0.0-20210817164053-32db794688a5\n+# golang.org/x/crypto v0.0.0-20210921155107-089bfa567519\n ## explicit\n golang.org/x/crypto/acme\n golang.org/x/crypto/acme/autocert\n golang.org/x/crypto/ocsp\n golang.org/x/crypto/pbkdf2\n-# golang.org/x/image v0.0.0-20210628002857-a66eb6448b8d\n+# golang.org/x/image v0.0.0-20211028202545-6944b10bf410\n ## explicit\n golang.org/x/image/draw\n golang.org/x/image/math/f64\n-# golang.org/x/lint v0.0.0-20200302205851-738671d3881b\n-golang.org/x/lint\n-golang.org/x/lint/golint\n-# golang.org/x/net v0.0.0-20210614182718-04defd469f4e\n+# golang.org/x/net v0.0.0-20210916014120-12bc252f5db8\n ## explicit\n golang.org/x/net/context\n golang.org/x/net/context/ctxhttp\n@@ -273,7 +268,7 @@ golang.org/x/oauth2/jws\n golang.org/x/oauth2/jwt\n golang.org/x/oauth2/microsoft\n golang.org/x/oauth2/yandex\n-# golang.org/x/sync v0.0.0-20200625203802-6e8e738ad208\n+# golang.org/x/sync v0.0.0-20210220032951-036812b2e83c\n golang.org/x/sync/errgroup\n golang.org/x/sync/semaphore\n # golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1\n@@ -286,10 +281,6 @@ golang.org/x/text/unicode/bidi\n golang.org/x/text/unicode/norm\n # golang.org/x/time v0.0.0-20200416051211-89c76fbcd5d1\n golang.org/x/time/rate\n-# golang.org/x/tools v0.0.0-20200825202427-b303f430e36d\n-golang.org/x/tools/go/ast/astutil\n-golang.org/x/tools/go/gcexportdata\n-golang.org/x/tools/go/internal/gcimporter\n # google.golang.org/appengine v1.6.6\n google.golang.org/appengine\n google.golang.org/appengine/internal"
    }
  ]
}
